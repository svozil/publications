\documentclass[11pt]{article}
\usepackage{eepic}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{geometry,url} \geometry{a4paper}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage[latin1]{inputenc}
\usepackage{fullpage}
\usepackage{array}
\usepackage{longtable}
\usepackage{calc}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{ifthen}
\usepackage{color}
\newcommand{\myshade}[1]{\raisebox{-4pt}{\rule{0pt}{16pt}}\colorbox[rgb]{.7,.7,.7}{#1}}
\begin{document}

\title{\bf   How Random Is Quantum Randomness?
}

\author{\bf Cristian S. Calude, Michael J. Dinneen, Karl Svozil,???\\\\[.5ex]
Department of Computer Science\\ University of Auckland,   New Zealand\\
  {\tt  $\{$cristian,mjd$\}$@cs.auckland.ac.nz} \\
  Institute for Theoretical Physics\\ University of Technology Vienna, Austria\\
  {\tt svozil@tuwien.ac.at}
  %Edit 3: {\tt  \today}
  }

\maketitle

\begin{abstract}Our aim is to experimentally study the possibility of distinguishing between sources of computable and incomputable ``randomness.''

We performed
tests of randomness on pseudo-random strings (finite sequences) of length $2^{32}$ generated with software
(Mathematica, Maple, AES) which are not only incomputable, but also cyclic, the bits of $\pi$, which are computable, but not cyclic, and strings which are prefixes infinite incomputable sequences generated by quantum measurements  (using the commercial device Quantis and produced by the Vienna IQOQI group).

Our empirical tests  indicate quantitative differences between computable
and incomputable sources.
\end{abstract}

\maketitle

\section{Introduction}


From the 16th century onwards, following Galilee, Kepler, Leibniz, Newton and others,
the rise of determinism culminated around the time of the French and American Revolutions
with Laplace's research on the stability of the solar system without divine intervention~\cite{frank}.
In the late 19th century, first indications of potential limits to
the pure deterministic research program emerged, in particular with Poincar{\'{e}}'s contribution to the
solution of the three- \cite{Sundman12} and general $n$-body problem~\cite{Wang91,Wang01,Diacu96},
which is often considered as a precursor of chaos theory~\cite{eckmann1}.

Soon, and despite the reluctance and opposition of many of its creators,
most notably Planck~\cite{born-55}, Einstein\footnote{
Recall Einstein's {\it dictum} in a letter to Born, dated December~12th, 1926~\cite[p.~113]{born-69},
``In any case I am convinced that he [[the Old One]] does not throw dice.''
(In German: ``Jedenfalls bin ich {\"{u}}berzeugt, dass der [[Alte]] nicht w{\"{u}}rfelt.'')},
Schr\"odinger and De Brogli,
quantum mechanics began to be accepted as an irreducibly probabilistic theory,
postulating an indispensable intrinsically random behaviour of individual particles,
while their probabilities follow deterministic laws.
With the rise of quantum mechanics (and later on also chaos theory), the {\em principle of sufficient reason}
--- stating that every phenomenon has its explanation and cause ---
had to be partially abandoned.
Indeed,  indeterminism and randomness in quantum mechanics,
as postulated by Born, Heisenberg, Bohr and Pauli~\cite[p.~115]{pauli-probaphysics}
is commonly believed, accepted and canonised to the extent  that~\cite{zeil-05_nature_ofQuantum}
``the discovery that individual events are
irreducibly random is probably one of the
most significant findings of the twentieth
century. [[$\ldots$]]~for the individual event in quantum physics, not only do we not know the cause, there is no cause.''


However, insufficient causation needs not be perceived merely negatively as a lack of prediction or control.
Today it is widely acknowledged that certified randomness can be a valuable resource
(e.g., for testing primality~\cite{ch-schw-78,Granville-92}), and that under various circumstances
a lack of randomness may have negative consequences (e.g., erroneous numerical calculations~\cite{PhysRevE.69.055702}).
The pitfalls of software-generated pseudo-randomness~\cite{v-neumann-50}
are well-known~\cite{Marsaglia-68,DBLP:journals/ibmrd/Pickover91,Bowman1995315,PhysRevE.69.055702}.
%\marginpar{examples}
In John von Neumann's words~ \cite{von-neumann1}:
``Anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin.''

Classical physical processes are subject to difficulties with ``subjective'' randomness
(a criticism often attributed to Heisenberg~\cite{zeil-05_nature_ofQuantum})
---
people consider events to be random when they cannot detect
any regularities characterising the structure of those events,
yet the events {\em could} still be causally described if they
would  know enough about the evolution of the system
---
or even bias; the typical example being coin tosses~\cite{diaconis:211}.
Several methods to generate random sequences from classical physical processes have been proposed~\cite{csw:prg},
among them the coding of electric pulses~\cite{0022-3735-3-8-303,0022-3735-3-10-528} or
semiconductor devices \cite{Agnew-87,Aware,Araneus,comscire,LavaRnd}.
%http://randomnumber.org/links.htm
%http://www.cs.berkeley.edu/~daw/rnd/
The first book~\cite{rand-55} containing a  million  of random digits  using a physical source of randomness
was published by The RAND Corporation in  1955\footnote{According to The RAND Corporation's disclosure,
``The random digits in this book were produced by rerandomization of a basic table generated
by an electronic roulette wheel. Briefly, a random frequency pulse source,
providing on the average about 100,000 pulses per second, was gated about once
per second by a constant frequency pulse. Pulse standardisation circuits passed
the pulses through a 5-place binary counter. In principle the machine was a 32-place
roulette wheel which made, on the average, about 3000 revolutions per trial and produced
one number per second. A binary-to-decimal converter was used which converted 20 of the 32 numbers
(the other twelve were discarded) and retained only the final digit of two-digit numbers;
this final digit was fed into an IBM punch to produce finally a punched card table of random digits.''
}.

More recently,  quantum randomness has been used as an ``objective'' resource of randomness
through various processes, in particular the decay of meta-stable states~\cite{PhysRevLett.54.1023,er-put:85,erber-95}
(for a criticism, see \cite{knight-86}) or radioactive decays~\cite{schmidt:462,walker-hotbits},
or the passage through some beam splitter~\cite{svozil-qct,rarity-94,zeilinger:qct,stefanov-2000}.


In three distinct but intricately interlinked ways, the evolution of quantum mechanics ordained the abandonment
of absolute determinism, and has established a clearly defined mixture of determinism and indeterminism,
at least in the mainstream perception of the formalism~\cite{jammer:89,jammer1,feynman-law,fuchs-peres,clauser-talkvie}:
\renewcommand{\labelenumi}{(\roman{enumi})}
\begin{enumerate}
\item
randomness of certain individual events,
such as the occurrence of certain measurement outcomes
for states which are in a  superposition of eigenstates
associated with eigenvalues corresponding to these outcomes;
\item
complementarity, as proposed by Pauli, Heisenberg and Bohr;
\item
value indefiniteness, as proven by Bell, Kochen \& Specker and others.
\end{enumerate}



\subsection{Random individual measurement outcomes}

With respect to the perception of certain individual outcomes of measurements,
the year 1926 marked the emergence of Born's acausal, indeterministic and
probabilistic interpretation of
Schr\"odinger's wave function as a complete and maximal description of a quantum mechanical state.
Born states that (cf. \cite[p.~866]{born-26-1}, English translation in \cite[p.~54]{wheeler-Zurek:83})\footnote{
{ ``Vom Standpunkt unserer Quantenmechanik gibt es keine Gr\"o\ss e, die im {\em Einzelfalle} den Effekts eines Sto\ss es
kausal festlegt; aber auch in der Erfahrung haben wir keinen Anhaltspunkt daf\"ur, da\ss~ es innere Eigenschaften
der Atome gibt, die einen bestimmten Sto\ss erfolg bedingen.
Sollen wir hoffen, sp\"ater solche Eigenschaften
[[$\ldots$]] zu entdecken und im Einzelfalle zu bestimmen?
Oder sollen wir glauben, dass die \"Ubereinstimmung von Theorie und Erfahrung
in der Unf\"ahigkeit, Bedingungen f\"ur den kausalen Ablauf anzugeben, eine pr\"astabilisierte Harmonie ist,
die auf der Nichtexistenz solcher Bedingungen beruht?
Ich selber neige dazu,die Determiniertheit in der atomaren Welt aufzugeben.''
}
}
\begin{quote}
{  ``From the standpoint of our quantum mechanics, there is no quantity
which in any individual case causally fixes the consequence of the collision;
but also experimentally we have so far no reason to believe that there are some inner properties of the atom
which condition a definite outcome for the collision.
Ought we to hope later to discover such properties [[$\ldots$]]  and determine them in individual cases?
Or ought we to  believe that the agreement of theory and experiment --- as to the impossibility
of prescribing conditions? I myself am inclined  to give up determinism in the world of atoms.''
}
\end{quote}
While postulating a probabilistic behaviour of individual particles,
Born offers a deterministic evolution of the wave function
(cf. \cite[p.~804]{born-26-2}, English translation in \cite[p.~302]{jammer:89})\footnote{
{  ``Die Bewegung der Partikel folgt Wahrscheinlichkeitsgesetzen,
die Wahrscheinlichkeit selbst aber breitet sich im Einklang mit dem Kausalgesetz  aus.
[Das hei\ss t, da\ss~ die Kenntnis des Zustandes in allen Punkten in einem Augenblick
die Verteilung des Zustandes zu allen sp{\"a}teren Zeiten festlegt.]''
}
}
\begin{quote}
{  ``The motion of particles conforms to the laws of probability, but the probability itself
is propagated in accordance with the law of causality.
[This means that knowledge of a state in all points in a given time determines the distribution of
the state at all later times.]''
}
\end{quote}

At the time of writing this statement Born did not specify the formal notion of ``indeterminism'' he was relating to.
So far, no mathematical characterisation of quantum randomness has been proven.
In the absence of any indication to the contrary, it is mostly implicitly assumed
that quantum randomness is of the strongest possible type;
which amounts to postulating that the associated sequences are algorithmically incompressible.
This does not exclude the possibility of weaker forms of randomness being generated by quantum measurements.


Random individual outcomes may occur at least in two different ways:
(i) either due to a context mismatch between preparation and measurement,
and
(ii) or
due to an ignorance of the state preparation resulting in a mixed state.
In what follows, we shall discuss them in some detail.


In what follows, we shall consider normalised states.
The superscript ``$T$'' indicates transposition.
If not stated otherwise, we shall adopt the notation of Mermin's book on {\em Quantum Computer Science}
\cite{mermin-07}.
A quantum mechanical context~\cite{svozil-2008-ql}
is a ``maximal collection of co-measurable observables'' constituting
a ``classical mini-universe'' within the nondistributive structure of quantum propositions.
It can be formalised by a single  ``maximal'' self-adjoint operator.
Every collection of mutually compatible co-measurable operators (such as projections corresponding to yes--no propositions)
are functions of such a maximal operator
(e.g., \cite[Sec.~II.10, p. 90, English translation p.~173]{v-neumann-49},
\cite[\S~2]{kochen1}, \cite[pp.~227,228]{neumark-54}, and  \cite[\S~84]{halmos-vs}).


\subsubsection{Mismatch between state preparation and measurement}
\label{2009-QvPR-s-mismatch}

There might be a {\em context} mismatch between state preparation and measurement;
i.e.,  the system has been prepared in a pure state
corresponding to a certain context (maximally observable),
and is measured in another,  complementary (see below) context
(maximally observable).
In such a case, the state of the system --- in terms of the spectral decomposition
of the measurement context --- is in a {\em coherent} superposition of at least some eigenstates of the preparation context.
An ``irreversible'' measurement~\cite{hkwz,greenberger2} ``reduces'' the state to one of the eigenstates
of the measurement context.
According to the Born rule (e.g., \cite[Chapter~1]{mermin-07}),
the probability of the occurrence of any such measurement outcome labelled by $i$
is given by the absolute square of the scalar products
$\vert \langle \psi_i \vert \varphi \rangle \vert^2$
between the state $\vert \varphi \rangle$  in which the system has been prepared
and the corresponding eigenstate $\vert \psi_i \rangle$
of the context.
Other than this probabilistic law, there is no further prediction for the occurrence of single measurement
outcomes.
Note that the amount of indeterminacy (as measured by the lack of bias of measurement outcomes
formalisable in terms of average algorithmic information increase per outcome)
increases with the ``apartness'' of the preparation and measurement properties;
i.e., with the magnitude of the context mismatch.
On the average, conjugate bases~\cite[p.~86]{wiesner} assure the greatest context mismatch,
and hence the greatest degree of randomness gain per experiment.


Quantum realisations of the method have been proposed~\cite{svozil-qct,rarity-94}\footnote{
See also the later patents at \cite{dultz-98,dultz-99},
as well as at \cite{Ribordy-04,Ribordy-06}.}
and realised~\cite[Fig.~1(b)]{zeilinger:qct} (see also \cite{stefanov-2000})
for a delayed choice Bell-type experiment~\cite{zeilinger-epr-98}.
Note that in this experimental realisation,  in the second {\em modus operandi} of \cite{zeilinger-epr-98},
light of very low intensity --- the photon production rate should be much smaller than the corresponding coherence time ---
is prepared by sending it through a linear polariser, e.g., in the vertical direction $\updownarrow$,
which guarantees that (ideally) only photons in a definite,
pure state corresponding to the polarisation direction $\updownarrow$ leave the polariser.
The photons impinge on a beam-splitting polariser,
which should (ideally) be maximally (anti)aligned at exactly $45^\circ$ ($\pi/4$~radians) in order to yield a 50:50 ratio of photons
polarised in either one of the two orthogonal directions $\swarrow\mkern-18mu\nearrow$
and $\searrow\mkern-18mu\nwarrow$ conveyed
in the two output ports and detected thereafter, respectively.


The process can be formalised as follows.
For a two-state process, a two-dimension Hilbert space suffices.
The role of the beam splitter can be described by a very general unitary transformation
which
can be represented by the product of a $U(1)=e^{-i\,\beta}$ and
of the unimodular unitary
matrix $SU(2)$ \cite{murnaghan}
\begin{equation}
\textsf{\textbf{ T}} (\omega ,\alpha ,\varphi )=
\left(
\begin{array}{cc}
{e^{i\,\alpha }}\,\cos \omega
&
{-e^{-i\,\varphi }}\,\sin \omega
\\
{e^{i\,\varphi }}\,\sin \omega
&
{e^{-i\,\alpha }}\,\cos \omega
 \end{array}
\right)
 \quad ,
\label{2009-e-QvPRSU2}
\end{equation}
where $-\pi \le \beta ,\omega \le \pi$,
$-\, {\pi \over 2} \le  \alpha ,\varphi \le {\pi \over 2}$.
For our purpose, it suffices to consider a 50:50 beam splitter~\cite{Mandel-Ou1987118,green-horn-zei,zeilinger:882,svozil-2004-analog}
of the Hadamard form
$
\textsf{\textbf{H}}= {1\over \sqrt{2}}
\left(
\begin{array}{rr}
1&1\\
1&-1
\end{array}
\right)$, which can be obtained from the general form by setting  $\omega =\frac{\pi}{4}$  and
$\alpha = \beta = \gamma =-\frac{\pi}{2}$  in $e^{-i\,\beta}$ and in Eq.~(\ref{2009-e-QvPRSU2}).
Note that $\textsf{\textbf{H}} \cdot \textsf{\textbf{H}} = \mathbb{I}_2$ is just the identity matrix in two dimensions.

If
$\vert \swarrow\mkern-18mu\nearrow \rangle \equiv (1,0)^T$ and
$\vert \searrow\mkern-18mu\nwarrow \rangle \equiv (0,1)^T$
--- alternatively, we could have used the notation $\vert 0 \rangle$  for $\vert \swarrow\mkern-18mu\nearrow \rangle$,
and $\vert 1 \rangle$  for $\vert \searrow\mkern-18mu\nwarrow \rangle$ ---
represent
certain orthogonal (linear polarisation) states measured,
and the particle have been prepared for in a (linear polarisation) state
\begin{equation}
\vert \updownarrow \rangle  =
\textsf{\textbf{H}} \vert \swarrow\mkern-18mu\nearrow \rangle =
\frac{1}{\sqrt{2}} \left( \vert \swarrow\mkern-18mu\nearrow \rangle
  + \vert \searrow\mkern-18mu\nwarrow  \rangle \right) \equiv \frac{1}{\sqrt{2}} (1,1)^T,
\end{equation}
which is a 50:50 superposition of both of these states,
then the probability to find the particle in either one of the detectors corresponding to
$\vert \swarrow\mkern-18mu\nearrow \rangle $ and
$\vert \searrow\mkern-18mu\nwarrow  \rangle $ is
\begin{equation}
\begin{array}{rcl}
P_\updownarrow (0)
&=&
\textrm{ trace} \left[
\vert \updownarrow \rangle \langle  \updownarrow \vert \cdot \vert \swarrow\mkern-18mu\nearrow \rangle \langle  \swarrow\mkern-18mu\nearrow \vert
\right]
\equiv
\textrm{ trace}
\left[
\frac{1}{2}\left(
\begin{array}{cc}
1&1\\
1&1
\end{array}
\right)
\cdot
\left(
\begin{array}{cc}
1&0\\
0&0
\end{array}
\right)
\right]
=\frac{1}{2},\;\textrm{
and }\\[2ex]
P_\updownarrow (1)&=&
\textrm{ trace} \left[
\vert \updownarrow \rangle \langle  \updownarrow \vert \cdot \vert \searrow\mkern-18mu\nwarrow  \rangle \langle   \searrow\mkern-18mu\nwarrow \vert
\right]
\equiv
\textrm{ trace}
\left[
\frac{1}{2}\left(
\begin{array}{cc}
1&1\\
1&1
\end{array}
\right)
\cdot
\left(
\begin{array}{cc}
0&0\\
0&1
\end{array}
\right)
\right]
=\frac{1}{2},
\end{array}
\end{equation}
that is, one obtains  a 50:50 chance for the occurrence of outcome $0$ or $1$, respectively.

In general it will be very difficult to establish and maintain an exact (anti)alignment of the polarisers,
resulting in a bias, which can be eliminated by partitioning the sequence of zeroes and ones into
fixed subsequences of length two, followed by discarding the even parity sequences $00$ and $11$,
and keeping only the odd parity ones $01$ and $10$, respectively.
In a second step, the remaining sequences could be mapped into the single symbols $01 \mapsto 0$ and  $10 \mapsto 1$,
thereby extracting a new unbiased sequence at the cost of a loss of original bits~\cite{von-neumann1}
(see Refs.~\cite{elias-72,PeresY-1992} for an improvement of this method,
and Refs.~\cite{dichtl-2007,Lacharme-2008} for a discussion of other methods).
%http://www.robertnz.net/hwrng.htm

\subsubsection{Ignorance resulting in a mixed state}

A second, maybe faster and easier and thus cheaper, possibility to produce quantum random bits
does not require any preparation step, but just {\em assumes}
the input state to be principally unknowable and indeterminate.
In this case, the system is in a non-pure, mixed state,
reflecting our ignorance about the state prepared~\cite[2nd part, \S~10, p.~827]{schrodinger}.


If the particle is in a totally mixed state,
its density matrix is just proportional to the identity matrix
$\rho_{\mathbb{I}_2 }=\frac{1}{2}\left(
\vert 0 \rangle \langle  0 \vert + \vert 1  \rangle \langle  1 \vert
\right) \equiv \frac{1}{2} \textrm{ diag}\left[\left(1,0 \right) +\textrm{ diag}\left(0,1 \right)\right] = \frac{1}{2}\mathbb{I}_2   $,
and the probability to find the particle in either one of the detectors corresponding to
$\vert 0 \rangle $ and
$\vert 1  \rangle $ is
\begin{equation}
\begin{array}{rcl}
P_{\rho_{\mathbb{I}_2 }}(0)&=&
\textrm{ trace} \left[
\rho_{\mathbb{I}_2 } \cdot \vert 0 \rangle \langle  0 \vert
\right]
\equiv
\textrm{ trace}
\left[
\frac{1}{2}\mathbb{I}_2
\cdot
\textrm{ diag}\left(1,0 \right)
\right]
=\frac{1}{2},\;\textrm{
and } \\[2ex]
P_{\rho_{\mathbb{I}_2 }}(1)&=&
\textrm{ trace} \left[
\rho_{\mathbb{I}_2 } \cdot \vert 1  \rangle \langle  1 \vert
\right]
\equiv
\textrm{ trace}
\left[
\frac{1}{2}\mathbb{I}_2
\cdot
\textrm{ diag}\left(0,1 \right)
\right]
=\frac{1}{2},
\end{array}
\end{equation}
that is, one again obtains a 50:50 chance for the occurrence of outcome $0$ or $1$, respectively.



Alas, is may be difficult to certify, control and assert  principle and total ignorance.
Indeed, the experimenter
preparing the system may {\em subjectively} assume to be ignorant,
whereas the system may implicitly be in a pure state with respect to a certain context, of which
the experimenter does not possess any knowledge, nor has any control.
Also temporal correlations may interfere with randomness.

Note also that any beam splitter is essentially a reversible, one-to-one
``translation device'' ``funnelling in'' particles in a certain state, thereby transforming
the state and ``spitting out'' the particles in a bijective manner.
This is reflected in the unitarity of its quantum mechanical description
by the product of $e^{-i\,\beta}$ and  Eq.~(\ref{2009-e-QvPRSU2}).
In this sense, without previous state preparation,
any quantum random number sequence is as good as the original source of particles.

For the sake of demonstration, consider  a ``black box'' which,
for undisclosed reasons, contains an (unknown) cyclic particle source or,
if one prefers, a mischievous demon  constantly
releasing particles (emanating from the black box) whose states oscillate
between
$\vert 0' \rangle =
\textsf{\textbf{H}} \vert 0 \rangle$
and
$\vert 1' \rangle =
\textsf{\textbf{H}} \vert 1 \rangle =
\frac{1}{\sqrt{2}} \left( \vert 0 \rangle
  - \vert 1  \rangle \right) \equiv \frac{1}{\sqrt{2}} (1,-1)^T,
$ with some frequency $\nu$, such that the state as a function of time is
either (pure case)
\begin{equation}
\vert \varphi_\nu (t) \rangle =  \sin (2\pi \nu t)
\vert 0' \rangle
+
 \cos (2\pi \nu t)
\vert 1' \rangle ,
\end{equation}
or (mixed case)
\begin{equation}
\rho_\nu (t)  =  \sin (2\pi \nu t)
\vert 0' \rangle \langle 0'  \vert
+
 \cos (2\pi \nu t)
\vert 1' \rangle \langle 1'  \vert
.
\end{equation}
If the sampling frequency (or any integer multiple thereof)
of this ``random'' sequence does not coincide with the oscillation frequency $\nu$,
then it may be very difficult for an experimenter to determine the source's regular behaviour,
which --- through the beam splitter ---  translates one-to-one into the sequence generated,
since
$\textsf{\textbf{H}}
\vert 0' \rangle
= \textsf{\textbf{H}} \cdot \textsf{\textbf{H}}  \vert 0 \rangle =
 \vert 0 \rangle
$
and
$\textsf{\textbf{H}}
\vert 1' \rangle
=        \textsf{\textbf{H}} \cdot \textsf{\textbf{H}}  \vert 1 \rangle =
\vert 1 \rangle
$.

Thus, it is not totally unjustified to state that claims of ``objective'' randomness
have to be cautiously reviewed
when particles emanating from an underspecified source are targeted directly towards some beam splitter,
as seems to be the case in one of the two setups in \cite[Fig.~1(a)]{zeilinger:qct}
and for other devices~\cite{stefanov-2000}\footnote{In its {\em White Paper on Random Numbers Generation
using Quantum Physics}~\cite{Quantis}, {\em id Quantique} on p.~7 (in the caption to Fig.~1) announces that
its {\em Quantis} device  uses a light emitting diode,
while at the same time (top of p.~7) pointing out that the monitoring of a Zener diode is problematic:
``Formally the evolution of these generators is not random, but just very complex. One
could say that determinism is hidden behind complexity.''
}.
The quality of the quantum random
sequences produced thus seems to depend on the quality of the light source
in combination with the beam splitter.
While {\em ``for all practical purposes (FAPP)}''
it may be justified to use a particular (or maybe even any type of) particle source
in combination with a particular beam splitter, this
falls short of a certified procedure to obtain truly random bits
in accordance with Bohm's principle of indeterminacy.


\subsection{Complementary contexts}

Complementarity is a quantum resource for randomness
which may be supporting the random occurrence of individual events
dealing with a mismatch between state preparation and measurement,
as has already been discussed in the section~\ref{2009-QvPR-s-mismatch}.
It is, however, no sufficient criterion for indeterminism, as can be seen from finite automata or generalised
urn models, which are nondistributive but still allow a classical representation~\cite{svozil-2001-eua}.
Whether or not complementarity is a necessary criterion for quantum indeterminism seems to be debatable.
For the lack necessity, it may suffice to refer to some recording of individual outcomes of
``irreversible'' measurements associated with a ``state reduction,''
or to some decay of a meta-stable state.
Yet, in the first ``state reduction'' case, the existence of principally unpredictable outcomes
seems to be linked to complementarity; at least from an operational point of view.
And also decays of excited states, due to the quantum Zeno effect~\cite{misra:756},
depend on the mode of their measurement, which may be linked to time and energy.
We shall not discuss these issues related to necessity further.


In 1933, Pauli gave the first explicit definition of complementarity stating that (cf. \cite[p.~7]{pauli:58},
partial English translation in \cite[p.~369]{jammer:89})\footnote{
{  ``Bei der Unbestimmtheit einer Eigenschaft eines Systems bei einer bestimmten Anordnung
(bei einem bestimmten Zustand eines Systems) vernichtet jeder Versuch, die betreffende Eigenschaft zu messen,
(mindestens teilweise) den Einflu\ss~
der fr{\"u}heren Kenntnisse vom System auf die (eventuell statistischen) Aussagen
{\"u}ber sp{\"a}tere m{\"o}gliche Messungsergebnisse.
[[$\ldots$]]
So m{\"u}ssen, um den Ort eines Teilchens zu bestimmen und um seinen Impuls zu bestimmen,
{\em einander ausschlie\ss ende Versuchsanordnungen benutzt werden.}
[[$\ldots$]]
Die Beeinflussung des Systems durch den Messaparat f{\"u}r den Impuls (Ort)
ist eine solche, da\ss~ innerhalb der durch die Ungenauigkeitsrelationen gegebenen Grenzen
die Benutzbarkeit der fr{\"u}heren Orts- (Impuls-)
Kenntnis f{\"u}r die Voraussagbarkeit der Ergebnisse sp{\"a}terer Orts- (Impuls-) Messungen verlorengegangen ist.
Wenn aus diesem Grunde die Benutzbarkeit {\em eines} klassischen Begriffes in einem
ausschlie\ss enden Verh{\"a}ltnis zu einem {\em anderen} steht, nennen wir diese beiden Begriffe (z.B. Orts- und
Impulskoordinaten eines Teilchens) mit Bohr {\em komplement{\"a}r.}
[[$\ldots$]]
Man wird sehen, dass diese ``Komplementarit{\"a}t'' kein Analogon in
der klassischen Gastheorie besitzt, die ja auch mit statistischen
Gesetzm\"a\ss igkeiten operiert.
Diese Theorie enth{\"a}lt n{\"a}mlich nicht die erst durch die Endlichkeit des Wirkungsquantums
geltend werdende Aussage, da\ss~ durch Messungen an einem System die durch fr{\"u}here Messungen gewonnenen Kenntnisse
{\"u}ber das System unter Umst{\"a}nden notwendig verlorengehen m{\"u}ssen, d.h. nicht mehr verwertet werden k{\"o}nnen.''
}
}
\begin{quote}
{  ``In the case of  an indeterminacy of a property of a system at a certain configuration
(at a certain state of a system), any attempt to measure the respective property (at least partially)
annihilates the influence of the previous knowledge of system on the (possibly statistical) propositions
about possible later measurement results.
[[$\ldots$]]
The impact
on the system by the  measurement apparatus for momentum (position) is such that
within the limits of the uncertainty relations
the value of the knowledge of the previous position (momentum) for the
prediction of later measurements of position and momentum is lost.
If, for this reason, the applicability of {\em one} classical concept stands in the relation of
exclusion to that of {\em another}, we call both of these
concepts (e.g., the position and momentum coordinates of a particle) with Bohr {\em complementary.}
[[$\ldots$]]
One will see that this ``complementarity''
has no analogy in the classical statistical theory of gases,
which also operates with statistical laws.
This theory does not contain the assertion --- which is only valid through the finiteness of the
quantum of action --- that the measurement of a system may necessarily result in a loss
of knowledge acquired through previous measurements; i.e., the previous
measurements can no longer be used.''
}
\end{quote}

Complementarity may thus be interpreted as a subtle kind of departure from
classical omniscience:
whereas it may in principle be possible to measure any single, individual context,
or any (classically operational) observable within (or encompassing) a context,
the direct measurement
(not involving counterfactuals in Einstein-Podolsky-Rosen type configurations~\cite{epr,svozil-2006-omni})
of two or more contexts, or of one context and some observable ``outside'' of it
is impossible.




\subsection{Value indefiniteness}

In deriving the quantum probabilities
---
which have originally been postulated by Born's rule as an axiom of quantum mechanics
---
from a buildup of classical probabilities within contexts in Hilbert spaces of dimension greater than two,
Gleason's theorem~\cite{Gleason,pitowsky:218,rich-bridge,r:dvur-93}
has motivated many authors to derive
nonlocal~\cite{bell,peres222,hey-red,ghz,mermin-93,zeilinger-epr-98}
as well as local~\cite{specker-60,kochen1,ZirlSchl-65,Alda,Alda2,kamber64,kamber65,peres-91,svozil-tkadlec,cabello-96,cabello:210401}
constraints on the existence of {\em global} truth functions (two-valued measures)
on the {\em entire domain} of quantum observables.
Bell's theorem already statistically indicated the
impossibility of co-existence of certain observables
``exceeding'' a single context, e.g.,
by considering the statistics of listing of possible measurement outcomes
and comparing them to the quantum expectations
\cite{peres222}; and the
Kochen-Specker theorem presented a finite proof (by contradiction)
of the impossibility of their co-existence.

When it comes to interpreting and understanding these results, one difficulty  is a fact
already encountered in the study of complementarity:
whereas the {\em totality} of contexts is not co-measurable,
any {\em individual} context is measurable.
In this sense,
the Kochen-Specker and related~\cite{ghz,mermin-93}
theorems  can be viewed to strengthen complementarity: not only
is it {\em operationally} impossible to directly~\cite{svozil-2006-uniquenessprinciple} measure
more than a single context (despite counterfactual measurements of two contexts
in Einstein-Podolsky-Rosen type configurations~\cite{epr,svozil-2006-omni}) ---
it is provable impossible to consistently assume any co-existence of all quantum observables
which could in principle be measured.

Of course, there are ways to ``cope'' with these findings deterministically;
the most popular being the ``contextuality''
assumption, which was first put forward by Bell
in an attempt to save a kind of realism~\cite{bohr-1949,bell-66,hey-red,redhead}.
It assumes that the
``$\ldots$
result of an observation may reasonably depend
not only on the state of the system  $\ldots$
but also on the complete disposition  of the apparatus,''
which could mean that the outcome of a measurement may depend on its context.
Other schemes to circumvent the quantum value indefiniteness are through
probabilities defined via paradoxical set decompositions~\cite{pitowsky-82,pitowsky-83}
or by considering certain dense subsets of scarcely interlinked quantum contexts~\cite{meyer:99}.

Despite these attempts to maintain at least a quasi-classical framework,
the Kochen-Specker theorem is a rather strong indication of value indefiniteness
and thus  of quantum randomness beyond Bohr's conjecture of the random occurrence of
individual events, and even beyond complementarity; at least for multi-context configurations.

Because a nontrivial interconnectedness of different bases
is possible only for Hilbert spaces of dimension three onwards,
the Gleason and the Kochen-Specker theorems apply only to Hilbert spaces
of dimensions {\em higher than two}, the value indefiniteness can be proven
only for systems of {\em three or more mutually exclusive outcomes}.
For two-dimensional system, one has still to rely purely on Born's indeterminacy postulate,
solely backed by complementarity and the quantum uncertainty relations.
We have to conclude that,
as all present quantum number generators using beam splitters (also the ones utilising complementarity)
operate with two exclusive outcomes,
they are not backed by value indefiniteness in the sense of Bell and Kochen \& Specker.

One may still argue that, although the Born rule for quantum probabilities and expectations
cannot be proven from the (more elementary) assumptions of Gleason's theorem
for two-dimensional Hilbert spaces by presently known mathematical methods, this
does not exclude the possibility that some other methods exist which would  prove similar results
related to value indefiniteness even for physical configurations with two
mutually exclusive outcomes.
For the sake of excluding this latter possibility, one should,
for instance, find a counterexample
(on the structure of quantum observables in two-dimensional Hilbert space)
which
(i) either is not in accordance with the Born rule but still
in accordance with the additivity property upon which Gleasons's theorem is based;
(ii) or is in accordance with the Born rule but allows
two-valued states which may or may not be sufficient for a homeomorphic embedding into a Boolean algebra.
A typical counterexample of the first type
would be one in which an electron spin observable,
for noncollinear directions, would always point ``up'' and ``down'' according to some algorithmic
rule~\cite[pp.~70-72]{svozil-ql}).
Formally, this is due to the fact that, for two-dimensional configurations, there exists a
full, separating set of two-valued states.
A counterexample of the second type appears to allow merely states which
are singular only in a {\em single} pair of observables (indeed, this is true for arbitrary Hilbert space dimensions), and thus are insufficient for the particular purpose.


In \cite{2008-cal-svo} it is proved that quantum randomness is not Turing computable.
More precisely, assume that a quantum experiment producing an infinite sequence of quantum random bits.
Is the sequence computable by a Turing machine?
If we accept value indefiniteness as expressed by Kochen-Specker theorem,
then the answer given in \cite{2008-cal-svo} is negative;
even more, {\it no Turing machine can enumerate an infinity of correct bits of such a sequence}.

But, is quantum randomness a ``true'' and ``objective'' form of randomness?
First, and foremost, there is no such thing as ``true'' randomness as measure-theoretical arguments show,
see \cite{calude:02}.
Secondly, it is an open question  whether quantum randomness satisfies the
requirements of algorithmic randomness \cite{calude:02}.
%\marginpar{started cris}

{\it Our aim is to experimentally study the possibility of distinguishing between sources of computable and incomputable ``randomness.''}\footnote{We are not concerned with any practical applicability of the outputs of studied sources.}  We performed
tests of randomness on pseudo-random strings (finite sequences) of length $2^{32}$ generated with software
(Mathematica, Maple, AES) which are not only incomputable, but also cyclic, the bits of $\pi$, which are computable, but not cyclic, and strings which are prefixes infinite incomputable sequences generated by quantum measurements  (using the commercial device Quantis and produced by the Vienna IQOQI group).

Our empirical tests  indicate quantitative differences between computable
and incomputable sources.

%\marginpar{official name?}


It is important to emphasise that our aim is to find tests that can  distinguish computable from incomputable sources by examining (long, but) finite prefixes of infinite sequences. Such differences are guaranteed to exist, but, because computability is an asymptotic property there is no guarantee that
finite tests can ``pick'' them. We used more tests than those described below, but discarded
those for which the results are inconclusive.

Since all classical statistical randomness tests (e.g.,  \cite{Rukhin-nist})
 do not differentiate the quality of randomness in these sequences we designed
a battery of randomness tests based on coding theory
algorithmic information theory results~\cite{calude:02}.
%http://modp.com/release/nist800-22/

\if 01
Fig.~\ref{2009-QvPR} depicts one of the most compact forms of proofs of the
Kochen-Specker theorem available today.

\begin{figure}
\begin{center}
%TeXCAD Picture [4.pic]. Options:
%\grade{\on}
%\emlines{\off}
%\epic{\off}
%\beziermacro{\on}
%\reduce{\on}
%\snapping{\off}
%\quality{8.00}
%\graddiff{0.01}
%\snapasp{1}
%\zoom{5.6569}
\unitlength 0.5mm % = 2.85pt
\allinethickness{2pt}%\linethickness{0.8pt}
\ifx\plotpoint\undefined\newsavebox{\plotpoint}\fi % GNUPLOT compatibility
\begin{picture}(134.09,125.99)(0,0)
%\emline(86.39,101.96)(111.39,58.46)
\multiput(86.39,101.96)(.119617225,-.208133971){209}{{\color{green}\line(0,-1){.208133971}}}
%\end
%\emline(86.39,14.96)(111.39,58.46)
\multiput(86.39,14.96)(.119617225,.208133971){209}{{\color{red}\line(0,1){.208133971}}}
%\end
%\emline(36.47,101.96)(11.47,58.46)
\multiput(36.47,101.96)(-.119617225,-.208133971){209}{{\color{brown}\line(0,-1){.208133971}}}
%\end
%\emline(36.47,14.96)(11.47,58.46)
\multiput(36.47,14.96)(-.119617225,.208133971){209}{{\color{pink}\line(0,1){.208133971}}}
%\end
\color{blue}\put(86.39,15.21){\color{blue}\line(-1,0){50}}
\put(86.39,101.71){\color{violet}\line(-1,0){50}}
%
\put(36.34,15.16){\color{pink}\circle{6}}
\put(36.34,15.16){\color{blue}\circle{4}}
\put(52.99,15.16){\color{blue}\circle{4}}
\put(52.99,15.16){\color{cyan}\circle{6}}
\put(69.68,15.16){\color{blue}\circle{4}}
\put(69.68,15.16){\color{orange}\circle{6}}
\put(86.28,15.16){\color{blue}\circle{4}}
\put(86.28,15.16){\color{red}\circle{6}}
%
\put(93.53,27.71){\color{red}\circle{4}}
\put(93.53,27.71){\color{orange}\circle{6}}
\put(102.37,43.44){\color{red}\circle{4}}
\put(102.37,43.44){\color{olive}\circle{6}}
\put(111.21,58.45){\color{red}\circle{4}}
\color{green}\put(111.21,58.45){\circle{6}}
%
\put(102.37,73.47){\color{green}\circle{4}}
\put(102.37,73.47){\color{olive}\circle{6}}
\put(93.53,89.21){\color{green}\circle{4}}
\put(93.53,89.21){\color{cyan}\circle{6}}
\put(86.28,101.76){\color{green}\circle{4}}
\put(86.28,101.76){\color{violet}\circle{6}}
%
\put(69.68,101.76){\color{violet}\circle{4}}
\put(69.68,101.76){\color{cyan}\circle{6}}
\put(52.99,101.76){\color{violet}\circle{4}}
\put(52.99,101.76){\color{orange}\circle{6}}
\put(36.34,101.76){\color{violet}\circle{4}}
\put(36.34,101.76){\color{brown}\circle{6}}
%
\put(29.24,89.21){\color{brown}\circle{4}}
\put(29.24,89.21){\color{orange}\circle{6}}
\put(20.4,73.47){\color{brown}\circle{4}}
\put(20.4,73.47){\color{olive}\circle{6}}
\put(11.56,58.45){\color{brown}\circle{4}}
\put(11.56,58.45){\color{pink}\circle{6}}

\put(20.4,43.44){\color{pink}\circle{4}}
\put(20.4,43.44){\color{olive}\circle{6}}
\put(29.24,27.71){\color{pink}\circle{4}}
\put(29.24,27.71){\color{cyan}\circle{6}}

\color{cyan}
\qbezier(29.2,27.73)(23.55,-5.86)(52.99,15.24)
\qbezier(29.2,27.88)(36.93,75)(69.63,101.91)
\qbezier(52.69,15.24)(87.47,40.96)(93.72,89.27)
\qbezier(93.72,89.27)(98.4,125.99)(69.49,102.06)
\color{orange}
\qbezier(93.57,27.73)(99.22,-5.86)(69.78,15.24)
\qbezier(93.57,27.88)(85.84,75)(53.13,101.91)
\qbezier(70.08,15.24)(35.3,40.96)(29.05,89.27)
\qbezier(29.05,89.27)(24.37,125.99)(53.28,102.06)
\color{olive}
\qbezier(20.15,73.72)(-11.67,58.52)(20.15,43.31)
\qbezier(20.33,73.72)(61.34,93.16)(102.36,73.72)
\qbezier(102.36,73.72)(134.09,58.52)(102.53,43.31)
\qbezier(102.53,43.31)(60.99,23.43)(20.15,43.49)
{\color{black} \normalsize
\put(12.41,116.02){\makebox(0,0)[rc]{$(0,1,-1,0)$}}
\put(12.41,2.65){\makebox(0,0)[rc]{$(0,0,1,-1)$}}
\put(58.68,116.38){\makebox(0,0)[rc]{$(1,0,0,1)$}}
\put(58.68,2.3){\makebox(0,0)[rc]{$(1,-1,0,0)$}}
\put(115.93,116.2){\makebox(0,0)[lc]{$(-1,1,1,1)$}}
\put(115.93,2.48){\makebox(0,0)[lc]{$(1,1,1,1)$}}
\put(65.65,116.38){\makebox(0,0)[lc]{$(1,1,1,-1)$}}
\put(65.65,2.3){\makebox(0,0)[lc]{$(1,1,-1,-1)$}}
\put(108.24,94.22){\makebox(0,0)[lc]{$(1,1,-1,1)$}}
\put(17.45,94.22){\makebox(0,0)[rc]{$(0,1,1,0)$}}
\put(108.24,22.45){\makebox(0,0)[lc]{$(1,-1,1,-1)$}}
\put(16.45,22.45){\makebox(0,0)[rc]{$(0,0,1,1)$}}
\put(114.13,77.96){\makebox(0,0)[lc]{$(1,0,1,0)$}}
\put(8.55,77.96){\makebox(0,0)[rc]{$(0,0,0,1)$}}
\put(114.13,38.72){\makebox(0,0)[lc]{$(1,0,-1,0)$}}
\put(8.55,38.72){\makebox(0,0)[rc]{$(0,1,0,0)$}}
\put(120.92,57.98){\makebox(0,0)[lc]{$(0,1,0,-1)$}}
\put(1.77,57.98){\makebox(0,0)[rc]{$(1,0,0,0)$}}
}
\end{picture}
\end{center}
\caption{ \label{2009-QvPR}
Greechie orthogonality diagram of a ``short'' proof~\cite{cabello-96,cabello:210401} of the Kochen-Specker theorem
in four dimensions containing 18 propositions in 9 tightly interlinked contexts.
The graph cannot be coloured by the two colours red (associated with truth)
and green (associated with falsity) such that every context contains exactly one red and three green points.
For
in a table containing the points of the contexts as columns
and the enumeration of contexts as rows,
every red point occurs in exactly {\em two} contexts, and
there should be an {\em even} number of red points.
On the other hand, there are nine contexts involved; thus by the rules it follows that there
should be an {\em odd} number (nine) of red points in this table (exactly one per context).
}
\end{figure}
\fi

\section{Randomness tests}

\subsection{Data}
 Our data consist on 42 binary sample 'random' strings  of length
$2^{32}$: 10 pseudo-random strings  produced by Mathematica 6 \cite{MRG},
10 pseudo-random strings  produced by  Maple 11 \cite{MAPLE},  10 quantum random strings  generated with  Quantis \cite{Quantis}, 10 quantum random strings   generated by the Vienna IQOQI group \cite{Vienna}, 2 pseudo-random strings  generated with the AES algorithm
 \cite{MR1986943} (see \cite{DBLP:journals/tomacs/HellekalekW03} for an empirical analysis), and the
 first $2^{32}$ bits of the binary expansion of $\pi$. Our experiments have been uniformly performed on all these sample strings. The tests presented below can be grouped into four classes: a) Borel normality test,
b)  tests based on Shannon's information theory, c) tests  based on algorithmic information theory, d)
test based on random walks, e) tests based on coding theory.
All results  appear in Appendix~A.

\subsection{Borel normality tests}

Every random infinite sequence is Borel normal, i.e.\ it contains infinitely many instances of any binary string.
This property was transposed to  strings in \cite{DBLP:conf/dlt/Calude93}.


%We denote by  $N_{i}(x)$ the number
%of  occurrences of the letter $i\in \{0,1\}$ in the string $x$.
%A  string $x$ is called
% $\varepsilon${\bf -limiting} ($\varepsilon $ is a fixed positive real)
%if it satisfies the inequality ($|x|$ is the length of $x$ considered as a string over $\{0,1\}$):
%$| N_{i}(x)/|x| - 1/2| \leq \varepsilon$, for $i=1,2$.
Fix  an integer $m > 1$, consider the alphabet $B_{m} = \{0,1\}^{m}$ consisting of all binary strings of length $m$,
 and for
every $1 \leq i \leq 2^{m}$ denote by $N_{i}^{m}$ the
 number of occurrences of the lexicographical $i$th binary string of length $m$ in the string $x$ (considered over the alphabet $B_{m}$).
 By $|x|_{m}$ we denote the length of $x$.
 A string $x$ is Borel normal if
  for every natural $1 \leq m \leq \log_{2}\log_{2} |x|,
\left| \frac{N_{j}^{m}(x)}{|x|_{m}} -  2^{-m} \right| \leq
\sqrt\frac{\log_{2}|x|}{|x|},$
for every $1 \leq j \leq 2^{m}$. In \cite{DBLP:conf/dlt/Calude93} one shows that {\it almost all algorithmic random strings are Borel normal}.
\if01
In  test~1 we  determine the shortest prefix that contains all $n$-bit binary strings,
 non-overlapping. Each sample string is divided in block of length $n$, $1\le n \le 23$, and we count the minimal number of blocks containing all $2^{n}$ $n$-bit strings. The shorter the prefix (for each length) the more random is the
 string. The results are presented in the Table~\ref{table1}.


 Test~2  calculates the largest $n$ such that the prefix of length $n$ contains all $2^n$ substrings, non-overlapping. The larger the prefix (for each length) the more random is the sample
 string.  All sample strings contain all strings of length 27: differences appear for strings of lengths 28, 29, and 30.The results are presented in Table~\ref{table2}.
\fi


In test~1  %test~3
we  count the maximum, minimum and difference of all  $k$-bit strings appearing in
each sample string for  $k=1,\ldots , 5$.   Almost all strings passed the Borel normality tests with some notable exceptions as Table~\ref{table3} shows; this is also reflected in Figure~1.

\marginpar{comment about `over normality'.}

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=6in]{boxborelk2.pdf}
   \caption{BoxWhiskerPlot for average results in Table~\ref{table3}}
   \label{fig:example}
\end{figure}


%In test~4 we count the long string of  only zeroes (ones) in  each sample string.
%The expected result---32---is obtained for most sample strings. The
%results are presented in Table~\ref{table7}.

\if01

\subsection{Tests based on Compression} A few well-known compressors
zip/gzip/bzip2/7-zip have been used to compress the sample strings.
The smaller the  compressed version the more random is the sample
string. Surprisingly, all compressors failed to notice their
incapacity to compress the sample strings, so they return a string
longer than $2^{32}$ bits. The longer is the output produced by a
compressor the more random is the sample string. The results of test~5 are
presented in Table~\ref{table4}.

\fi



\subsection{Tests based on Shannon's information theory}

Test~2 %Test~6
computes  ``sliding window'' estimations of the Shannon entropy $L_n^1, \ldots ,L_n^t$ according to the method described in
\cite{Wyner}: a larger  entropy is a symptom of  more randomness. The results are presented in Table~\ref{table6} and Figure~2..

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=6in]{boxplotLentropy.pdf}
   \caption{BoxWhiskerPlot for average results in Table~\ref{table6}}
   \label{fig:example}
\end{figure}



Test~3 %Test~7
uses  the ``book stack'' (also known as ``move to front'') randomness
test as proposed in \cite{MR2099021,MR2162569} which is based on results
and ideas  coding theory.
%The test rejects the randomness hypothesis if the string can be compressed
%by a considered universal code asymptotically till the Shannon entropy per
%symbol.  More compression means less randomness.
The results, presented in
Table~\ref{table8} and Figure~3, show the original count, the count after the application
of the transformation and the difference.  The key metric for this test is
the count of ones after the transformation.  The book stack encoder does
not compress data but instead rewrites each byte with its index (from
the top/front) with respect to its input characters being
stacked/moved-to-front.
Thus, if a lot of repetitions occur (i.e., a symptom of
non-randomness), then the output  contains more zeros than ones due to
the sequence of indices generally being smaller numerically.

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=6in]{boxbookstack.pdf}
   \caption{BoxWhiskerPlot for average results in Table~\ref{table8}}
   \label{fig:example}
\end{figure}

\subsection{Tests based on algorithmic information theory}

Test~4 is   based solely on the behaviour of algorithmic random strings (as
selectors for Solovay-Strassen probabilistic primality test) and not on specific properties of randomness.

To test whether a positive integer
$n$ is prime, we take $k$ natural numbers uniformly distributed between 1
and $n - 1$, inclusive, and for each one $i$ check whether the predicate
$W (i, n)$ holds.  If this is the case we say that
``$i$ is a witness of $n$'s compositeness''.
If $W (i, n)$ holds for at least one $i$ then $n$ is
composite; otherwise, the test is inconclusive, but in this case if one declares $n$ to be  prime then the
 probability to be wrong is smaller than $ 2^{-k}$.

 The reason comes from the fact that
 at least half  $i$s from $1$ to $ n - 1$ satisfy $W (i, n)$  if $n$ is indeed composite,
 and {\it none} of them satisfy $W (i, n)$ if $n$ is prime, \cite{MR0466001}.  Selecting $k$ natural numbers  between 1
and $n - 1$ is the same as choosing a binary string $s$ of length $n-1$ with $k$ 1s such that the $i$th bit is 1 iff $i$ is selected.  In \cite{ch-schw-78} one proves that if $s$ is a long enough   algorithmically random binary string then $n$ is prime iff $Z(s,n)$ is true, where $Z$ is a predicate constructed directly from conjunctions of negations of  $W$.\footnote{In fact, every  ``decent'' Monte Carlo simulation algorithm in  which  tests are chosen according to an algorithmic random string produces the result
not only true with high probability, but {\it rigourously correct} \cite{MR757602}.}

A Carmichael number is a composite positive integer $k$ satisfying the congruence $b^{k-1} \equiv 1 ({\rm mod } \, k)$ for all integers $b$ relative prime to $k$. Carmichael numbers are composite, but are very close to primes; they are sometimes called pseudo-primes. Carmichael numbers can fool Fermat's primality test, but less the Solovay-Strassen test. Carmichael numbers exist,\footnote{There are 1,401,644 Carmichael numbers in the interval $[1, 10^{18}]$.}  but with growth they become rare.

Test~6  uses Solovay-Strassen probabilistic primality test for Carmichael numbers (composite) with prefixes of the sample strings as the binary string $s$. We used the Solovay-Strassen  test for all Carmichael numbers less than $10^{9}$---computed in \cite{Pinch}---with numbers selected according to increasing prefixes of each sample string till the algorithm returns
a non-primality verdict. The longer it takes to reach the correct
verdict the more non-random is the selection source. The results are
presented in Table~\ref{table5} and Figure~4.

\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=6in]{boxsolovey.pdf}
   \caption{BoxWhiskerPlot for average results in Table~\ref{table5}}
   \label{fig:example}
\end{figure}

\subsection{Test based on random walks}

A string is  `more random' if the plot generated by viewing a sample sequence as
a 1D random walk meanders farther away
from the starting point (both ways); hence the max-min range is the metric.

Test~5 %Test~9
is based on viewing a  random
sequence as a 1D random walk.  Here the bits (indices along the $x$-axis) are
interpreted as follows: 1=move up, 0=move down ($y$-axis).
This test measures  how far away from the starting point (in either positive
or negative) from the starting $y$-value of 0 one can reach using successive bits
of the sample sequence
to move up or down.  Table~\ref{table9} and Figure~5 summarise the results.

\footnote{???
 Quantum random sources (both Vienna and Quantis) seem to
move farther away from the starting point than the pseudo-generators.
The other extreme is the AES and Mathematica sources which seem to
be  ``human-designed''  to locally balance the number of zeros and ones.

Open questions: Is there any statistical evidence of these groupings?
Or is the average of 10 sequences not enough to conclude anything?
The differences in ranges of these initial tests seem quite big.}


\begin{figure}[htbp] %  figure placement: here, top, bottom, or page
   \centering
   \includegraphics[width=6in]{boxrandomwalk.pdf}
   \caption{BoxWhiskerPlot for average results in Table~\ref{table9}}
   \label{fig:example}
\end{figure}

All programs are presented in Appendix B.
\bibliography{svozil}
\bibliographystyle{osa}

\newpage
\appendix

\section{Summary tables of tests}

\def\inputGnumericTable{11} % with headings
%\def\inputGnumericTable{10} % no headings
%
\if\inputGnumericTable\newcommand{\texbf}[1]{\textbf{#1}}
\else\newcommand{\texbf}[1]{---}\fi

%\input{table1.tex} \newpage
%\input{table2.tex} \newpage
\input{table3.tex} \newpage
%\input{table7.tex} \clearpage

%\input{table4.tex} \newpage
\input{table6.tex} \newpage
\input{table8.tex}\newpage
\input{table5.tex}\newpage
\input{table9.tex}

\clearpage
\section{Test programs}

%\includegraphics[width=7in]{test1.pdf} \newpage
%\includegraphics[width=7in]{test2.pdf} \newpage
\includegraphics[width=7in]{test3.pdf} \newpage
\includegraphics[width=5.2in]{test5a.pdf} \\ %\newpage
\hspace*{4ex}\includegraphics[width=5.1in]{test5b.pdf} \newpage
\includegraphics[width=6.5in]{test5c.pdf} \newpage
%\includegraphics[width=7in]{test6.pdf} \newpage
%\includegraphics[width=7in]{test7} \newpage
\includegraphics[width=7in]{test8_mtf.pdf}
\includegraphics[width=6.5in]{test9.pdf}
\end{document}

