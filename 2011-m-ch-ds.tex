\chapter{Divergent series}
\index{divergent series}
\label{2011-m-ch-ds}
In this final chapter we will consider {\em divergent series}, which,
as has already been mentioned earlier,
seem to have been ``invented by the devil'' \cite{Hardy:1949}.
Unfortunately such series occur
very often in physical situation;
for instance in celestial mechanics or in quantum field theory,
and one may wonder with Abel why, {\em ``for the most part,
it is true that the results are correct, which is very strange''  }
\cite{rousseau-2004}.

\section{Convergence and divergence}
Let us first define {\em convergence} in the context of series.
\index{convergence}
A series
\begin{equation}
\sum_{j=0}^\infty a_j =a_0+a_1+a_2+\cdots
\end{equation}
is said to converge to the {\em sum}
$s$, if the {\em partial sum}
\begin{equation}
s_n=  \sum_{j=0}^n a_j =a_0+a_1+a_2+\cdots + a_n
\end{equation}
tends to a finite limit $s$ when $n\rightarrow \infty$;
otherwise it is said to be divergent.
\index{divergence}

One of the most prominent series is the Leibniz series~\cite{leibnitz-1860,moore-1938,Hardy:1949,everest-2003}
\begin{equation}
s = \sum_{j=0}^\infty (-1)^j=1-1+1-1+1-\cdots ,
\label{2009-fiftyfifty-1s}
\end{equation}
which is a particular case $q=-1$ of a {\em geometric series}
\index{geometric series}
\begin{equation}
s = \sum_{j=0}^\infty q^j=1+q+q^2+q^3+ \cdots  =1+q s
\label{2009-fiftyfifty-1sgs}
\end{equation}
which, since $s=1+qs$, converges  to $s=1/(1-q)$ if $\vert q\vert <1$.
Another one is
\begin{equation}
s = \sum_{j=0}^\infty (-1)^{j+1} j =1-2+3-4+5-\cdots =
\left(\sum_{j=0}^\infty (-1)^j\right)
\left(\sum_{k=0}^\infty (-1)^k\right)
,
\label{2009-fiftyfifty-1s1}
\end{equation}
which, in the same sense as the Leibnitz series is $1/[1-(-1)]=1/2$, sums up to $1/4$.

\section{Euler differential equation}
\index{Euler differential equation}

In what follows we demonstrate that divergent series may make sense, in the way Abel
wondered.
That is, we shall show that the first partial sums of divergent series
may yield ``good'' approximations of the exact result; and
that, from a certain point onward, more terms contributing to the
sum  might worsen the approximation rather an make it better -- a situation totally different
from convergent series, where more terms always result in better approximations.

Let us, with Rousseau,
for the sake of demonstration of the former situation,
consider the {\em Euler differential equation}
\index{Euler differential equation}
\begin{equation}
\begin{array}{l}
\left(x^2 \frac{d}{dx} +1\right) y(x) = {x}\textrm{, or}
\left(\frac{d}{dx} +\frac{1}{x^2}\right) y(x) = \frac{1}{x}.
\end{array}
\label{2011-m-ch-dsee}
\end{equation}

We shall solve this equation by two methods:  we shall, on the one hand,
present a divergent series solution, and on the other hand, an exact solution.
Then we shall  compare the series approximation to the exact solution by considering
the difference.

A series solution of the Euler differential equation can be given by
\begin{equation}
{y_s} (x) = \sum_{j=0}^\infty (-1)^j j! x^{j+1}.
\label{2011-m-ch-dseess}
\end{equation}
That (\ref{2011-m-ch-dseess})
solves  (\ref{2011-m-ch-dsee})
can be seen by inserting the former into the latter; that is,
\begin{equation}
\begin{array}{l}
\left(x^2 \frac{d}{dx} +1\right) \sum_{j=0}^\infty (-1)^j j! x^{j+1} = {x},  \\
\sum_{j=0}^\infty (-1)^j (j+1)! x^{j+2} + \sum_{j=0}^\infty (-1)^j j! x^{j+1} = {x},  \\
\qquad \textrm{[change of variable in the first sum: } j \rightarrow j-1\textrm{ ]}\\
\sum_{j=1}^\infty (-1)^{j-1} (j+1-1)! x^{j+2-1} + \sum_{j=0}^\infty (-1)^j j! x^{j+1} = {x},  \\
\sum_{j=1}^\infty (-1)^{j-1} j! x^{j+1} + x +\sum_{j=1}^\infty (-1)^j j! x^{j+1} = {x},  \\
x +\sum_{j=1}^\infty (-1)^j\left[(-1)^{-1} +1\right] j! x^{j+1}    = {x},  \\
x +\sum_{j=1}^\infty (-1)^j\left[ -1  +1\right] j! x^{j+1}    = {x},  \\
x    = {x}.  \\
\end{array}
\label{2011-m-ch-dsee111}
\end{equation}


On the other hand, an exact solution can be found by {\em quadrature;}
that is, by explicit integration (see, for instance, Chapter one of Ref. \cite{birkhoff-Rota-48}).
Consider the homogenuous first order differential equation
\begin{equation}
\begin{array}{l}
\left(\frac{d}{dx} + p(x)  \right)  y(x)=0\textrm{, or}
\frac{dy(x)}{dx} = - p(x)   y(x) \textrm{, or}
\frac{dy(x)}{ y(x) } = - p(x) dx .
\end{array}
\label{2011-m-ch-dseeqsh}
\end{equation}
Integrating both sides yields
\begin{equation}
\begin{array}{l}
\log \vert y(x)\vert =  - \int p(x) dx +C \textrm{, or}
\vert y(x)\vert =K e^{- \int p(x) dx},
\end{array}
\label{2011-m-ch-dseedi}
\end{equation}
where $C$ is some constant, and $K=e^C$.
Let $P(x)={ \int p(x) dx}$. Hence, heuristically,
$y(x)e^{P(x)}$ is constant, as can also be seen by explicit differentiation of $y(x)e^{P(x)}$; that is,
\begin{equation}
\begin{array}{l}
\frac{d}{dx}y(x)e^{P(x)}
=  e^{P(x)}\frac{dy(x)}{dx}   +  y(x)\frac{d}{dx} e^{P(x)}\\
\qquad =
e^{P(x)}\frac{dy(x)}{dx}   +  y(x)  p(x) e^{P(x)}\\
\qquad =
e^{P(x)}\left(\frac{d}{dx}   +   p(x) \right)y(x)\\
\qquad = 0
\end{array}
\label{2011-m-ch-dseeed}
\end{equation}
if and, since $ e^{P(x)}\neq 0$,
only if $y(x)$ satisfies the homogenuous equation  (\ref{2011-m-ch-dseeqsh}).
Hence,
\begin{equation}
\begin{array}{l}
y(x)  =c e^{- \int p(x) dx} \textrm { is the solution of}\\
\left(\frac{d}{dx} + p(x)  \right)  y(x)=0
\end{array}
\label{2011-m-ch-dseesoh}
\end{equation}
for some constant $c$.



Similarly, we can again find a solution to the inhomogenuos  first order differential equation
\begin{equation}
\begin{array}{l}
\left(\frac{d}{dx} + p(x)  \right)  y(x)+ q(x)=0\textrm{, or}      \\
\left(\frac{d }{dx}  + p(x) \right)   y(x)= - q(x)
\end{array}
\label{2011-m-ch-dseeinh}
\end{equation}
by differentiating the function $y(x)e^{P(x)}=y(x)e^{ \int p(x) dx}$;
that is,
\begin{equation}
\begin{array}{l}
\frac{d }{dx}   y(x)e^{  \int p(x) dx} =
e^{  \int p(x) dx}\frac{d }{dx}   y(x) + p(x) e^{ \int p(x) dx}  y(x) \\
\qquad
=  e^{  \int p(x) dx}\left(\frac{d }{dx}    + p(x) \right)   y(x)
\qquad    - e^{  \int p(x) dx} q(x).
\end{array}
\label{2011-m-ch-dsee1213}
\end{equation}
Hence, for some constant $y_0$ and some $a$,
we must have, by integration,
\begin{equation}
\begin{array}{l}
y(x)e^{  \int_a^x p(t) dt} = y_0 -  \int_a^x e^{ \int_a^t p(s) ds }q(t) dt\textrm{, and whence}\\
y(x)= y_0e^{ - \int_a^x p(t) dt}  -  e^{ - \int_a^x p(t) dt} \int_a^x e^{ \int_a^t p(s) ds} q(t) dt,
\end{array}
\label{2011-m-ch-dseekh}
\end{equation}
with $y(a)= y_0$.

Coming back to the Euler differential equation and identifying
$p(x)=1/x^2$ and $q(x) = - 1/x$ we obtain, up to a constant,
\begin{equation}
\begin{array}{l}
y(x)=    -  e^{ - \int_0^x \frac{ dt}{t^2}} \int_0^x e^{ \int_0^t \frac{ ds}{s^2}} \left(-\frac{ 1}{t}\right) dt
\\ \qquad =
     e^{   \frac{1}{x}} \int_0^x  \frac{ e^{ - \frac{1}{t}}}{t} dt
\\ \qquad =
e^{   } \int_0^x  \frac{ e^{ \frac{1}{x} -\frac{1}{t}}}{t} dt.
\end{array}
\label{2011-m-ch-dseeeesola}
\end{equation}
With the change of coordinate {\it Ansatz}
\begin{equation}
\begin{array}{l}
\xi = \frac{x}{z}-1
, \;
z =  \frac{x}{1+ \xi}
, \;
dz =  -\frac{x}{(1+ \xi)^2} d\xi
\end{array}
\label{2011-m-ch-dseeans}
\end{equation}
the integral (\ref{2011-m-ch-dseeeesola}) can be rewritten as
\begin{equation}
y(x)= \int_0^\infty
\frac{e^{-\frac{\xi}{x}}}{1+\xi} d\xi .
\label{2011-m-ch-dseefasol}
\end{equation}

Note that whereas the series solution $y_s(x)$ diverges for all nonzero $x$,
the solution $y(x)$ in (\ref{2011-m-ch-dseefasol})
converges and is well defined for all $x\ge 0$.

Let us now estimate the absolute difference between $y_{s_k}(x)$
which represents  ``$y_s((x)$ truncated
after the $k$th term'' and $y(x)$; that is, let us consider
\begin{equation}
\begin{array}{l}
\vert y(x) - y_{s_k}(x) \vert=
\left\vert \int_0^\infty
\frac{e^{-\frac{\xi}{x}}}{1+\xi} d\xi
-
\sum_{j=0}^k (-1)^j j! x^{j+1} \right\vert .
\end{array}
\label{2011-m-ch-dseeanest}
\end{equation}

It can be shown \cite{rousseau-2004}
that, for any $x\ge 0$ this difference can be estimated by  a bound from above
\begin{equation}
\begin{array}{l}
\vert y(x) - y_{s_k}(x) \vert
\le
k! x^{k+1}.
\end{array}
\label{2011-m-ch-dseeest}
\end{equation}

{\color{OliveGreen}
\bproof

For a proof, observe that,
since
\begin{equation}
\begin{array}{l}
\sum_{k=0}^n a_k =a_0 {1-r^{n+1}\over 1-r} =a_0 r{1-r^{n}\over 1-r}
\end{array}
\label{2011-m-ch-dsee12}
\end{equation}
it is true that
\begin{equation}
\begin{array}{l}
\frac{1}{1-\zeta}=\sum_k=0^{n-1} (-1)^k \zeta^k + (-1)^n \frac{\zeta^n}{1+\zeta}.
\end{array}
\label{2011-m-ch-dsee13}
\end{equation}
Thus
\begin{equation}
\begin{array}{l}
f(x) =\int_0^\infty \frac{e^{-\frac{\zeta}{x}}}{1-\zeta}d\zeta \\
\qquad =
\int_0^\infty  e^{-\frac{\zeta}{x}}\left(
\sum_k=0^{n-1} (-1)^k \zeta^k + (-1)^n \frac{\zeta^n}{1+\zeta}
\right)
d\zeta \\
\qquad =
\sum_k=0^{n-1}\int_0^\infty (-1)^k \zeta^k  e^{-\frac{\zeta}{x}}   d\zeta
 +
\int_0^\infty (-1)^n \frac{\zeta^ne^{-\frac{\zeta}{x}}}{1+\zeta}
d\zeta  .
\end{array}
\label{2011-m-ch-dsee14}
\end{equation}
Since
\begin{equation}
k!= \Gamma(k+1)=    \int_0^\infty z^k e^{-k} dz,
\label{2011-m-ch-dsee15}
\end{equation}
one obtains
\begin{equation}
\begin{array}{l}
\int_0^\infty  \zeta^k  e^{-\frac{\zeta}{x}}   d\zeta     \\
\qquad \textrm{[substitution:  }z=\frac{\zeta}{x}, d \zeta =x dz  \textrm{ ]  } \\
\qquad = \int_0^\infty x^{k+1} z^k  e^{-z}   dz
\\
\qquad =  x^{k+1} k! ,
\end{array}
\label{2011-m-ch-dsee16}
\end{equation}
and hence
\begin{equation}
\begin{array}{l}
f(x)  =
\sum_k=0^{n-1}\int_0^\infty (-1)^k \zeta^k  e^{-\frac{\zeta}{x}}   d\zeta
 +
\int_0^\infty (-1)^n \frac{\zeta^ne^{-\frac{\zeta}{x}}}{1+\zeta}
d\zeta  \\
\qquad =
\sum_k=0^{n-1}  (-1)^k x^{k+1} k!
 +
\int_0^\infty (-1)^n \frac{\zeta^ne^{-\frac{\zeta}{x}}}{1+\zeta}
d\zeta  \\
\qquad =
f_n(x)  +R_n(x),
\end{array}
\label{2011-m-ch-dsee17}
\end{equation}
where $f_n(x)$ represents the partial sum of the power series, and $R_n(x)$ stands for the remainder,
the difference between $f(x)$ and $f_n(x)$.
The absolute of the remainder can be estimated by
\begin{equation}
\begin{array}{l}
\vert R_n(x)\vert
=
\int_0^\infty  \frac{\zeta^n e^{-\frac{\zeta}{x}}}{1+\zeta}\\
\qquad \le
\int_0^\infty  \zeta^n e^{-\frac{\zeta}{x}} \\
\qquad = n! x^{n+1}.
\end{array}
\label{2011-m-ch-dsee18}
\end{equation}
As a result, the remainder grows with growing number of terms contributing to the sum;
a characterisztic feature of divergent series (for convergent series, the remainder decreases).

\eproof
}

\begin{center}
{\color{olive}   \Huge
%\decofourright
 %\decofourright
%\decofourleft
%\aldine X \decoone c
 \floweroneright
% \aldineleft ]
% \decosix
%\leafleft
% \aldineright  w  \decothreeleft f \leafNE
% \aldinesmall Z \decothreeright h \leafright
% \decofourleft a \decotwo d \starredbullet
%\decofourright
% \floweroneleft
}
\end{center}
