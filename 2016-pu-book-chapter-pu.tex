%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{On what is entirely hopeless}
\label{2016-pu-book-chapter-pu} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

According to his own narrative, the
Baron M\"unchhausen pulled himself (and his horse) out of a mire by his own hair~\cite[Chapter~4]{Buerger-Muenchhausen}. (This story is not contained in
Raspe's earlier collections~\cite{raspe-1877}).
In the following we shall be concerned with the question exactly why it is entirely hopeless to pursue the strategy
suggested by the Baron M\"unchhausen; and why should one be concerned about this.
More generally, is it (im)plausible to attempt to reach out into some external domain with purely intrinsic means;
that is, by operational (from the point of view of intrinsic, embedded observers) capacities
and means which cannot include any ``extrinsic handle,'' or Archimedean point?

Most likely everyone pursuing that kind of strategy -- with the sole exception of the Baron M\"unchhausen  -- has drowned.
But maybe something general can be learned from this flawed attempt of self-empowerment?
And M\"unchhausen's vain attempt to lift himself entirely (and not only parts of himself, such as his hair
)
indicates that some internal means -- tactics which rely entirely on operations referring to, and movements within himself,
with rare exceptions\footnote{
Interesting though that if, instead of on a horse, M\"unchhausen would have ridden a loaded cannon, then by firing the cannon ball towards the ground might have helped.
} --
are useless.

Epistemic issues resembling this metaphor have been called
{\em M\"unchhausen trilemma}
\index{M\"unchhausen trilemma}:
as Albert has pointed out that, {\em ``if one wants a justification for {\em everything}, then one must also require a justification
for those findings and premises which one has used to derive and justify the
respective reasoning -- or the relevant statements.''}\footnote{
German original~\cite[Chapter~2, p.~15]{albert-traktat-68}: {\em ``Wenn man f\"ur {\em alles} eine Begr\"undung verlangt, muss man auch
f\"ur die Erkenntnisse, auf die man jeweils die zu begr\"undende Auffassung -- bzw. die betreffende Aussagen-Menge --
zur\"uck gef\"uhrt hat, wieder eine Begr\"undung verlangen.''}}
% https://en.wikipedia.org/wiki/Hans_Albert
% https://books.google.de/books?id=RlDjHpWPg1QC&pg=PR3&hl=de&source=gbs_selected_pages&cad=2#v=onepage&q=M%C3%BCnchhausen&f=false

With regards to the {trilemma} there seem to be only three alternatives or attempts of resolutions:  either
(i) an infinite regress in which each proof requires a further proof, {\it ad infinitum}; or
(ii) circularity in which theory and proof support each other; very much like the {\em ouroboros} symbol,
\index{ouroboros}
 serpent or dragon eating its own tail; or
(iii) a termination of justification at an arbitrary point of settlement by the introduction of axioms.

When compared with the original goal of omni-justification of everything all three alternatives  appear not very satisfactory.
% https://en.wikipedia.org/wiki/M%C3%BCnchhausen_trilemma
This is well in line with ancient scepticism, and Albert's three ``resolutions'' of the M\"unchhausen trilemma
can be related to the {\em tropes}
\index{trope}
or {\em Five Modes}
\index{Five Modes}
enumerated by Sextus Empiricus, in his {\em Outlines of Pyrrhonism}.
These are in turn attributed to Diogenes Laertius and ultimately to Agrippa.
These tropes are~\cite{sep-skepticism-ancient}
(i) dissent and  disagreement of conflicting arguments, such that conflict cannot be decided;  as well as uncertainty about arguments;
(ii) infinite regress ;
(iii) mean and relation dependence, relativity of arguments;
(iv) assumption about the truth of axioms without providing argument; as well as
(v) circularity - The truth asserted involves a vicious circle.

% https://en.wikipedia.org/wiki/Agrippa_the_Skeptic


If one pursues the axiomatic approach --
by holding to some (at least preliminary)
{\em theory of everything},
then what can and what cannot be expressed and formally proven is (means) relatives to the assumptions and axioms and derivation rules made.
Once a formal framework is fixed, this framework constitutes a universe of expressions.
If such a framework is ``strong'' or ``sophisticated enough'' it includes self-expressibility by its capacity to encode the terms occurring within it,
and by substituting and applying these terms into functions which themselves are encodable.
While there is nothing wrong with self-expressibility
-- actually it has been argued in Chapter~\ref{2016-pu-book-chapter-eo} that physics is bound to reflexivity --
some conceivable expressions are paradoxical, and need to be excluded for ``security reasons;'' in particular,
to avoid contradictions.
This results in provable limits to self-expressibility,
limits which are even quantifiable~\cite{chaitin-ACM,Chaitin199283}.

This is very different from revelations about numbers, such as Srinivasa Ramanujan's inspirations.
In such cases, no bounds to expressibility can be given.
Indeed, expressibility by intuition may be unlimited.
It cannot be ruled out that some agents, such as human minds, have a more direct access to truth than, say, an automated proof system.

But trusting such claims is very problematic.
The claims are not correct with respect to any axioms and derivation rules which one might have agreed upon as being valid,
and therefore cannot be checked and found (in-)correct relative to the latter.

Of course, one might say, that ultimately there has to be trust involved.
Because also in the traditional, axiomatic ways, the axioms and derivation rules have to be trusted.
(Ramsey theory might be an exception.)




\chapter{Forecasting and unpredictability}
\label{2016-pu-book-chapter-up}

While -- depending on one's subjective optimism or pessimism often, sometimes or rarely -- it is possible to predict the future,
certain forecasting tasks, in particular, when it comes to self-reference, are provable unattainable, and will remain so forever.
Why? Because some forecasting tasks would result in the following situation, frugally explained by
Aaronson~\cite{aaronson-blog}
{\em ``Turing imagined that there was a special machine that could solve the Halting Problem.
Then he showed how we could have this machine analyse itself,
in such a way that it has to halt if it runs forever, and run forever if it halts.
Like a hound that finally catches its tail and devours itself, the mythical machine vanishes in a fury of contradiction.
(That's the sort of thing you don't say in a research paper.)''}

\section{Reduction from logical incompleteness}
\label{2016-pu-book-chapter-up-red}

Given two problems A and B. Let us say that if ``a reduction from problem A (in)to problem B'' exists
\index{reduction}
(or ``problem A is reducible to problem B'')  then the
solution to problem B can be used to solve problem A. Indeed,
one may think of B as some ``oracle'' or ``subroutine''
which can be used to solve A.
Thereby, reduction from A into B is an algorithm for transforming problem A into another problem B.
Therefore, when problem A is reducible to problem B, then a solution of problem A cannot be
harder than a solution to problem B, since a solution to B
provides a solution to A.
Hence, a reduction from  problem A to another problem B
can be used to show that problem B is at least as difficult as problem A.


More specifically, reduction (aka ``algorithmic translation'') from some unsolvable problem A (in particular, the halting problem)
to problem B means
the demonstration that the problem B in question
is unsolvable by showing that the unsolvable problem A (in particular, the halting problem) can
be reduced to it:
that is,  by showing that if we could compute a solution to problem B
in question, we could use this solution to get a computable method for solving the
unsolvable problem A (in particular, the halting problem)~\cite[\S~2.1, pp.~34]{rogers1}.
But there cannot exist such a computable method of solving A.
Therefore problem B must be unsolvable as well.


In what follows we shall follow previous reviews  of that subject~\cite{svozil-93,svozil-07-physical_unknowables};
mostly in the context of classical mechanics.
Thereby the standard method is a reduction
from  some form of recursion theoretic incompleteness (in particular, the halting problem)
into some physical entity or decision problem.
Here the term {\em reduction} also refers to the method
to link physical undecidability by reducing it to logical undecidability.
Logical undecidability, in turn, can be related to ancient
antinomies -- for instance ``the liar:''  already the
Bible's Epistle to Titus 1:12, states that
{\em ``one of Crete's own prophets has said it: `Cretans are always liars, evil brutes, lazy gluttons.' He has surely told the truth.''} --
as well as antinomies plaguing Cantor's naive set theory.


A typical example for this strategy is the embedding of a Turing machine, or any type of computer capable of
universal computation, into a physical system.
As a consequence, the physical system inherits
any type of unsolvability derivable for universal computers such as the
unsolvability of the halting problem:
because the computer or recursive agent is embedded within that physical system,
so are its behavioural patterns.

Refs.~\cite{wolfram84,kanter,moore,wolfram85b,dc-d91a,dc-d91b,suppes-1993,svozil-93,1994IJTP...33.1085H,casti:94-onlimits_book,casti:96-onlimits,barrow-impossibilities,Eisert-PhysRevLett.108.260501,cubit-15,cubit-15-marketing}.
contain concrete examples.
The author used a similar reduction technique in the context of a universal ballistic computational model to argue that
the {\em $n$-body problem}~\cite{weierstrass-1885,poincare14,Diacu96-ce}
\index{n-body problem}
may perform in an undecidable manner; that is, some observables may not be computable.
Consequently, the associated series solutions~\cite{Sundman12,Wang91,Wang01} might not have computable rates of convergence; just like Chaitin's $\Omega$~\cite{s00032-006-0064-2,chaitin3,rtx100200236p}, the
halting probability for prefix-free algorithms on universal computers~\cite{2002-glimpseofran,calude-dinneen06}.


Of course, at some point this method or metaphor becomes problematic, as universal computation
requires  the arbitrary allocation of time and -- depending of the computational model -- computational and/or memory) space;
that is,  a potentially infinite totality.
This is never achievable in realistic physical situations~\cite{bridgman52,bridgman36,bridgman,gandy1,gandy2}.


\section{Determinism does not imply predictability}
\label{2016-pu-book-chapter-up-dnip}

One immediate consequence of reduction is the fact that,
at least for sufficiently complex systems allowing the implementation of Peano arithmetic or universal computation,
determinism does not imply predictability~\cite{suppes-1993,svozil-93}.
This may sound counterintuitive at first but is quite easy to understand in terms of
the behaviour, the temporal evolution or phenomenology of a device or subsystem capable of universal computation.

Let us, for the sake of a more explicit (but not formal and in a rather algorithmic way) demonstration what could happen,
consider a supposedly and hypothetically {\em universal predictor}.
We shall, by a {\em  proof by contradiction}
\index{proof by contradiction}
show, that the assumption of such a universal predictor (and some ``innocent'' side constructions)
yields a complete contradiction.
Therefore, if we require consistency, our only consolation -- or rather our sole option -- is
to abandon the assumption of the existence of a universal predictor.

\subsection{Unsolvability of the halting problem}
\index{halting problem}

The scheme of the proof by contradiction is as follows:
the existence of a hypothetical halting algorithm
capable of solving universal prediction will be {\em assumed.}
More specifically, it will be (wrongly) assumed that
a ``universal predictor'' exists which can forecast whether or not any particular program halts on any particular input.
This could, for instance, be a subprogram of some suspicious super-duper macro library
that takes the code of an arbitrary program as input and outputs 1 or 0,
depending on whether or not the respective program halts.
One may also think of it as a sort of oracle or black box analysing an arbitrary
program in terms of its symbolic code and outputting one of two symbolic states, say, 1 or 0,
referring to termination or nontermination of the input program, respectively.

On the basis of this {\em hypothetical halting algorithm}
one constructs another {\em diagonalization program} as follows:
on receiving some arbitrary {\em input program} code (including its input code) as input, the {diagonalization program}
consults the {\em hypothetical halting algorithm} to find out whether or not this
{input program} halts.  Upon receiving the answer, it does the exact {\em opposite} consecutively:
If  the   hypothetical halting algorithm  decides that the   input program  {\em halts,}
the   diagonalization program  does {\em not halt} (it may do so easily by entering an infinite loop).
Alternatively, if  the   hypothetical halting algorithm  decides that the  input program  does {\em not halt,}
the {diagonalization program} will {\em halt} immediately.

The {diagonalization program} can be forced to execute a paradoxical task by
receiving {\em its own program code} as input.
This is so because, by considering the {diagonalization program,}
the {hypothetical halting algorithm} steers the {diagonalization program} into
{\em halting} if it discovers that it {\em does not halt;}
conversely,  the {hypothetical halting algorithm} steers the {diagonalization program} into
{\em not halting} if it discovers that it {\em halts.}


The contradiction obtained in applying the {diagonalization program} to its own code proves that this program
and, in particular, the {hypothetical halting algorithm} as the single and foremost nontrivial step in the execution, cannot exist.
A slightly revised form of the proof using quantum diagonalization operators
holds for quantum diagonalization \cite{1612095},
as quantum information could be in a fifty-fifty fixed-point halting state.
Procedurally, in the absence of any fixed-point halting state,
the aforementioned task might turn into a nonterminating
alteration of oscillations between halting and nonhalting states \cite{Kauffman198753}.

\subsection{Determinism does not imply predictability}
\label{2016-pu-book-chapter-up-dnip-rice}

A very general result about the incomputability of nontrivial functional properties is  {\em Rice's theorem}
\index{Rice's theorem}  (Cf. the Appendix Sect.~\ref{2016-pu-book-chapter-ranform-rp} on page~\pageref{2016-pu-book-chapter-ranform-rp})
stating that,  given an algorithm, all functional properties
(that is, some ``nontrivial'' input/output behavior which neither is true for every program, nor true for no program
that is, some programs show this behaviour, and others don't)
of that algorithm are undecidable.
Stated differently,  given a program,
there is no general algorithm predicting or determining whether the function it computes has or has  not
some property (which some programs have, and others do not have).

% https://www.youtube.com/watch?v=xbr9K-u0wmE

One proof is by reduction to the halting problem; that is, a proof by contradiction:
we construct a decicion problem about functional properties by overlaying it with a primary halting problem.
A the primary halting problem will in general be undecidable,
so will be the compounded decision problem about function properties.

Suppose (wrongly) that there exists a program predicting or determining
whether or not, for any given program,
the function it computes has or has  not
some particular property (which some programs have, and others do not have).

Then we construct another program which first solves the halting program from some other arbitrary but definite program,
then clears the  memory, and after that, in a third step, runs a program which has the property which we are interested in.
Now we apply this new program to the predictor.
Suppose the other arbitrary but definite program terminates, then the predictor could in principle predict that
the new program satisfies the preperty.

Alas, if the other arbitrary but definite program does not halt (but for instance goes into an infinite loop),
then our predictor will never be able to execute the two final steps of the new program
-- that is, clearing the memory and running the program with the property we are interested in.
Therefore, predicting the functional property for the new three-step program constructed amounts to deciding
the halting problem for the other arbitrary but definite program.
This task is in general undecidable for arbitrary other but definite programs.


% https://www.youtube.com/watch?v=F5tQ7DlkNf8

\section{Quantitative estimates in terms of the busy beaver function}

More quantitatively one can interpret this unpredictability in terms of the busy beaver function~\cite{rado,chaitin-ACM,dewdney,brady},
\index{busy beaver function} also discussed in Appendix~\ref{2016-pu-book-chapter-ranform-s-bb}, which can be defined as a sort of ``worst case scenario'' as follows: suppose one considers all  programs (on a particular computer)
up to length (in terms of the number of symbols) $n$.
What is the {\em largest number} producible by such a program before halting?
(Note that non-halting programs, possibly producing an infinite number, e.g., by a non-terminating loop, do not apply.)
This number may be called the {\em  busy beaver function} of $n$.


Consider a related question: what is the upper bound of running time  --  or,
alternatively, recurrence time  --  of a program of length $n$ bits before
terminating  or, alternatively, recurring?
An answer to this question will explain just how long we have to
wait for the most time-consuming program of length $n$ bits to
halt. That, of course, is a worst-case scenario. Many programs of
length $n$ bits will have halted long  before the maximal halting time.
We mention without proof~\cite{chaitin-ACM,chaitin-bb}  that
this bound can be represented by the busy beaver function.

Knowledge of the maximal halting time would solve the halting
problem quantitatively
because if the maximal halting time were known
and bounded by any computable function of the program size of $n$ bits,
one would have to wait
just a little longer than the maximal halting time to make sure
that every program of length $n$  --  also this particular program, if it is destined for termination  --
has terminated.
Otherwise, the program would run forever.
Hence, because of the recursive unsolvability of the halting problem
the maximal halting time cannot be a computable function.
Indeed, for large values of $n$, the maximal halting time ``explodesunbounded by computability;''
thereby
growing faster than any computable function  of $n$ (such as the Ackermann function).


By reduction, upper bounds for the recurrence of any kind of physical behaviour can be obtained;
for deterministic systems representable by $n$ bits,
the maximal recurrence time grows faster than any computable number
of $n$.
This bound from below for possible behaviours may be interpreted quite generally
as a measure
of the impossibility to predict and forecast such behaviours by algorithmic means.


\chapter{Induction by rule inference}
\label{2016-pu-book-chapter-ri}

Induction is the inference of general rules
``causing'' and ``generating'' (in an algorithmic interpretation) physical behaviours from these very behaviours (without any extra assumptions) alone.
Thus induction is ``bottom up:'' given the phenomena and how observers perceive them operationally, these observers somehow obtain the causes and rules
which supposedly underlie these phenomena.
Thereby we shall restrict ourselves to algorithmic methods of induction; others, such as intuition, guesses or oracles, or means other than intrinsic.


Again it can be shown that for any deterministic system strong enough to support Peano arithmetic or
universal computation, the  induction problem for general algorithms (laws) or behaviours (phenomenology)
is provable unsolvable.
Induction is thereby reduced to the unsolvability of
the rule inference problem \cite{go-67,blum75blum,angluin:83,ad-91,li:92}.
This is the task to identify a rule or law reproducing the behaviour of a deterministic system
by observing its input-output performance by purely algorithmic means
(not by oracles or intuition).

Informally, the algorithmic idea of the proof is to take any sufficiently powerful
rule or method of induction and, by using it, to define some
functional behaviour which is not identified by it.
This amounts to a sort of diagonalization; that is,
the construction of an algorithm which
(passively)
fakes the guesser by simulating some particular function
until the guesser
pretends to be able to guess the function correctly.
In a second,  diagonalization step, the faking algorithm then switches to a different
 functional behaviour to invalidate the guesser's guess.

%
%More formally, assume two (universal) computers $U$ and $U'$.
%Suppose that the second computer $U'$ executes an arbitrary
%algorithm $p$ unknown to computer $U$, the ``guesser.''
% The task of $U$,
% which is called the rule inference problem,
% is to conjecture the ``law'' or algorithm $p$ by analysing the
% behavior of $U'(p)$.
% The recursive unsolvability of the rule inference problem \citep{go-67} states that this task cannot be
% performed by any effective computation.
%
%For the sake of contradiction, assume \citep{li:92}
%that there exists a ``perfect guesser'' $U$ which can identify
%all total recursive functions (wrong).
%Then it is possible to construct a function $\varphi^\ast:{\Bbb N} \rightarrow
%\{0,1\}$, such that the guesses of $U$ are wrong infinitely often,
%thereby contradicting the above assumption.
%
%Define $\varphi^\ast (0)=0$.
%One may construct $\varphi^\ast $ by simulating $U$. Suppose the values
%$\varphi^\ast (0)$, $\varphi^\ast (1)$, $\varphi^\ast (2)$, $\cdots$,
%$\varphi^\ast (n-1)$ have already been constructed. Then, on input $n$,
%simulate $U$, based on the previous series
%$
%\{0, \varphi^\ast (0)\}$,
%$
%\{1, \varphi^\ast (1)\}$,
%$
%\{2, \varphi^\ast (2)\},
%\cdots ,
%\{n-1, \varphi^\ast (n-1)\}$,
% and define
%$\varphi^\ast (n)$ equal to 1 plus the guess of $U$ of
%$\varphi^\ast (n)$ mod 2. In this way, $U$ can never guess
%$\varphi^\ast $ correctly; thereby making an infinite number of mistakes.

One can also relate this result to the recursive
unsolvability of the halting problem, or in turn interpret it quantitatively in terms of  the {\em busy beaver} function:
\index{busy beaver function}
there is no recursive bound on the
time the guesser has to wait  to make sure that the guess is
correct.
More generally, one could relate induction also to
the problem of {\em functional equivalence,}
\index{functional equivalence}
\index{equivalence, functional}
which is perovable undecidable~\cite[\S~2.1, pp.~33,34]{rogers1}
do two or more algorithms compute the same function?
Two algorithms $\varphi$ and $\psi$ are equivalent if  and only if
they share a common domain (and image), and  for any argument $x$ of the domain,
they are  conditionally equal  $\varphi (x) = \psi (x)$;
that is, both sides are meaningful at the same time and, if meaningful, they assume the same value.



\chapter{Other types of recursion theoretic unknowables}
\label{2016-pu-book-chapter-otrtu}


The following theorems of recursive  analysis~\cite{aberth-80,Weihrauch} have some
implications for theoretical physics.

\begin{itemize}
\item
{Specker's theorem of recursive analysis:}
There exist recursive monotone bounded sequences of rational numbers
whose limit is no computable number~\cite{Specker49}.

A concrete example of such a number is Chaitin's Omega number~\cite{chaitin3,calude:02,calude-dinneen06},
also discussed in Appendix~\ref{2016-pu-book-chapter-ranform-Omega},
the halting probability for a computer (using prefix-free code),
which can be defined by a sequence of rational numbers
with no computable rate of convergence.


\item
{Specker's other theorem of recursive analysis:}
There exist a recursive real function which has its maximum in the unit interval
at no recursive real number~\cite{specker57}.
This has implications for the principle of least action~\cite{kreisel}.


\item
{Wang's theorem of recursive analysis:}
The predicate ``there exists a real number $r$ such that whether or not $G(r) = 0$'' is recursively undecidable for $G(x)$
in a class of functions which involves polynomials and the sine function~\cite{wang}.
This, again, has some bearing on  the principle of least action.


\item
{Uncomputable sulutions of differential equations:}
There exist uncomputable solutions of the wave equations for computable initial values~\cite{pr1,bridges1}.

\item
{Ubiquity and pervasiveness of undecidability:}
On the basis of theorems of recursive analysis~\cite{Scarpellini-63,richardson68}
many questions in dynamical systems theory are provable undecidable~\cite{1985cfd..book.....F,dc-d93,Stewart-91,calude:037103}.


\end{itemize}

\chapter{What if there are no laws? Emergence of laws}
\label{2016-pu-book-chapter-pu-ch-emlaws}
\index{emergence}

The following speculations resemble Darwin's and also Turing's ``inversion of reason'' -- that is, ``competence without comprehension'' --
forcefully put forward by  the atheistic philosopher Daniel Dennett in his phrase
{\em ``delere Auctorem Rerum Ut Universum Infinitum Noscas; aka DARW(=UU)IN:  destroy the author of things in order to know the universe''}.

%https://www.ft.com/content/96187a7a-fce5-11e6-96f8-3700c5664d30

%http://williamsrecord.com/2009/10/06/philosopher-dennett-recasts-darwins-legacy/

\section{Mythological roots}

The idea that the universe is lawless and grounded in Chaos, or a structureless void can be found in many mythologies and cosmogonies.
For instance,
in Chinese cosmogony {\em hundun} \index{hundun} is identified with primordial chaos.

In Greek mythology and cosmogony, \textgreek{q'aoc} -- {\em chaos} (or {\em chasm}, ``gap, yawning''~\cite[p.~3]{gantz-earlyGreekMyth}) has been considered
\index{chaos}
the primordial ``nonform'' of the universe.
In particular, Hesiod's \textgreek{Theogonia} -- {\it Theogony}  \index{Theogony}
{\em ``(not necessarily Hesiod's title) offers a brief
account of the origins of the cosmos as preface to the extolling of Zeus' rule''},
thereby contrasting the ``lawful'' organization of the
world of the gods {\em ``with the absence of such order in previous times''}~\cite[p.~1]{gantz-earlyGreekMyth}:
{\em ``From the beginning, tell me which of these was first to come.
Chasm it was, in truth, who was the very first''}~\cite[115-116]{hesiod+700};
or, in a different translation,
{\em ``In truth, first of all Chasm came to be''}~\cite[115-116]{hesiod+700-2}.
The latter author remarks in Footnote~7:
{\em ``Usually [[Chasm is]] translated as ``Chaos''; but that suggests to us, misleadingly,
a jumble of disordered matter, whereas Hesiod's term
indicates instead a gap or opening.''}

Two centuries after Hesiod, Plato's {\em Tomaeus} \index{Tomaeus} stated
that the god-demiurge {\em ``found everything visible
in a state of turmoil, moving in a discordant and chaotic
manner (prior to the intervention of the
demiurge, there is chaos), so he led it from chaos to order, which he regarded
as in all ways better''}~\cite[p.~18,127; 30a]{plato-Timaeus}
% unordered motion


Also the Bible's {\em Genesis} [1.2] states that, after its creation by God {\em ``the earth was without form and void.''}

\section{Physical indeterminism in Vienna at the dawn of quantum mechanics}
\label{2016-pu-book-chapterpu-vi}

Probably the first researcher speculating that {\em all} physical laws are not exact but emerge from, and
are subject to, microphysical indeterminism, was Exner
\index{Exner}
in {\it fin de si\`ecle} Vienna: in his
inaugural lecture {\em ``On Laws in Science and Humanities''} as rector of the University of
Vienna, held on Oktober 15th, 1908, Exner suggests~\cite[p.~18]{Exner-1908}
that there are no exact laws of nature; or, as Hanle puts it~\cite{Hanley-1979},
{\em ``laws do not exist in nature but are formulated by man.''}
In Exner's own words~\cite{Exner-1908},
{\em ``$\ldots$~in the region of the small, in time as in space, the physical
laws are probably invalid
$\ldots$
Therefore we have to perceive all so-called exact laws  as probabilistic which are not valid with absolute certainty;
but the more individual processes are involved the higher the certainty
All physical laws can be traced back to random processes on the  molecular level,
and from them the result follows according to the laws of probability theory$\ldots$''}\footnote{
German original~\cite{Exner-1908}
{\em ``$\ldots$~im kleinen, der Zeit wie dem Raume nach,
gelten die physikalischen Gesetze voraussichtlich nicht
$\ldots$
So m\"ssen wir also alle sogenannten exakten Gesetze
nur als Durchschnittsgesetze auffassen die nicht
mit absoluter Sicherheit gelten, wohl aber mit um so
gr\"o{\ss}erer Wahrscheinlichkeit aus je mehr Einzelvorg\"angen
sie sich ergeben. Alle physikalischen Gesetze
gehen zur\"uck auf molekulare Vorg\"ange zuf\"alliger Natur
und aus ihnen folgt das Resultat nach den Gesetzen
der Wahrscheinlichkeitsrechnung$\ldots$''}}

Indeed, Exner speculated, it could well be that the statistical laws do not necessitate nonprobabilistic,
deterministic laws on the microlevel -- it could well be that, in particular, on the microscopic level for individual particles,
irreducible random events occur, giving rise to statistical macrolevel descriptions.
This has already suggested by Exner even for classical physics such as collisions~\cite{Exner-1908}.
Exner also explicitly mentiones Boltzmann's methods of statistucal physics;
\index{Boltzmann}
ane Schr\"odinger mentions the second law of thermodynamics.



Egon von Schweidler, a collegue of Exner at the University of Vienna,
might have been the first to interpret single
radiactive decays irreducible random~\cite{schweidler-1905} (cf. Section~\ref{2016-pu-book-chapter-radec}, p.~\pageref{2016-pu-book-chapter-radec}).
And Schr\"odinger, the ``scientific apprentice'' of both Schweidler \& Exner, later in his Z\"urich inaugural lecture
(Antrittsrede an der Universit\"at Z\"rich, 9. Dezember 1922~\cite{schrodinger-1929}; English translation in~\cite[Chapter~VI, p-107-118]{book:16081}),
referred to Exner's indeterminism.
So, essentially, both Exner's 1909  inaugural address as {\it Rektor}
of the University of Vienna,  as well as Schr\"odinger's 1922 inaugural address as chair professor
for theoretical physics at the University of Z\"urich
suggest the following: it is at least possible, if not preferable, to assume that
all physical laws, classical and quantum alike, are emergent and correct only statistically and for large groups of outcomes,
and at the microlevel are grounded in irreducible random individual events.
As far as I know, these inaugural lectures are in German only and unavailable in their entirety in English;
for excerpts and reviews see Refs.~\cite{Hanley-1979,Stoeltzner-1999,Stoeltzner-2000,Stoeltzner-2003}.


\section{Contemporary representations}

Let us, for the sake of exposing an extreme position, contemplate on an infinite universe
consisting of random bits -- that is, these collection of bits are not only ``lawless''
in the sense that there does not exist any algorithm generating them,
but they are, in a strictly formal way~\cite{ml:70,chaitin-99,calude:02}, also algorithmically incompressible.
That is, its behaviour cannot be ``compressed'' by any algorithm or rule.
One model of such a universe would be a single random real.
We assume that the algorithmic incompressibility of encoded microphysical structures
might be a quite appropriate formalization of primordial chaos.

There are two ways how pseudo-lawfulness might be ``revealed'' to intrinsic observers:
\begin{enumerate}[(i)]

\item Lawful substructures:
It might be the case that these observers might have only restricted operational access to the entire random string,
and merely perceive an orderly partial sequence (string) --
that is, they accidentally live in a substructure of the random real which appears to be algorithmically compressible.
Any such compression might be interpreted as a ``law'' governing this particular section of the universe.

Calude, Meyerstein and Salomaa discuss universes which are lawless~\cite{calude-meyerstein,lawless}
and mention the possibility that
we might be riding on a huge but finite segment of a random string which, to its inhabitants, appears to be lawful:
{\em ``As our direct information
refers to finite experiments, it is not out of question to discover local rules, functioning
on large, but finite scales, even if the global behaviour of the process is truly random''}~\cite[p.~1077]{calude-meyerstein}.

These considerations are based on the finding that, {\em ``almost all real numbers, when expressed in any base,
contain every possible digit or possible string of digits''}~\cite[Theorem~6.1, p.~148]{calude:02} -- even entire deterministic universes.
There appear ``spurious correlations'' in the following sense: {\em ``very large databases have to contain arbitrary correlations.
These correlations appear only due to the size, not the nature, of data''}~\cite{Calude2016}.

Yanofsky~\cite{Yanofsky-chaos} has discussed related scenarios, and has heuristically investigated the {\em ``extracted order that can be found in the chaos''} by
considering large matrices and finding patterns therein:
Suppose, instead of a matrix, a long string (one might say a  $1 \times n$ matrix)
whose entries of are filled randomly and independently with decimal digits.
The expected number of times  any particular substring of $m$ digits, say ``$123\ldots m$,'' occurs
within this larger string of length $n$ is $(n-m+1) (1/10)^m$.

% http://math.stackexchange.com/questions/220521/expected-number-of-times-random-substring-occurs-inside-of-larger-random-string
% http://math.stackexchange.com/questions/726168/how-many-times-can-a-word-appear-in-a-random-phrase?rq=1


\item  Emergence:
The laws of nature might actually be ``emergent'' in a Ramsey-theory type way.
Because just as  {\em ``one cannot not communicate''}~\cite[\S~2.24, p.~51]{Watzlawick-1967}
Ramsey theory~\cite{Ramsey-GRS-90,landman+robertson2004,Soifer} reveals that there exist  properties
and correlations for {\em any} kind of data, which do not depend on the way these date are generated or structured.
This would also (but is not limited to) include \textgreek{q'aoc}; that is, universes
which are not ``lawful'' and generated by intent; and consisting of data which cannot be algorithmically compressed.
Such inevitable correlations might be ``interpreted'' as ``laws'' in any data:
any sufficiently large structure inevitably
contains orderly substructures which can be conjectured to be ``lawful''  -- just as the Elders looked up into the skies and
``found'' animal constellations there~\cite{GS-90}.

Unlike the lawful substructures scenario, emergence does not presume local non-typicality.

\end{enumerate}



\section{Provable impossibility to prove (in)determinism}

Every absolute claim of both irreducible determinism and indeterminism remains speculative and metaphysical.
Because, due to the recursive undecidability of induction (the rule inference),
one can never be sure if a phenomenology identified as deterministic -- with a particular law or ``theory of everything''~\cite{barrow-TOE} --
 ``switches its course'' and behaves differently, thereby disproving such claims.
This is ultimately due to the fact that no recursive upper (algorithmic space/memory and runtime) bound exists for such an assertion.

Conversely, any claim of absolute, irreducible indeterminism
falls short of a proof that no laws exist relative to the phenomenology,
for various reasons.
Suppose the physical phenomena are coded into bit strings; then these bit strings are necessarily finite (there is no infinite operational precision).
For finite bit strings always laws exist -- think of a simple enumeration.
One may also argue that, due to reduction from the halting problem,
it cannot be guaranteed that no algorithmic compression exists -- in general this bound will also be proportional to
the worst-case scenario, which is a busy beaver \index{busy beaver function}
type behaviour~\cite{chaitin-bb} -- and thus nonrecursive in the length of the bit string.
And finally, and also connected with worst-case space/memory and runtime --
not all laws can in principle be enumerated (because there exist a potential infinity of them);
and those few analized cannot be recursively asserted to not yield that particular bit string encoding the aforementioned phenomenology.


\section{Potential misperceptions by over-interpretation}
\label{2016-pu-book-chapter-pu-pmboi}

Square-integrable functions can be approximated by a variety of rather different complete
systems of {\em orthogonal functions}~\cite[Section~10.4, p.~649]{arfken05},
\index{orthogonal functions}
such as, for instance, trigonometric functions, (Legendre) polynomials,
or, more generally, due to the spectral theorem
\index{spectral theorem}
the system of eigenfunctions of certain normal operators.
Are we thus justified to infer that such a particular function, because it can be written in these various forms,
is actually ``composed of,'' say, vibrations and oscillations  in the case of Fourier analysis,
or, alternatively, polynomials, or any other such complete set of orthogonal functions?
At first sight it might be tempting to assume just that.
But a second thought reveals that these choices of functional sets (and thus of normal operators) are purely conventional.
They might, from the practical point of view, be convenient or suitable for the particular purpose,
but they cannot justify any ``deep'' truth or ontology.
They are just particular formal representations of a functional entity.



As has been noted already in the preface, Freud advised analysts
to adopt a contemplative strategy of {\em evenly-suspended attention}~\cite{Freud-1912,Freud-1912-e}
\index{evenly-suspended attention}; and, in particular,  to be aware of the dangers
caused by {\em
``$\ldots$~the temptation of projecting outwards
some of the peculiarities of his own personality,
which he has dimly perceived, into the field of science,
as a theory having universal validity; he will bring the psycho-analytic method into discredit, and lead the inexperienced astray.''}~\cite{Freud-1912-e}\footnote{
German original~\cite{Freud-1912}: {\em ``Er wird leicht in die Versuchung geraten,
was er in dumpfer Selbstwahrnehmung von den Eigent\"umlichkeiten seiner eigenen Person erkennt,
als allgemeing\"ultige Theorie in die Wissenschaft hinauszuprojizieren,
er wird die psychoanalytische Methode in Misskredit bringen und Unerfahrene irreleiten.''}}
And the late Jaynes warns and disapproves of
the {\em Mind Projection Fallacy}~\cite{jaynes-89,jaynes-90},
\index{Mind Projection Fallacy}
pointing out that
{\em ``we are all under an ego-driven temptation to project our private
thoughts out onto the real world, by supposing that the creations of one's own imagination are real
properties of Nature, or that one's own ignorance signifies some kind of indecision on the part of
Nature.''}

For a recent neurophysiological finding corroborating
the possibility to induce halucinations by perceptual priors and expectations see Ref.~\cite{Powers596}.


So, it may not be entirely unreasonable to speculate that our own universe might be grounded in
\textgreek{q'aoc} --  chaos (or  chasm, ``gap, yawning''~\cite[p.~3]{gantz-earlyGreekMyth}).
Those ``laws'' which we purport to ``discover'' might be spurious reflections of our own minds,
desperately attempting to ``make sense'' of the phenomena.

One is reminded of Fritz Lang's remark in Godard's movie {\em Le m\'epris (Contempt)}, approximately 14 minutes into that movie:
{\em ``Jerry, don't forget. The gods have not created man. Man has created gods.''}
And Schr\"odinger,   in  {\em Nature and the Greeks},
\index{Schr\"odinger}
quotes fragments of Xenophanes \index{Xenophanes} as follows~\cite[p.~71]{schroed:natgr}:
{\em ``(Fr. 15) Yes, and if the oxen or horses or lions had hands
and could paint with their hands, and produce works of art
as men do, horses would paint the forms of the gods like
horses, and oxen like oxen and make their bodies in the
image of their several kinds.
(Fr. 16) The Ethiopians make their gods black and snubnosed;
the Thracians say theirs have blue eyes and red hair.''}

For the sake of a bold demonstration take some recent findings in machine learning.
\index{machine learning}
In particular, consider
the interpretation of photographic images by neural networks,
also called {\em deep dreaming}.
\index{deep dreaming}
Depending of the class of objects the network has handled and has been trained in the past,
it ``projects'' or interprets images presented to it according to its expectations and (trained) knowledge.
Thereby,
{\em ``even a relatively simple neural network can be used to over-interpret an image,
just like as children we enjoyed watching clouds and interpreting the random shapes''}~\cite{google-deepdreaming-over}.
An ironic and less sophisticated example is
graphically depicted in Figure~\ref{2016-pu-book-chapter-pu-figure-deepdreaming}.
\begin{figure}
\begin{center}
\includegraphics[width=5cm,angle=0]{2016-pu-book-chapter-pu-figure-deepdreaming}
\end{center}
\caption{
Ironic example of an over-interpretation of an image.
\label{2016-pu-book-chapter-pu-figure-deepdreaming}
}
\end{figure}
