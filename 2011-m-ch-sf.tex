\chapter{Special functions of mathematical physics}
\label{2011-m-ch-sf}

This chapter follows several good approaches
\cite{lebedev:1965:sft,Wilf,bell-specfun,Temme:1996:SFI,andrews:1999:sfu,Kuznetsov,Kisil}.
For reference, consider
\cite{abramowitz:1964:hmf,Brych-HBSF,Gradshteyn}.

Special functions often arise as solutions of differential equations; for instance as eigenfunctions
of differential operators in quantum mechanics.
Sometimes they occur  after several {\em separation of variables}
and substitution steps have transformed the physical problem into something manageable.
For instance, we might start out with some linear partial differential equation like the wave equation,
then separate the space from time coordinates,
then separate the radial from the angular components,
and finally separate the two angular parameter.
After we have done that, we end up with several separate differential equations of the Liouville form;
among them the Legendre differential equation leading us to the Legendre polynomials.

In what follows a particular class of special functions will be considered.
These functions are all special cases of the
{\em hypergeometric function}
\index{hypergeometric function},
which is the solution of the
{\em hypergeometric equation}.
\index{hypergeometric equation}
The hypergeometric function exhibis a high degree of
``plasticity,''
as many elementary analytic functions can be expressed by them.

First, as a prerequisite, let us define the gamme function.
Then we proceed to second order Fuchsian differential equations;
\index{Fuchsian equation}
followed by a rewriting of this Fuchsian  differential equations
into hypergeometric equation.
Then we study the hypergeometric function as a solution to the
hypergeometric equation.
Finally, we mention some particular hypergeometric functions, such as the
Legendre orthogonal polynomials, and others.

Again, if not mentioned otherwise, we shall restrict our attention to
second order differential equations.
Sometimes -- such as for the Fuchsian class -- a generalization is possible but
not very relevant for physics.

\section{Gamma function}
\index{gamma function}

Although
the gamma function $\Gamma (x)$ is an extension of the factorial function  $n!$ as
\begin{equation}
\Gamma (n+1) = n! \textrm { for } n \in {\Bbb N},
\label{2011-m-ch-sfgamman}
\end{equation}
it is also for real or complex arguments.

Let us first define the
{\em shifted factorial}
\index{shifted factorial}
or, by another naming,
the
{\em Pochhammer symbol}
\index{Pochhammer symbol}
\begin{equation}
(a)_0=1, \quad (a)_n=a(a+1)\cdots (a+n-1)\textrm{, for }n>0,
\label{2011-m-ch-sfsf}
\end{equation}
where $a$ can be any real or complex number.


With this definition,
\begin{equation}
\begin{array}{l}
 z ! ( z +1)_ n
=1\cdot 2 \cdots  z  \cdot ( z +1)(( z +1)+1)\cdots (( z +1)+ n -1)  \\
\qquad
=1\cdot 2 \cdots  z  \cdot ( z +1)(  z +2)\cdots ( z + n ) \\
\qquad
= ( z + n )!
\textrm{,
or } \\
 z !
= \frac{( z + n )!}{  ( z +1)_ n }.
\end{array}
\label{2011-m-ch-sfsf1}
\end{equation}

Since
\begin{equation}
\begin{array}{l}
( z + n )!
=( n + z )!     \\
\qquad
= 1\cdot 2 \cdots  n  \cdot ( n +1)( n +2)\cdots ( n + z )   \\
\qquad
=  n ! \cdot ( n +1)( n +2)\cdots ( n + z )   \\
\qquad
=  n ! \cdot ( n +1)( n +2)\cdots ( n + z )   \\
\qquad
= n !( n +1)_ z  ,
\end{array}
\end{equation}
we can rewrite Eq. (\ref{2011-m-ch-sfsf1}) into
\begin{equation}
 z !
= \frac{ n !( n +1)_ z  }{  ( z +1)_ n }
=   \frac{ n !  n ^ z  }{  ( z +1)_ n }  \frac{( n +1)_ z  }{  n ^ z }
.
\label{2011-m-ch-sfsf2}
\end{equation}

Since the latter factor, for large $n$, converges as  [``$O(x)$'' means ``of the order of $x$'']
\begin{equation}
\begin{array}{l}
\frac{( n +1)_ z  }{  n ^ z }   =
\frac{( n +1)(( n +1)+1)\cdots (( n +1)+ z -1)}{  n ^ z }  \\
\qquad                              =
\frac{ n ^ z  +O( n ^{ z -1})}{  n ^ z }  \\
\qquad   =
\frac{ n ^ z }{  n ^ z }  +
\frac{O( n ^{ z -1})}{ n ^ z }  \\
\qquad   =
1  + O( n ^{-1})
\stackrel{ n  \rightarrow \infty}{\longrightarrow} 1,
\end{array}
\end{equation}
in this limit, Eq. (\ref{2011-m-ch-sfsf2})  can be written as
\begin{equation}
 z !
= \lim_{ n \rightarrow \infty}  z !
=  \lim_{ n \rightarrow \infty} \frac{ n !  n ^ z  }{  ( z +1)_ n }
.
\label{2011-m-ch-sfsf3}
\end{equation}

Hence, for all $z\in {\Bbb C}$ which are not equal to a negative integer
--
that is, $z \neq 0, -1,-2,\ldots$
--
we can, in analogy to the ``classical factorial,''
define   a ``factorial function shifted by one'' as
\begin{equation}
\begin{array}{l}
\Gamma ( z + 1)
=  \lim_{ n \rightarrow \infty} \frac{ n !  n ^ z  }{  ( z +1)_ n }
\textrm{, or}         \\
\Gamma ( z  )
=  \lim_{ n \rightarrow \infty} \frac{ n !  n ^ { z -1}  }{  ( z )_ n }
.
\end{array}
\label{2011-m-ch-sfsfdga}
\end{equation}
Hence we effectively express $z!$ in Eq. (\ref{2011-m-ch-sfsf1}) in terms of $\Gamma (z+1)$,
which also implies that
\begin{equation}
\Gamma ( z + 1)
=  z
\Gamma ( z  ) ,
\end{equation}
as well as  $\Gamma ( n +1 ) =n!$ for $n\in {\Bbb N}$.
Note that, since
\begin{equation}
(1)_n =1 (1+1) (1+2)\cdots (1-n-1)= n! ,
\end{equation}
Eq. (\ref{2011-m-ch-sfsfdga})  yields
\begin{equation}
\Gamma ( 1)
=  \lim_{ n \rightarrow \infty} \frac{ n !  n ^ 0  }{  (  1)_ n }
=  \lim_{ n \rightarrow \infty} \frac{ n !    }{  n !}  =1
.
\end{equation}

We state without proof that, for positive real parts $\Re x$,  $\Gamma (x)$ has an integral
representation as
\begin{equation}
\Gamma ( x )
=
\int_0^\infty t^{x-1}e^{-t}dt
.
\end{equation}

Also the next formulae
\begin{equation}
\begin{array}{l}
\Gamma ( \frac{1}{2})=\sqrt{\pi } \textrm{, or, more generally, }\\
\Gamma ( \frac{n}{2})=\sqrt{\pi }\frac{( n-2)!!}{2^{(n-1)/2}} \textrm{, for }n>0 \textrm {,  and }\\
\Gamma ( x)\Gamma ( 1-x) =\frac{\pi}{\sin (\pi x)} \textrm{, Euler's reflection formula,}
\end{array}
\end{equation}
are stated without proof.


Here, the
{\em  double factorial}
\index{double factorial} is defined by
\begin{equation}
n!!=
\left\{
\begin{array}{l}
1   \textrm { for } n=-1,0  \textrm {, and} \\
2\cdot 4\cdots (n-2)\cdot n\\
\qquad = (2k)!!=  \prod_{i=1}^k (2i)\\
\qquad =  2^{n/2}\left(1\cdot 2\cdots \frac{(n-2)}{2}\cdot \frac{n}{2}\right)\\
\qquad =  k!2^k
\textrm{ for positive even }  n= 2k ,  k\ge 1 \textrm{, and}
\\
1\cdot 3 \cdots (n-2) \cdot  n \\
\qquad = (2k-1)!!   =  \prod_{i=1}^k (2i-1)\\
\qquad = \frac{1\cdot 2 \cdots (2k-2) \cdot  (2k-1)\cdot  (2k)}{(2k)!!} \\
\qquad =  \frac{(2k)!}{k!2^k}
\textrm{  for odd positive }  n= 2k-1 ,  k\ge 1 .
\end{array}
\right.
\end{equation}


Stirling's formula
\index{Stirling's formula}
[again, $O(x)$ means ``of the order of $x$'']
\begin{equation}
\begin{array}{l}
\log n! = n \log n -n + O(\log (n))\textrm{, or}   \\
n! \stackrel{n\rightarrow \infty}{\longrightarrow} \sqrt{2\pi n} \left(\frac{n}{e}\right)^n
\textrm{, or, more generally, }\\
\log \Gamma (x) = \sqrt{\frac{2\pi }{x}}\left(\frac{x}{e}\right)^x \left( 1+ O\left(\frac{1}{x}\right) \right)
\end{array}
\end{equation}
is stated without proof.

\section{Beta function}
\index{beta function}
The  {\em beta function,}
also called the  {\em Euler integral of the first kind,} is a special function defined by
\index{Euler integral}
\begin{equation}
B(x,y)=\int_0^1 t^{x-1}(1-t)^{y-1} dt =\frac{\Gamma (x) \Gamma (y)}{\Gamma (x+y)} \textrm{ for } \Re x, \Re y >0
\label{2011-m-ch-sf-beta}
\end{equation}
No proof of the identity of the two representations in terms of an integral, and of $\Gamma$-functions is given.


\section{Fuchsian differential equations}
\index{Fuchsian equation}

Many differential equations of theoretical physics are Fuchsian equations.
We shall therefore study this class in some generality.


\subsection{Regular,  regular singular, and irregular singular point}
Consider the homogenuous differential equation   [Eq. (\ref{2011-m-ch-sl1}) on page \pageref{2011-m-ch-sl1} is inhomogenuos]
\begin{equation}
{\cal L}_x y(x) =   a_2(x) \frac{d^2}{dx^2}y(x)  +  a_1(x) \frac{d}{dx}y(x)+   a_0(x) y(x)
 =
0.
\label{2011-m-ch-sf-fc1}
\end{equation}
If $a_0(x)$, $a_1(x)$ and $a_2(x)$ are analytic at some point $x_0$ and in its neighborhood,
and if $a_2(x_0)\neq 0$
at $x_0$, then
 $x_0$
is called an {\em ordinary point}, or {\em regular point}.
\index{ordinary point}
\index{regular point}
We  state without proof that in this case the solutions around $x_0$ can be expanded as power series.
In this case we can  divide equation (\ref{2011-m-ch-sf-fc1}) by $a_2(x)$ and rewite it
\begin{equation}
\frac{1}{a_2(x)}{\cal L}_x y(x) =   \frac{d^2}{dx^2}y(x) + d(x)  \frac{d}{dx}y(x)+  e(x) y(x)
 =
0,
\label{2011-m-ch-sf-fc2}
\end{equation}
with
$d(x)=    a_1(x) / a_2(x)
$
and
$e(x)=     a_0(x) / a_2(x)
$.

If, however, $a_2(x_0)= 0$ and $a_1(x_0)$ or $a_0(x_0)$ are nonzero, the $x_0$ is called
{\em singular point}
\index{singular point} of (\ref{2011-m-ch-sf-fc1}).
The simplest case is if $a_0(x_0)$ has a {\em simple zero} at $x_0$;
then both $d(x)$ and $e(x)$
in (\ref{2011-m-ch-sf-fc2})
have at most simple poles.


Furthermore, for reasons disclosed later
-- mainly motivated by the possibility to write the solutions as power series --
a point $x_0$ is called a
{\em regular singular point}
\index{regular singular point}
of Eq. (\ref{2011-m-ch-sf-fc1})
if
\begin{equation}
\lim_{x\rightarrow x_0} \frac{(x-x_0) a_1(x)}{a_2(x)}\textrm{, as well as }
\lim_{x\rightarrow x_0} \frac{(x-x_0)^2 a_0(x)}{a_2(x)}
\end{equation}
both exist. If any one of these limits does not exist, the singular point is
an
{\em irregular singular point}.
\index{irregular singular point}


A  very important case is the case
of the {\em Fuchsian differential equation},
where in (\ref{2011-m-ch-sf-fc2})
\begin{itemize}
\item
$d(x)$ has at most a {\em single pole}, and
\item
$e(x)$ has at most a {\em double pole}.
\end{itemize}
\marginpar{The simples realization of this case is for
$$
\begin{array}{l}
a_2(x)= a(x-x_0),\\
a_1(x)= b(x-x_0),\\
a_0(x)= c.\\
\end{array}
$$
}
Stated differently, a linear ordinary differential equation is called Fuchsian
if every singular point, including infinity, is regular.
Hence, in Eq. (\ref{2011-m-ch-sf-fc2}), the equation is of the Fuchsian class if
the coefficients are of the form
\begin{equation}
\begin{array}{l}
d(x)= \prod_{j=1}^k \frac{q_1(x)}{(x-x_j)}\textrm{, and}\\
e(x)= \prod_{j=1}^k \frac{q_0(x)}{(x-x_j)^2},
\end{array}
\label{2011-m-ch-sf-eforp}
\end{equation}
where the $x_1,\ldots ,x_k$ are $k$ (singular) points, and
$q_1(x)$ and $q_0(x)$ are polynomials of degree less then or equal to
$k$ and $2k$,
respectively. Hence, the coefficients of Fuchsian equations must be rational functions; that is,
they must be of the form $\frac{P(x)}{Q(x)}$,
where $P (x)$ and $Q (x)$ are polynomials in $x$ with real coefficients.


The {\em hypergeometric differential equation} is a {\em Fuchsian differential equation}
which has at most {\em three regular singularities}, including infinity,
at $0$, $1$, and $\infty$ \cite{Kuznetsov}.

\subsection{Power series solution}
Now let us get more concrete about the solution of Fuchsian equations by {\em power series}.
\index{power series solution}

{
\color{blue}
\bexample
In order to get a feeling for power series solutions of differential equations,
consider the ``first order'' Fuchsian equation  \cite{larson-edwards-calculus}
\begin{equation}
y'-\lambda  y=0.
\label{2011-m-ch-sf-pss1}
\end{equation}
Make the {\it Ansatz} that the solution can be expanded into a power series of the form
\begin{equation}
y(x)=\sum_{j=0}^\infty a_j x^j.
\end{equation}
Then,  Eq. (\ref{2011-m-ch-sf-pss1}) can be written as
\begin{equation}
\begin{array}{l}
\left(\frac{d}{dx}  \sum_{j=0}^\infty a_j x^j\right)-\lambda   \sum_{j=0}^\infty a_j x^j=0,\\
 \sum_{j=0}^\infty ja_j x^{j-1}-\lambda   \sum_{j=0}^\infty a_j x^j=0,\\
 \sum_{j=1}^\infty ja_j x^{j-1}-\lambda   \sum_{j=0}^\infty a_j x^j=0,\\
 \sum_{m=j-1=0}^\infty (m+1)a_{m+1} x^{m}-\lambda   \sum_{j=0}^\infty a_j x^j=0,\\
 \sum_{ j =0}^\infty (j+1)a_{j+1} x^{j}-\lambda   \sum_{j=0}^\infty a_j x^j=0,
\end{array}
\label{2011-m-ch-sf-pss2iuzuiz}
\end{equation}
and hence, by comparing the coefficients of $x^j$,  for $n\ge 0$,
\begin{equation}
\begin{array}{l}
(j+1)a_{j+1}= \lambda   a_j\textrm{, or }\\
a_{j+1}= \frac{\lambda   a_j}{j+1} =a_0 \frac{\lambda ^{j+1}}{(j+1)!}\textrm{, and }\\
a_{j }= a_0 \frac{\lambda ^{j }}{j!}
 .
\end{array}
\end{equation}
Therefore,
\begin{equation}
y(x)=\sum_{j=0}^\infty a_0 \frac{\lambda ^{j }}{j!} x^j=a_0 \sum_{j=0}^\infty \frac{(\lambda  x)^{j }}{j!} =a_0 e^{\lambda  x}.
\end{equation}

\eexample
}

In the Fuchsian case let us consider the following {\em generalized power series} {\em Ansatz} around a regular singular point $x_0$,
which can be  motivated by Eq. (\ref{2011-m-ch-sf-eforp}), and by the {\em Laurent series expansion}
\index{Laurent series}
(\ref{011-m-ch-ca-else1})--(\ref{011-m-ch-ca-else2}) on
page \pageref{011-m-ch-ca-else1}:
\begin{equation}
\begin{array}{l}
d(x)= \frac{A_1(x)}{x-x_0}=\sum_{j=0}^\infty \alpha_j (x-x_0)^{j-1} \textrm{, for } 0 < \vert x-x_0 \vert < r_1,\\
e(x)= \frac{A_2(x)}{(x-x_0)^2}=\sum_{j=0}^\infty \beta_j (x-x_0)^{j-2} \textrm{, for } 0 < \vert x-x_0 \vert < r_2,\\
y(x)=  (x-x_0)^{\sigma} \sum_{l=0}^\infty w_l (x-x_0)^{l}
=  \sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma}\textrm{, with } w_0\neq 0
.
\end{array}
\label{2011-m-ch-sf-pss2}
\end{equation}
Eq. (\ref{2011-m-ch-sf-fc2})
then becomes
$$
\begin{array}{l}
\frac{d^2}{dx^2}y(x) + d(x)  \frac{d}{dx}y(x)+  e(x) y(x)     =   0,    \\
\left[\frac{d^2}{dx^2}  + \sum_{j=0}^\infty \alpha_j (x-x_0)^{j-1}  \frac{d}{dx}y(x)+ \sum_{j=0}^\infty \beta_j (x-x_0)^{j-2}\right]
\sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma}     =   0,    \\
({l + \sigma})({l + \sigma-1})  \sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma -2}\\
\qquad + \left[({l + \sigma})  \sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma -1}\right]  \sum_{j=0}^\infty \alpha_j (x-x_0)^{j-1}
\\
\qquad + \left[\sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma}\right] \sum_{j=0}^\infty \beta_j (x-x_0)^{j-2}
    =   0,    \\
%
({l + \sigma})({l + \sigma-1})  \sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma -2}\\
\qquad + \left[({l + \sigma})  \sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma -1}\right]  \sum_{j=0}^\infty \alpha_j (x-x_0)^{j-1}
\\
\qquad + \left[\sum_{l=0}^\infty w_l (x-x_0)^{l + \sigma}\right] \sum_{j=0}^\infty \beta_j (x-x_0)^{j-2}
    =   0,    \\
%
(x-x_0)^{\sigma-2}  \sum_{l=0}^\infty (x-x_0)^{l}
\left[
({l + \sigma})({l + \sigma-1})   w_l \right. \\
\qquad + ({l + \sigma})   w_l    \sum_{j=0}^\infty \alpha_j (x-x_0)^{j}
\\   \left.
\qquad +  w_l  \sum_{j=0}^\infty \beta_j (x-x_0)^{j}
\right]
    =   0,    \\
%
(x-x_0)^{\sigma-2}  \sum_{l=0}^\infty
({l + \sigma})({l + \sigma-1})   w_l (x-x_0)^{l} \\
\qquad +  \sum_{l=0}^\infty ({l + \sigma})   w_l    \sum_{j=0}^\infty \alpha_j (x-x_0)^{l+j}
\\
\qquad +  \sum_{l=0}^\infty  w_l  \sum_{j=0}^\infty \beta_j (x-x_0)^{l+j}
    =   0.
\end{array}
$$
Next, in order  to reach a  common power of $(x-x_0)$,
we perform an index identification
$l=m$ in the first summand, as well as an index shift
$$
l+j =m, \; j= m-l
\textrm{, since } l\ge 0 \textrm{ and } j\ge 0 \Rightarrow 0\le l\le m
$$
in the second and third summands (where the order of the sums change):
\begin{equation}
\begin{array}{l}
(x-x_0)^{\sigma-2}  \sum_{l=0}^\infty
({l + \sigma})({l + \sigma-1})   w_l (x-x_0)^{l} \\
\qquad + \sum_{j=0}^\infty  \sum_{l=0}^\infty ({l + \sigma})   w_l    \alpha_j (x-x_0)^{l+j}
\\
\qquad + \sum_{j=0}^\infty  \sum_{l=0}^\infty  w_l  \beta_j (x-x_0)^{l+j}
    =   0,\\
(x-x_0)^{\sigma-2}  \sum_{m=0}^\infty
({m + \sigma})({m + \sigma-1})   w_m (x-x_0)^{m} \\
\qquad + \sum_{m=0}^\infty  \sum_{l=0}^m ({l + \sigma})   w_l    \alpha_{m-l} (x-x_0)^{l+m-l}
\\
\qquad + \sum_{m=0}^\infty  \sum_{l=0}^m  w_l  \beta_{m-l} (x-x_0)^{l+m-l}
    =   0,\\
(x-x_0)^{\sigma-2}\left\{     \sum_{m=0}^\infty
(x-x_0)^{m} \left[
({m + \sigma})({m + \sigma-1})   w_m \right.\right. \\
\qquad + \sum_{l=0}^m  ({l + \sigma})   w_l   \alpha_{m-l}
\\   \left.  \left.
\qquad +  \sum_{l=0}^m  w_l \beta_{m-l}
\right]
\right\}
    =   0,    \\
(x-x_0)^{\sigma-2}\left\{     \sum_{m=0}^\infty
(x-x_0)^{m} \left[
({m + \sigma})({m + \sigma-1})   w_m
\right.
\right.
 \\
\qquad \qquad +
\left.
\left.
 \sum_{l=0}^m w_l  \left( ({l + \sigma}) \alpha_{m-l}
 + \beta_{m-l}
\right)
\right]
\right\}
    =   0.
\end{array}
\label{2011-m-ch-sf-pss646465}
\end{equation}

If we can divide this equation through  $(x-x_0)^{\sigma-2}$
and exploit the linear independence of the polynomials $(x-x_0)^{m}$,
we obtain an infinite number of equations for the infinite number of coefficients $w_m$
by requiring that all the terms ``inbetween'' the $[\cdots ]$--brackets in Eq. (\ref{2011-m-ch-sf-pss646465}) vanish {\em individually.}
In particular, for $m=0$ and $w_0\neq 0$,
\begin{equation}
\begin{array}{l}
({0+ \sigma})({0 + \sigma-1})   w_0
+
 w_0  \left( ({0 + \sigma}) \alpha_{0} + \beta_{0}\right)
    =   0\\
\sigma({\sigma-1}) +  \sigma \alpha_{0} + \beta_{0}      = f_0(\sigma )     =   0
.
\end{array}
\label{2011-m-ch-sf-pss2sigma}
\end{equation}
The {\em radius of convergence} of the sulution will,
\index{radius of convergence}
in accordance with the Laurent series expansion, extend to the next singularity.


Note that in  Eq. (\ref{2011-m-ch-sf-pss2sigma}) we have defined $f_0(\sigma )$ which we will use now.
Furthermore, for successive $m$, and with the definition of $f_k(\sigma )=\alpha_k \sigma +\beta_k$,
we obtain the sequence of linear equations
\begin{equation}
\begin{array}{l}
w_0f_0(\sigma ) =0\\
w_1f_0(\sigma +1)+w_0f_1(\sigma )  =0,\\
w_2f_0(\sigma +2)+w_1f_1(\sigma +1) +w_0f_2(\sigma )  =0,\\
\vdots      \\
w_nf_0(\sigma+ n)   +w_{n-1}f_1(\sigma+ n-1)+ \cdots +w_0f_n(\sigma )  =0.
\end{array}
\label{2011-m-ch-sf-pss2sigmaiter}
\end{equation}
which can be used for an inductive determination of the coefficients $w_k$.

Eq. (\ref{2011-m-ch-sf-pss2sigma}) is a quadratic equation
$   \sigma^2 +\sigma (\alpha_{0}-1 ) +  \beta_{0}  =0$
for the
{\em characteristic exponents}
\index{characteristic exponents}
\begin{equation}
\sigma_{1,2} = \frac{1}{2} \left[1 - \alpha_{0} \pm \sqrt{(1 - \alpha_{0})^2-4  \beta_{0}}\right]
\end{equation}
We state without proof that, if the difference of the characteristic exponents
\begin{equation}
\sigma_1 - \sigma_2  =   \sqrt{(1 - \alpha_{0})^2-4  \beta_{0}}
\end{equation}
is  {\em nonzero} and {\em not} an integer, then the two solutions found from   $\sigma_{1,2}$
through  the generalized series Ansatz  (\ref{2011-m-ch-sf-pss2}) are linear independent.

If, however $\sigma_1=\sigma_2+n$ with $n\in {\Bbb Z}$
then we can only obtain a {\em single} solution of the Fuchsian equation.
In order to obtain anotherlinear  independent solution we have to employ the
d'Alambert reduction, which is a general method to obtain another, linear independent solution
\index{d'Alambert reduction}
$y_2(x)$ from an existing particular solution  $y_1(x)$ by
\begin{equation}
y_2(x)=y_1(x)\int_x u(s)ds.
\label{2011-m-ch-sf-dalambansatz}
\end{equation}
Inserting $y_2(x)$ from (\ref{2011-m-ch-sf-dalambansatz}) into the Fuchsian equation (\ref{2011-m-ch-sf-fc2}),
and using the fact that by assumption $y_1(x)$
is a solution of it,
yields
\begin{equation}
\begin{array}{l}
\frac{d^2}{dx^2}y_2(x) + d(x)  \frac{d}{dx}y_2(x)+  e(x) y_2(x)
 =
0, \\
\frac{d^2}{dx^2}y_1(x)\int_x u(s)ds + d(x)  \frac{d}{dx}y_1(x)\int_x u(s)ds+  e(x) y_1(x)\int_x u(s)ds
 =
0, \\
\frac{d }{dx }\left\{
\left[\frac{d }{dx }y_1(x)\right]\int_x u(s)ds
+y_1(x)  u(x) \right\}   \\ \qquad
+ d(x)  \left[\frac{d}{dx}y_1(x)\right] \int_x u(s)ds+y_1(x)  u(x)
+  e(x) y_1(x)\int_x u(s)ds
 =
0, \\
\left[ \frac{d^2 }{dx^2 }y_1(x)\right] \int_x u(s)ds
+\left[ \frac{d  }{dx  }y_1(x)\right]   u(x)
+\left[ \frac{d  }{dx  }y_1(x)\right]   u(x)
+y_1(x)  \left[ \frac{d  }{dx  }u(x)\right]    \\ \qquad
+ d(x)  \left[ \frac{d}{dx}y_1(x)\right] \int_x u(s)ds+ d(x) y_1(x)  u(x)
+  e(x) y_1(x)\int_x u(s)ds
 =
0, \\
\left[ \frac{d^2 }{dx^2 }y_1(x)\right] \int_x u(s)ds
+ d(x)  \left[ \frac{d}{dx}y_1(x)\right] \int_x u(s)ds
+  e(x) y_1(x)\int_x u(s)ds      \\ \qquad
+ d(x) y_1(x)  u(x)
+\left[ \frac{d  }{dx  }y_1(x)\right]   u(x)
+\left[ \frac{d  }{dx  }y_1(x)\right]   u(x)
+y_1(x)  \left[ \frac{d  }{dx  }u(x)\right]
 =
0, \\
\left[ \frac{d^2 }{dx^2 }y_1(x)\right] \int_x u(s)ds
+ d(x)  \left[ \frac{d}{dx}y_1(x)\right] \int_x u(s)ds
+  e(x) y_1(x)\int_x u(s)ds      \\ \qquad
+y_1(x)  \left[ \frac{d  }{dx  }u(x)\right]
+2\left[ \frac{d  }{dx  }y_1(x)\right]   u(x)
 + d(x) y_1(x)  u(x)
 =
0, \\
\left\{\left[ \frac{d^2 }{dx^2 }y_1(x)\right]
+ d(x)  \left[ \frac{d}{dx}y_1(x)\right]
+  e(x) y_1(x)\right\}\int_x u(s)ds      \\ \qquad
+y_1(x)  \left[ \frac{d  }{dx  }u(x)\right]
+\left\{ 2\left[ \frac{d  }{dx  }y_1(x)\right]
  + d(x) y_1(x) \right\} u(x)
 =
0, \\
 y_1(x)  \left[ \frac{d  }{dx  }u(x)\right]
+\left\{ 2\left[ \frac{d  }{dx  }y_1(x)\right]
  + d(x) y_1(x) \right\} u(x)
 =
0,
\end{array}
\end{equation}
and finally,
\begin{equation}
     u'(x) + u(x)   \left\{ 2 \frac{y'_1(x)}{y_1(x)}    + d(x) \right\} = 0.
\label{2011-m-ch-sf-fc2123}
\end{equation}

{
\color{blue}
\bexample

Let us consider some examples involving Fuchsian equations of the second order.

\begin{enumerate}


\item
 Let
 $w'' +p_1(z)w' +p_2(z)w=0$
a Fuchsian equation.
Derive
from the Laurent series expansion of $p_1(z)$ and $p_2(z)$ with Cauchy's integral formula
the following equations:
\begin{equation}
\begin{array}{l}
\alpha_0=\lim_{z\rightarrow z_0} (z-z_0)p_1(z),\\
\beta_0=\lim_{z\rightarrow z_0} (z-z_0)^2p_2(z),
\end{array}
\end{equation}
 where $z_0$ is a regular singular point.

Let us consider {$\alpha_0$ }  and the Laurent series for
$$
   p_1(z)=\sum_{k=-1}^\infty \tilde a_k(z-z_0)^k
\textrm{ with}
   \tilde a_k={1\over 2\pi i}\oint p_1(s)(s-z_0)^{-(k+1)}ds.
$$
The summands  vanish  for $k<-1$, because $p_1(z)$ has at most a pole of order one at $z_0$.
Let us change the index : $n=k+1$ ($\Longrightarrow k=n-1$) and
$\alpha_n:=\tilde a_{n-1}$; then
$$ p_1(z)
=\sum_{n=0}^\infty \alpha_n(z-z_0)^{n-1},$$
where $$  \alpha_n={\tilde a}_{n-1}={1\over 2\pi i}
\oint p_1(s)(s-z_0)^{-n}ds;$$
in particular,
$$ \alpha_0={1\over2\pi i}\oint p_1(s)ds.$$
Because the equation is Fuchsian,  $p_1(z)$ has only a pole of order one at $z_0$; and $p_1(z)$ is of the form
$$
   p_1(z)={a_1(z)\over(z-z_0)}={p_1(z)(z-z_0)\over(z-z_0)}
$$
and
$$
   \alpha_0={1\over2\pi i}\oint{p_1(s)(s-z_0)\over(s-z_0)}ds,
$$
where $p_1(s)(s-z_0)$ is analytic around $z_0$; hence we can apply Cauchy's integral formula:
$$
   \alpha_0=\lim_{s\to z_0}p_1(s)(s-z_0)
$$

An easy way to see this is with the
{\em Ansatz}: $  p_1(z)=\sum_{n=0}^\infty\alpha_n(z-z_0)^{n-1}$;
multiplication with $(z-z_0)$ yields
$$
   (z-z_0)p_1(z)=\sum_{n=0}^\infty\alpha_n(z-z_0)^n .
$$
In the limit $z\to z_0$,
$$
   \lim_{z\to z_0}(z-z_0)p_1(z)=\alpha_n
$$


\noindent  Let us consider {$\beta_0$ } and the Laurent series for
$$
   p_2(z)=\sum_{k=-2}^\infty \tilde b_k(z-z_0)^k
\textrm{ with}
   \tilde b_k={1\over 2\pi i}\oint p_2(s)(s-z_0)^{-(k+1)}ds.
$$
The summands  vanish  for $k<-2$, because $p_2(z)$ has at most a pole of second order  at $z_0$.
Let us change the index : $n=k+2$ ($\Longrightarrow k=n-2$) and
$\beta_n:=\tilde b_{n-2}$.
Hence,
$$
p_2(z)=\sum_{n=0}^\infty\beta_n(z-z_0)^{n-2},$$
where $$  \beta_n={1\over 2\pi i}\oint
p_2(s)(s-z_0)^{-(n-1)}ds,$$
in particular,
$$\beta_0={1\over2\pi i}
\oint p_2(s)(s-z_0)ds.$$
Because the equation is Fuchsian,  $p_2(z)$ has only a pole of the order of two at $z_0$; and $p_2(z)$ is of the form
$$
   p_2(z)={a_2(z)\over(z-z_0)^2}={p_2(z)(z-z_0)^2\over(z-z_0)^2}
$$
where $a_2(z)=p_2(z)(z-z_0)^2$ is analytic around $z_0$
$$
   \beta_0={1\over2\pi i}\oint{p_2(s)(s-z_0)^2\over(s-z_0)}ds  ;
$$   hence we can apply Cauchy's integral formula
$$
   \beta_0=\lim_{s\to z_0}p_2(s)(s-z_0)^2.
$$

An easy way to see this is with the
{\em Ansatz}: $p_2(z)=\sum_{n=0}^\infty\beta_n(z-z_0)^{n-2}$.
multiplication with $(z-z_0)^2$, in the limit $z\to z_0$, yields
$$
   \lim_{z\to z_0}(z-z_0)^2p_2(z)=\beta_n
$$





\item
For $z=\infty$, transform the Fuchsian equation $w'' +p_1(z)w' +p_2(z)w=0$   above
into the new variable $t={1\over z}$.

$$ t={1\over z},\ z={1\over t},\ u(t):=
w\left({1\over t}\right)=w(z)$$
$$  {dz\over dt}=-{1\over t^2}\Longrightarrow{d\over dz}=
-t^2{d\over dt}$$
$${d^2\over dz^2}=-t^2{d\over dt}\left(-t^2{d\over dt}\right)=
-t^2\left(-2t{d\over dt}-t^2{d^2\over dt^2}\right)=
2t^3{d\over dt}+t^4{d^2\over dt^2}$$
$$ w'(z)={d\over dz}w(z)=-t^2{d\over dt}u(t)=
-t^2u'(t)$$
$$  w''(z)={d^2\over dz^2}w(z)=
\left(2t^3{d\over dt}+t^4
{d^2\over dt^2}\right)u(t)=2t^3u'(t)+t^4u''(t)$$

Insertion into the Fuchsian equation $w''+p_1(z)w'+p_2(z)w=0 $ yields
$$
   2t^3u'+t^4u''+p_1\left({1\over t}\right)(-t^2u')+
   p_2\left({1\over t}\right)u=0,
$$
and hence,
$$
    u''+\left[{2\over t}-{p_1\left({1\over t}\right)
   \over t^2}\right]u'+{p_2\left({1\over t}\right)\over t^4}u=0
$$
with $\displaystyle \tilde p_1(t):=\left[{2\over t}-
{p_1\left({1\over t}\right)\over t^2}\right]$ und
$\displaystyle \tilde p_2(t):={p_2\left({1\over t}\right)\over t^4}$ ist
$u''+\tilde p_1(t)u'+\tilde p_2(t)u=0$.


\item
Find out whether the following differential equations are Fuchsian,
and enumerate the regular singular points:
\begin{equation}
\begin{array}{l}
zw''+(1-z)w'=0 ,  \\
z^2w''+zw'-\nu ^2 w=0 ,  \\
z^2(1+z)^2w''+2z(z+1)(z+2)w'-4w=0 , \\
2z(z+2)w'' +w' -zw=0.
\end{array}
\end{equation}

{ ad 1:} $\displaystyle zw''+(1-z)w'=0\ \Longrightarrow
\ w''+{(1-z)\over z}w'=0$\\[2ex]
 {$z=0$:}
$$
   \alpha_0=\lim_{z\to0}z{(1-z)\over z}=1,\quad
   \beta_0=\lim_{z\to0}z^2\cdot0=0.
$$
The equation for the characteristic exponent is
$$
   \sigma(\sigma-1)+\sigma\alpha_0+\beta_0=0\Longrightarrow
   \sigma^2-\sigma+\sigma=0\Longrightarrow\sigma_{1,2}=0.
$$

\bigskip

\noindent  {$z=\infty$:} $  z={1\over t}$
$$
   \tilde p_1(t)={2\over t}-{{\left(1-{1\over t}\right)\over{1\over t}}\over
   t^2}={2\over t}-{\left(1-{1\over t}\right)\over t}={1\over t}
   +{1\over t^2}={t+1\over t^2}
$$
$\Longrightarrow$ not Fuchsian.

\bigskip

\noindent {  ad 2:} $\displaystyle z^2w''+zw'-v^2w=0\Longrightarrow
w''+{1\over z}w'-{v^2\over z^2}w=0$.\\[2ex]
 {$z=0$:}
$$
   \alpha_0=\lim_{z\to0}z{1\over z}=1,\quad
   \beta_0=\lim_{z\to0}z^2\left(-{v^2\over z^2}\right)=-v^2.
$$
$$
   \Longrightarrow \sigma^2-\sigma+\sigma-v^2=0\Longrightarrow\sigma_{1,2}=
   \pm v
$$

\bigskip

\noindent  {$z=\infty$:} $  z={1\over t}$
\begin{eqnarray*}
   \tilde p_1(t)&=&{2\over t}-{1\over t^2}t={1\over t}\\
   \tilde p_2(t)&=&{1\over t^4}\left(-t^2v^2\right)=-{v^2\over t^2}
\end{eqnarray*}
$$
   \Longrightarrow u''+{1\over t}u'-{v^2\over t^2}u=0 \Longrightarrow
   \sigma_{1,2}=\pm v
$$
$\Longrightarrow$ Fuchsian equation.

\bigskip

\noindent {  ad 3:}
$$
   z^2(1+z)^2w''+2z(z+1)(z+2)w'-4w=0\Longrightarrow
   w''+{2(z+2)\over z(z+1)}w'-{4\over z^2(1+z)^2}w=0
$$
 {$z=0$:}
$$
   \alpha_0=\lim_{z\to0}z{2(z+2)\over z(z+1)}=4,\quad
   \beta_0=\lim_{z\to0}z^2\left(-{4\over z^2(1+z)^2}\right)=-4.
$$
$$
   \Longrightarrow\sigma(\sigma-1)+4\sigma-4=\sigma^2+3\sigma-4=0
   \Longrightarrow\sigma_{1,2}=
   {-3\pm\sqrt{9+16}\over 2}=\left\{{-4\atop +1}\right.
$$
 {$z=-1$:}
$$
   \alpha_0=\lim_{z\to-1}(z+1){2(z+2)\over z(z+1)}=-2,\quad
   \beta_0=\lim_{z\to-1}(z+1)^2\left(-{4\over z^2(1+z)^2}\right)=-4.
$$
$$
   \Longrightarrow\sigma(\sigma-1)-2\sigma-4=\sigma^2-3\sigma-4=
   0\Longrightarrow\sigma_{1,2}=
   {3\pm\sqrt{9+16}\over 2}=\left\{{+4\atop -1}\right.
$$
 {$z=\infty$:}
\begin{eqnarray*}
   \tilde p_1(t)&=&{2\over t}-{1\over t^2}{2\left({1\over t}+2\right)
                   \over {1\over t}\left({1\over t}+1\right)}=
                   {2\over t}-{2\left({1\over t}+2\right)\over
                   1+t}={2\over t}\left(1-{1+2t\over 1+t}\right)\\
   \tilde p_2(t)&=&{1\over t^4}\left(-{4\over{1\over t^2}
                   \left(1+{1\over t}\right)^2}\right)=-{4\over t^2}
                   {t^2\over(t+1)^2}=-{4\over(t+1)^2}
\end{eqnarray*}
$$
   \Longrightarrow u''+{2\over t}\left(1-{1+2t\over1+t}\right)u'-
   {4\over(t+1)^2}u=0
$$
$$
   \alpha_0=\lim_{t\to0}t{2\over t}\left(1-{1+2t\over1+t}\right)=0,\quad
   \beta_0=\lim_{t\to0}t^2\left(-{4\over (t+1)^2}\right)=0.
$$
$$
   \Longrightarrow\sigma(\sigma-1)=0\Longrightarrow\sigma_{1,2}=
   \left\{{0\atop 1}\right.
$$
$\Longrightarrow$ Fuchsian equation.

\bigskip

\noindent {  ad 4:}
$$
   2z(z+2)w''+w'-zw=0\Longrightarrow w''+{1\over 2z(z+2)}w'-{1\over 2(z+2)}w=0
$$
 {$z=0$:}
$$
   \alpha_0=\lim_{z\to0}z{1\over 2z(z+2)}={1\over4},\quad
   \beta_0=\lim_{z\to0}z^2{-1\over 2(z+2)}=0.
$$
$$
   \Longrightarrow\sigma^2-\sigma+{1\over 4}\sigma=0\Longrightarrow
   \sigma^2-{3\over 4}\sigma=0\Longrightarrow\sigma_1=0,\sigma_2={3\over 4}.
$$
 {$z=-2$:}
$$
   \alpha_0=\lim_{z\to-2}(z+2){1\over 2z(z+2)}=-{1\over 4},\quad
   \beta_0=\lim_{z\to-2}(z+2)^2{-1\over 2(z+2)}=0.
$$
$$
   \Longrightarrow\sigma_1=0,\quad\sigma_2={5\over 4}.
$$
 {$z=\infty$:}
\begin{eqnarray*}
   \tilde p_1(t)&=&{2\over t}-{1\over t^2}\left({1\over 2{1\over t}
                   \left({1\over t}+2\right)}\right)={2\over t}-
                   {1\over 2(1+2t)}\\
   \tilde p_2(t)&=&{1\over t^4}{(-1)\over 2\left({1\over t}+2\right)}=
                   -{1\over 2t^3(1+2t)}
\end{eqnarray*}
$\Longrightarrow$ no Fuchsian.
Klasse!

\item
Determine the solutions of
$$z^2w''+(3z+1)w'+w=0 $$  around the regular singular points.

The singularities are at $z=0$ and $z=\infty$.

\noindent  {Singularities   at $z=0$:}
$$
   p_1(z)={3z+1\over z^2}=
   {a_1(z)\over z} \qquad \mbox{mit} \qquad
   a_1(z)=3+{1\over z}
$$
  $p_1(z)$ has a pole of higher order than one; hence this is no Fuchsian equation;
and  $z=0$
is an irregular singular point.

\noindent  {Singularities   at $z=\infty$:}
\begin{itemize}
\item Transformation $\displaystyle z={1\over t}$, $w(z)\to u(t)$:
      $$
         u''(t)+\left[{2\over t}-{1\over t^2}p_1\left({1\over t}\right)
         \right]\cdot u'(t)+{1\over t^4}p_2\left({1\over t}\right)\cdot
         u(t)=0.
      $$
      The new coefficient functions are
      \begin{eqnarray*}
         \tilde p_1(t)&=&{2\over t}-{1\over t^2}p_1\left({1\over t}\right)=
                         {2\over t}-{1\over t^2}(3t+t^2)={2\over t}
                         -{3\over t}-1=-{1\over t}-1\\
         \tilde p_2(t)&=&{1\over t^4}p_2\left({1\over t}\right)=
                         {t^2\over t^4}={1\over t^2}
      \end{eqnarray*}
\item check whether this is a  regular singular point:
      $$
         \begin{array}{lll}
            \displaystyle \tilde p_1(t)=-{1+t\over t}={\tilde a_1(t)\over t} &
            ~~\mbox{mit}~~\tilde a_1(t)=-(1+t)&~\mbox{regul\"ar}\\
            \displaystyle \tilde p_2(t)={1\over t^2}={\tilde a_2(t)\over t^2} &
            ~~\mbox{mit}~~\tilde a_2(t)=1&~\mbox{regul\"ar}
         \end{array}
      $$
      $\tilde a_1$ and $\tilde a_2$ are regular at $t=0$, hence  this is a  regular singular point.
\item {\it Ansatz} around $t=0$:
the transformed equation is
      \begin{eqnarray*}
         u''(t)+\tilde p_1(t)u'(t)+\tilde p_2(t)u(t)&=&0\\
         u''(t)-\left({1\over t}+1\right)u'(t)+{1\over t^2}u(t)&=&0\\
         t^2 u''(t)-(t+t^2)u'(t)+u(t)&=&0
      \end{eqnarray*}
      The generalized power series is
      \begin{eqnarray*}
         u(t)  &=&\sum_{n=0}^\infty w_n t^{n+\sigma}\\
         u'(t) &=&\sum_{n=0}^\infty w_n (n+\sigma)t^{n+\sigma-1}\\
         u''(t)&=&\sum_{n=0}^\infty w_n (n+\sigma)(n+\sigma-1)
                  t^{n+\sigma-2}
      \end{eqnarray*}
      If we insert this into the transformed differential equation we obtain
      $$
         \begin{array}{l}
           t^2\sum_{n=0}^\infty w_n(n+\sigma)
             (n+\sigma-1)t^{n+\sigma-2}-\\
           \qquad\quad -\ (t+t^2)\sum_{n=0}^\infty
             w_n(n+\sigma)t^{n+\sigma-1}+
             \sum_{n=0}^\infty w_n t^{n+\sigma}=0\\
          \sum_{n=0}^\infty w_n(n+\sigma)(n+\sigma-1)t^{n+\sigma}-
             \sum_{n=0}^\infty w_n(n+\sigma)t^{n+\sigma}-\\
           \qquad\quad -\ \sum_{n=0}^\infty w_n(n+\sigma)
             t^{n+\sigma+1}+\sum_{n=0}^\infty w_n t^{n+\sigma}=0
         \end{array}
      $$
      Change of index: $m=n+1$, $n=m-1$ in the third sum yields
      $$
         \sum_{n=0}^\infty w_n\Bigl[(n+\sigma)(n+\sigma-2)+1\Bigr]
         t^{n+\sigma}-
         \sum_{m=1}^\infty w_{m-1}(m-1+\sigma)t^{m+\sigma}=0.
      $$
      In the second sum, substitute $m$ for $n$
      $$
         \sum_{n=0}^\infty w_n\Bigl[(n+\sigma)(n+\sigma-2)+1\Bigr]
         t^{n+\sigma}-
         \sum_{n=1}^\infty w_{n-1}(n+\sigma-1)t^{n+\sigma}=0.
      $$
      We write out explicitly the  $n=0$ term of the first sum
      $$
         \begin{array}{l}
            \displaystyle w_0\Bigl[\sigma(\sigma-2)+1\Bigr]t^\sigma+
               \sum_{n=1}^\infty w_n\Bigl[(n+\sigma)(n+\sigma-2)+1\Bigr]
               t^{n+\sigma}-\\
            \displaystyle \qquad -\ \sum_{n=1}^\infty
               w_{n-1}(n+\sigma-1)t^{n+\sigma}=0.
         \end{array}
      $$
      Now we can combine the two sums
      $$
         \begin{array}{l}
         \displaystyle w_0\Bigl[\sigma(\sigma-2)+1\Bigr]t^\sigma+\\
         \displaystyle \quad +\, \sum_{n=1}^\infty
            \Bigl\{w_n\Bigl[(n+\sigma)(n+\sigma-2)+1\Bigr]
            -w_{n-1}(n+\sigma-1)\Bigr\}t^{n+\sigma}=0.
         \end{array}
      $$
      The left hand side can only vanish for all  $t$ if the coefficients vanish; hence
      \begin{eqnarray}
         w_0\Bigl[\sigma(\sigma-2)+1\Bigr]&=&0, \label{eqn:5.3.1}\\
         w_n\Bigl[(n+\sigma)(n+\sigma-2)+1\Bigr]-
            w_{n-1}(n+\sigma-1)&=&0. \label{eqn:5.3.2}
      \end{eqnarray}
      ad (\ref{eqn:5.3.1}) for $w_0$:
      \begin{eqnarray*}
         \sigma(\sigma-2)+1&=&0\\
         \sigma^2-2\sigma+1&=&0\\
         (\sigma-1)^2&=&0\quad \Longrightarrow\ \sigma_\infty^{(1,2)}=1
      \end{eqnarray*}
      The charakteristic exponent is $\sigma_\infty^{(1)}=
      \sigma_\infty^{(2)}=1$.\medskip\\
      ad (\ref{eqn:5.3.2})for $w_n$:
      For the coefficients $w_n$we have the recursion formula
      \begin{eqnarray*}
         w_n\Bigl[(n+\sigma)(n+\sigma-2)+1\Bigr]&=&w_{n-1}(n+\sigma-1)\\
         \Longrightarrow\ w_n&=&{n+\sigma-1\over (n+\sigma)(n+\sigma-2)+1}
         w_{n-1}.
      \end{eqnarray*}
      Let us insert $\sigma=1$:
      $$
         w_n={n\over (n+1)(n-1)+1}w_{n-1}={n\over n^2-1+1}w_{n-1}=
         {n\over n^2}w_{n-1}={1\over n}w_{n-1}.
      $$
      We can fix $w_0=1$, hence:
      \begin{eqnarray*}
         w_0&=&1={1\over 1}={1\over 0!}\\
         w_1&=&{1\over 1}={1\over 1!}\\
         w_2&=&{1\over 1\cdot 2}={1\over 2!}\\
         w_3&=&{1\over 1\cdot 2\cdot 3}={1\over 3!}\\
         &\vdots\\
         w_n&=&{1\over 1\cdot 2\cdot 3\cdot\,\cdots\,\cdot n}={1\over n!}
      \end{eqnarray*}
      And finally,
      $$
         u_1(t)=t^\sigma\sum_{n=0}^\infty w_n t^n=t\sum_{n=0}^\infty
         {t^n\over n!}=te^t .
      $$
\item Notice that both characteristic exponents are equal; hence we have to employ  the
d'Alambert reduction
      $$
         u_2(t)=u_1(t)\int\limits_0^t v(s)ds
      $$
      with
      $$
         v'(t)+v(t)\left[2{u_1'(t)\over u_1(t)}+\tilde p_1(t)\right]=0.
      $$
     Insertion of $u_1$ and $\tilde p_1$ ein,
      \begin{eqnarray*}
         u_1(t)&=&te^t\\
         u_1'(t)&=&e^t(1+t)\\
         \tilde p_1(t)&=&-\left({1\over t}+1\right),
      \end{eqnarray*}
      yields
      \begin{eqnarray*}
         v'(t)+v(t)\left(2{e^t(1+t)\over te^t}-{1\over t}-1\right)&=&0\\
         v'(t)+v(t)\left(2{(1+t)\over t}-{1\over t}-1\right)&=&0\\
         v'(t)+v(t)\left({2\over t}+2-{1\over t}-1\right)&=&0\\
         v'(t)+v(t)\left({1\over t}+1\right)&=&0\\
         {dv\over dt}&=&-v\left(1+{1\over t}\right)\\
         {dv\over v}&=&-\left(1+{1\over t}\right)dt
      \end{eqnarray*}
      Upon integration of both sides we obtain
      \begin{eqnarray*}
         \int{dv\over v}&=&-\int\left(1+{1\over t}\right)dt\\
         \log v&=&-(t+\log t)=-t-\log t\\
         v&=&\exp(-t-\log t)=e^{-t}e^{-\log t}={e^{-t}\over t},
      \end{eqnarray*}
      and hence an explicit form of $v(t)$:
      $$
         v(t)={1\over t}e^{-t}.
      $$
      If we insert this into the equation for  $u_2$ we   obtain
      $$
         u_2(t)=te^t\int_0^t{1\over t}e^{-t}dt.
      $$

\item Therefore, with $  t={1\over z}$, $u(t)=w(z)$,
      the two linear independent solutions around the regular singular point at $z=\infty$ are
      \begin{eqnarray*}
         w_1(z)&=&{1\over z}\exp\left({1\over z}\right)\textrm{, and}\\
         w_2(z)&=&{1\over z}\exp\left({1\over z}\right)
                \int\limits_0^{1\over z}{1\over t}e^{-t}dt.
      \end{eqnarray*}
\end{itemize}

\end{enumerate}
\eexample
}




\section{Hypergeometric function}
\index{hypergeometric function}

\subsection{Definition}
A
{\em hypergeometric series}
\index{hypergeometric series}
is a series
\begin{equation}
\sum_{j=0}^\infty c_j ,
\label{2011-m-ch-sfhserd}
\end{equation}
with $c_{j+1}/c_j$ is a {\em rational function} of $j$, so that it can be factorized by
\begin{equation}
\frac{c_{j+1}}{c_j}
=
\frac{(j+a_1)(j+a_2)\cdots (j+a_p)}{(j+b_1)(j+b_2)\cdots (j+b_q)}
\frac{x}{j+1}.
\label{2011-m-ch-sfhser}
\end{equation}
The factor $j+1$ in the denominator has been chosen to define the fachtor $j!$ in the definition below; if
it does not arise ``naturally''  we may just obtain it by compensating it with the factor $j+1$ in the numerator.
With this ratio, the hypergeometric series (\ref{2011-m-ch-sfhserd}) can be written i terms of
{\em shifted factorials},
\index{shifted factorial}
or, by another naming,
the
{\em Pochhammer symbol},
\index{Pochhammer symbol}
as
\begin{equation}
\begin{array}{l}
\sum_{j=0}^\infty c_j \\
\qquad =
 c_0 \sum_{j=0}^\infty  \frac{( a_1)_j( a_2)_j\cdots ( a_p)_j}{( b_1)_j( b_2)_j\cdots ( b_q)_j}
\frac{x^j}{j!}
\\
\qquad =
c_0 {{}_pF_q} \left(
\begin{array}{cc}
a_1,\ldots ,a_p\\
b_1,\ldots ,b_p
\end{array} ; x
\right)     \textrm{, or}\\
\qquad =
c_0 {{}_pF_q} \left(
a_1,\ldots ,a_p;
b_1,\ldots ,b_p
 ; x
\right) .     \\
\end{array}
\label{2011-m-ch-sfhserd1}
\end{equation}

Apart from this definition {\it via}
hypergeometric series, the Gauss {\em hypergeometric function},
or, used synonymuously,
the {\em Gauss series}
\index{Gauss series}
\begin{equation}
\begin{array}{l}
{\;}_2F_1 \left(
\begin{array}{cc}
a ,b\\
c
\end{array} ; x
\right)
={\;}_2F_1 \left(
a ,b;c ; x
\right)
=   \sum_{j=0}^\infty  \frac{( a)_j( b)_j}{(c)_j} \frac{x^j}{j!}
\\
\qquad
=
1+ \frac{ab}{c} x   + \frac{1}{2!}\frac{a(a+1)b(b+1)}{c(c+1)} x^2
\end{array}
\end{equation}
can be defined as a solution of a {\em Fuchsian differential equation}
which has at most {\em three regular singularities}
at $0$, $1$, and $\infty$.

Indeed, any Fuchsian  equation
with
finite  {regular singularities} at $x_1$ and $x_2$ can be rewritten into the Gaussian form with
regular singularities
at $0$, $1$, and $\infty$.
\marginpar{The Bessel equation has a regular singular point at $0$, and an irregular singular point at infinity.
\index{Bessel equation}}
This can be demonstrated by rewriting any such equation of the form
\begin{equation}
\begin{array}{l}
 w''(x) + \left( \frac{A_1}{x-x_1}    + \frac{A_2}{x-x_2}
\right) w'(x)
\\ \qquad + \left(  \frac{B_1}{(x-x_1)^2}+\frac{B_2}{(x-x_2)^2} +\frac{C_1}{x-x_1} +\frac{C_2}{x-x_2}
\right)  w(x)  =0
\end{array}
\label{2011-m-ch-sfhserd12}
\end{equation}
through transforming Eq. (\ref{2011-m-ch-sfhserd12}) into the  {\em hypergeometric equation}
\index{hypergeometric equation}
\begin{equation}
\left[{}\frac{d^2}{dx^2}+ \frac{(a+b+1)x-c}{x(x-1)}\frac{d}{dx}+\frac{ab}{x(x-1)} \right]
{\;}_2F_1(a,b;c;x)=0,
\label{2011-m-ch-sfhserd121eq}
\end{equation}
where the solution is proportional to the Gauss hypergeometric function
\begin{equation}
w(x) \longrightarrow (x-x_1)^{\sigma^{(1)}_1} (x-x_2)^{ \sigma^{(2)}_2} {\;}_2F_1(a,b;c;x),
\end{equation}
 and the variable transform as
\begin{equation}
\begin{array}{l}
x \longrightarrow x = \frac{x-x_1}{x_2-x_1}  \textrm{, with}\\
a=  {\sigma^{(1)}_1}+{\sigma^{(1)}_2}   +{\sigma^{(1)}_\infty},  \\
b=  {\sigma^{(1)}_1}+{\sigma^{(1)}_2}   +{\sigma^{(2)}_\infty} ,\\
c= 1+ {\sigma^{(1)}_1}   -{\sigma^{(2)}_1} .
\end{array}
\label{2011-m-ch-sfhserd121}
\end{equation}
where $\sigma^{(i)}_j$ stands for the $i$th characteristic exponent of the $j$th singularity.


{\color{OliveGreen}
\bproof

Whereas the full transformation from Eq. (\ref{2011-m-ch-sfhserd12})
to the hypergeometric equation  (\ref{2011-m-ch-sfhserd121eq}) will not been given, we shall show that
the Gauss hypergeometric function ${\;}_2F_1$ satisfies the hypergeometric equation (\ref{2011-m-ch-sfhserd121eq}).

First, define the differential operator
\begin{equation}
\vartheta = x \frac{d}{dx} ,
\label{2011-m-ch-sfhserddovt}
\end{equation}
and observe that
\begin{equation}
\begin{array}{l}
\vartheta (\vartheta +c-1) x^n
=x \frac{d}{dx} \left( x \frac{d}{dx} +c-1\right) x^n\\  \qquad
=x \frac{d}{dx} \left( x n  x^{n-1}+c x^n- x^n\right)\\  \qquad
=x \frac{d}{dx} \left(   n  x^{n}+c x^n- x^n\right)\\     \qquad
=x \frac{d}{dx} \left(  n +c-1\right) x^n\\              \qquad
=n\left(  n +c-1\right) x^n.
\end{array}
\label{2011-m-ch-sfhserddovd1}
\end{equation}

Thus, if we apply  $\vartheta (\vartheta +c-1)$ to ${\;}_2F_1$, then
\begin{equation}
\begin{array}{l}
\vartheta (\vartheta +c-1) {\;}_2F_1 (a,b;c;x)
\\  \qquad
=  \vartheta (\vartheta +c-1) \sum_{j=0}^\infty  \frac{( a)_j( b)_j}{(c)_j} \frac{x^j}{j!}
\\  \qquad
=   \sum_{j=0}^\infty  \frac{( a)_j( b)_j}{(c)_j} \frac{j(j+c-1)x^j}{j!}
\\  \qquad
=   \sum_{j=1}^\infty  \frac{( a)_j( b)_j}{(c)_j} \frac{j(j+c-1)x^j}{j!}
\\  \qquad
=   \sum_{j=1}^\infty  \frac{( a)_j( b)_j}{(c)_j} \frac{ (j+c-1)x^j}{(j-1)!}
\\  \qquad
\textrm{[index shift: } j\rightarrow n+1, n=j-1, n\ge 0\textrm{]}
\\  \qquad
=   \sum_{n=0}^\infty  \frac{( a)_{n+1}( b)_{n+1}}{(c)_{n+1}} \frac{ ({n+1}+c-1)x^{n+1}}{n!}
\\  \qquad
=  x \sum_{n=0}^\infty  \frac{( a)_{n}(a+n)( b)_{n}(b+n)}{(c)_{n}(c+n)} \frac{ ({n }+c)x^{n}}{n!}
\\  \qquad
=  x\sum_{n=0}^\infty  \frac{( a)_{n}( b)_{n}}{(c)_{n}} \frac{(a+n) (b+n)x^{n}}{n!}
\\  \qquad
=   x(\vartheta +a)(\vartheta +b)  \sum_{n=0}^\infty  \frac{( a)_{n}( b)_{n}}{(c)_{n}} \frac{x^{n}}{n!}
\\  \qquad
=   x(\vartheta +a)(\vartheta +b)  {\;}_2F_1(a,b;c;x)
,
\end{array}
\label{2011-m-ch-sfhserddovd123}
\end{equation}
where we have used that
\begin{equation}
(a)_{n+1}=a(a+1)\cdots (a+n-1)(a+n) =  (a)_{n}(a+n).
\end{equation}
Writing out $\vartheta$ in  Eq. (\ref{2011-m-ch-sfhserddovd123}) explicitly yields
\begin{equation}
\begin{array}{l}
\left\{\vartheta (\vartheta +c-1)  -   x(\vartheta +a)(\vartheta +b)\right\}  {\;}_2F_1(a,b;c;x) =0,
   \\ \qquad
\left\{x \frac{d}{dx} \left(x \frac{d}{dx} +c-1\right)    -   x\left(x \frac{d}{dx}+a\right)\left(x \frac{d}{dx} +b\right) \right\}  {\;}_2F_1(a,b;c;x) =0,
   \\ \qquad
\left\{ \frac{d}{dx} \left(x \frac{d}{dx} +c-1\right)    -    \left(x \frac{d}{dx}+a\right)\left(x \frac{d}{dx} +b\right) \right\}  {\;}_2F_1(a,b;c;x) =0,
   \\ \qquad
\left\{ \frac{d}{dx} + x \frac{d^2}{dx^2} +(c-1)\frac{d}{dx}
 -    \left(x^2 \frac{d^2}{dx^2}+ x \frac{d}{dx}+ bx\frac{d}{dx} +  ax \frac{d}{dx} +ab\right) \right\}  {\;}_2F_1(a,b;c;x) =0,
   \\ \qquad
\left\{  \left( x    -x^2 \right)\frac{d^2}{dx^2}
+
\left(
1+c-1-x-x(a+b)
\right)\frac{d}{dx}
+
ab  \right\}  {\;}_2F_1(a,b;c;x) =0
,   \\ \qquad
\left\{ - \left(    x(x-1)\right)\frac{d^2}{dx^2}
-
\left(
c-x(1+a+b)
\right)\frac{d}{dx}
-
ab \right\}  {\;}_2F_1(a,b;c;x) =0,
   \\ \qquad
\left\{ \frac{d^2}{dx^2}
+
\frac{x(1+a+b)-c}{x(x-1)}
\frac{d}{dx}
+
\frac{ab}{x(x-1)} \right\}  {\;}_2F_1(a,b;c;x) =0.
\end{array}
\label{2011-m-ch-sfhserddovd1234}
\end{equation}


\eproof
}

\subsection{Properties}

There exist many properties of the hypergeometric series.
In the following we shall mention a few.


\begin{equation}
{d\over dz}{\;}_2F_1(a,b;c;z)={ab\over c}{\;}_2F_1(a+1,b+1,c+1;z) .
\end{equation}

{\color{OliveGreen}
\bproof

\begin{eqnarray*}
   {d\over dz}{\;}_2F_1(a,b,c;z)&=&{d\over dz}\sum_{n=0}^\infty
                           {(a)_n(b)_n\over(c)_n}{z^n\over n!}=\\
                        &=&\sum_{n=0}^\infty {(a)_n(b)_n\over(c)_n}
                           n{z^{n-1}\over n!}\\
                         &=&\sum_{n=1}^\infty
                           {(a)_n(b)_n\over(c)_n}{z^{n-1}\over(n-1)!}
\end{eqnarray*}
Index shift $n\to n+1$, $m=n-1$:
$$
   {d\over dz}{\;}_2F_1(a,b;c;z)=\sum_{n=0}^\infty
   {(a)_{n+1}(b)_{n+1}\over(c)_{n+1}}{z^n\over n!}
$$
As
\begin{eqnarray*}
   (x)_{n+1}&=&x(x+1)(x+2)\cdots(x+n-1)(x+n)\\
   (x+1)_n  &=&\phantom{x}(x+1)(x+2)\cdots(x+n-1)(x+n)\\
   (x)_{n+1}&=&x(x+1)_n
\end{eqnarray*}
holds, we obtain
$$
   {d\over dz}{\;}_2F_1(a,b;c;z)=\sum_{n=0}^\infty{ab\over c}
   {(a+1)_n(b+1)_n\over(c+1)_n}{z^n\over n!}=
   {ab\over c}{\;}_2F_1(a+1,b+1;c+1;z).
$$

\eproof
}

We state {\em Euler's integral representation} for $\Re c>0$ and $\Re b>0$  without proof:
\begin{equation}
 {\;}_2F_1(a,b;c;x)=\frac{\Gamma(c)}{\Gamma(b)\Gamma(c-b)}
\int_0^1 t^{b-1}(1-t)^{c-b-1}(1-xt)^{-a} dt
.
\end{equation}


For  $\Re (c-a-b)>0$, we also state Gauss' theorem
\index{Gauss theorem}
\begin{equation}
 {\;}_2F_1(a,b;c;1)=\sum_{j=0}^\infty \frac{(a)_j(b)_j}{j! (c)_j} =\frac{\Gamma(c)\Gamma(c-a-b)}{\Gamma(c-a)\Gamma(c-b)}.
\end{equation}

{\color{OliveGreen}
\bproof
For a proof, we can set $x=1$ in Euler's integral representation, and the Beta function defined in Eq.
(\ref{2011-m-ch-sf-beta}).
\eproof
}

\subsection{Plasticity}

Some of the most important elementary functions can be expressed as hypergeometric series; most importantly the Gaussion one ${\;}_2F_1$,
which is
sometimes denoted by just $F$.
Let us enumerate a few.
\begin{eqnarray}
e^x
&=&
{\;}_0F_0(-;-;x)
\\
\cos x
&=&
{\;}_0F_1(-;\frac{1}{2};-\frac{x^2}{4})
\\
\sin x
&=&
x
{\;}_0F_1(-;\frac{3}{2};-\frac{x^2}{4})
\\
(1-x)^{-a}
&=&
{\;}_1F_0(a;-  ;x)
\\
\sin^{-1} x
&=&
x
{\;}_2F_1(\frac{1}{2},\frac{1}{2};\frac{3}{2};x^2)
\\
\tan^{-1} x
&=&
x
{\;}_2F_1(\frac{1}{2},1;\frac{3}{2};-x^2)
\\
\log (1 + x)
&=&
x
{\;}_2F_1(1,1;2;-x)
\\
H_{2n}(x)
&=&
\frac{(-1)^n(2n)!}{n!}
{\;}_1F_1(-n;\frac{1}{2}; x^2)
\\
H_{2n+1}(x)
&=&
2x
\frac{(-1)^n(2n+1)!}{n!}
{\;}_1F_1(-n;\frac{3}{2}; x^2)
\\
L_{n}^\alpha (x)
&=&
\left(
\begin{array}{c}
n+\alpha\\
n
\end{array}
\right)
{\;}_1F_1(-n;\alpha +1; x)
\\
P_{n}(x)
&=&   P^{(0, 0 )}_n (x)
=
{\;}_2F_1(-n,n+1; 1;\frac{1- x}{2}) ,
\\
C_{n}^\gamma (x)
&=& \frac{(2\gamma )_n}{\left( \gamma +\frac{1}{2}\right)_n}  P^{(\gamma -\frac{1}{2}, \gamma -\frac{1}{2} )}_n (x)
 ,
\\
T_{n}  (x)
&=& \frac{n!}{\left(  \frac{1}{2}\right)_n}  P^{( -\frac{1}{2},  -\frac{1}{2} )}_n (x)
,
\\
J_{\alpha }  (x)
&=& \frac{\left(\frac{x}{2}\right)^\alpha }{\Gamma (\alpha +1)}
{\;}_0F_1(- ; \alpha +1;-\frac{1 }{4}x^2) ,
\end{eqnarray}
where
$H$ stands for
{\em Hermite polynomials},
\index{Hermite polynomial}
$L$ for
{\em Laguerre polynomials},
\index{Laguerre polynomial}
\begin{equation}
P^{(\alpha, \beta )}_n (x)
=\frac{(\alpha +1)_n}{n!} {\;}_2F_1(-n,n+\alpha +\beta +1; \alpha +1;\frac{1- x}{2})
\end{equation}
for
{\em Jacobi polynomials},
\index{Jacobi polynomial}
$C$ for
{\em Gegenbauer polynomials},
\index{Gegenbauer polynomial}
$T$ for
{\em Chebyshev polynomials},
\index{Chebyshev polynomial}
$P$  for
{\em Legendre polynomials},
\index{Legendre polynomial}
and
$J$  for   the
{\em Bessel functions of the first kind},
\index{Bessel function}
respectively.

{
\color{blue}
\bexample

\begin{enumerate}

\item
Let us prove that
 $$\log (1-z)=-z {\;}_2F_1(1,1,2;z) . $$
Consider
$$
   {\;}_2F_1(1,1,2;z)=\sum_{m=0}^\infty{[(1)_m]^2\over(2)_m}{z^m\over m!}=
   \sum_{m=0}^\infty{[1\cdot2\cdot\,\cdots\,\cdot m]^2\over
   2\cdot(2+1)\cdot\,\cdots\,\cdot(2+m-1)}{z^m\over m!}
$$
With
$$
   (1)_m=1\cdot2\cdot\,\cdots\,\cdot m=m!,\qquad
   (2)_m=2\cdot(2+1)\cdot\,\cdots\,\cdot (2+m-1)=(m+1)!
$$
follows
$$
   {\;}_2F_1(1,1,2;z)=\sum_{m=0}^\infty{[m!]^2\over(m+1)!}
   {z^m\over m!}=\sum_{m=0}^\infty {z^m\over m+1}.
$$
Index shift $k =m+1$
$$
   {\;}_2F_1(1,1,2;z)=\sum_{k=1}^\infty {z^{k-1}\over k}
$$
and hence
$$
   -z{\;}_2F_1(1,1,2;z)=-\sum_{k=1}^\infty{z^k\over k}.
$$
Compare with the series
$$
   \log(1+x)=\sum_{k=1}^\infty(-1)^{k+1}{x^k\over k}\qquad
   \mbox{f\"ur}\quad -1<x\leq1
$$
If one substitutes $-x$ for $x$, then
$$
   \log(1-x)=-\sum_{k=1}^\infty{x^k\over k}.
$$
The identity follows from the analytic continuation of $x$ to the complex $z$ plane.


\item
Let us prove that,  because of $(a+z)^n=\sum_{k=0}^n\pmatrix{n\cr k\cr }
 z^ka^{n-k}$,
 $$(1-z)^n={\;}_2F_1(-n,1,1;z). $$

$$
   {\;}_2F_1(-n,1,1;z)=\sum_{i=0}^\infty{(-n)_i(1)_i\over(1)_i}{z^i\over i!}=
   \sum_{i=0}^\infty(-n)_i{z^i\over i!}.
$$
Consider $(-n)_i$
$$
   (-n)_i=(-n)(-n+1)\cdots(-n+i-1).
$$

For even$n\geq0$
the series stops after a finite number of terms, because the factor
$-n+i-1=0$ f\"ur $i=n+1$ vanishes;
hence the sum of $i$ extends only
from $0$ to $n$.
Hence, if we collect the factors
 $(-1)$ which yield $(-1)^i$ we obtain
$$
   (-n)_i=(-1)^in(n-1)\cdots[n-(i-1)]=(-1)^i{n!\over(n-i)!}.
$$
Hence, insertion into the Gauss hypergeometric function yields
$$
   {\;}_2F_1(-n,1,1;z)=\sum_{i=0}^n(-1)^iz^i{n!\over i!(n-i)!}=
   \sum_{i=0}^n{n\choose i}(-z)^i.
$$
This is the binomial series
$$
   (1+x)^n=\sum_{k=0}^n{n\choose k}x^k
$$
with $x=-z$; and hence,
$$
   {\;}_2F_1(-n,1,1;z)=(1-z)^n.
$$




\item
 Let us prove that,  because of $\arcsin x=\sum_{k=0}^\infty
 {(2k)!x^{2k+1}\over 2^{2k}(k!)^2(2k+1)}$,
 $${\;}_2F_1\left({1\over 2},{1\over 2},{3\over 2}; \sin^2 z\right)
 ={z\over \sin z }  .$$

Consider
$$
   {\;}_2F_1\left({1\over 2},{1\over 2},{3\over 2};\sin^2z\right)=
   \sum_{m=0}^\infty{\left[\left({1\over 2}\right)_m\right]^2\over
   \left({3\over 2}\right)_m}{(\sin z)^{2m}\over m!}.
$$
We take
\begin{eqnarray*}
   (2n)!!&:=& 2\cdot4\cdot\,\cdots\,\cdot(2n)=n!2^n\\
   (2n-1)!!&:=& 1\cdot3\cdot\,\cdots\,\cdot(2n-1)={(2n)!\over2^n n!}
\end{eqnarray*}
Hence
\begin{eqnarray*}
   \left({1\over 2}\right)_m\!\!\!&=\!\!\!&{1\over 2}\cdot
   \left({1\over 2}+1\right)\cdots\left({1\over 2}+m-1\right)=
   {1\cdot3\cdot5\cdots(2m-1)\over2^m}={(2m-1)!!\over2^m}\\
   \left({3\over 2}\right)_m\!\!\!&=\!\!\!&{3\over 2}\cdot
   \left({3\over 2}+1\right)\cdots\left({3\over 2}+m-1\right)=
   {3\cdot5\cdot7\cdots(2m+1)\over2^m}={(2m+1)!!\over2^m}
\end{eqnarray*}
Therefore,
$$
   {\left({1\over 2}\right)_m\over\left({3\over 2}\right)_m}=
   {1\over 2m+1}.
$$
On the other hand,
\begin{eqnarray*}
   (2m)!&=&1\cdot2\cdot3\cdot\,\cdots\,\cdot(2m-1)(2m)=(2m-1)!!(2m)!!=\\
        &=&1\cdot3\cdot5\cdot\,\cdots\,\cdot(2m-1)\cdot
           2\cdot4\cdot6\cdot\,\cdots\,\cdot(2m)=\\
        &=&\left({1\over 2}\right)_m2^m\cdot2^m m!=2^{2m}m!
           \left({1\over 2}\right)_m
   \Longrightarrow\left({1\over 2}\right)_m={(2m)!\over 2^{2m}m!}
\end{eqnarray*}
Upon insertion one obtains
$$
   F\left({1\over 2},{1\over 2},{3\over 2};\sin^2z\right)=
   \sum_{m=0}^\infty{(2m)!(\sin z)^{2m}\over 2^{2m}(m!)^2(2m+1)}.
$$
Comparing with the series for arcsin one finally obtains
$$
   \sin z F\left({1\over 2},{1\over 2},{3\over 2};\sin^2z\right)=
   \arcsin(\sin z)=z.
$$
\end{enumerate}
\eexample
}

\subsection{Four forms}


We state without proof the four forms of
Gauss' hypergeometric function \cite{macrobert:1967:she}.
\begin{eqnarray}
F(a,b;c;x)
&=&(1-x)^{c-a-b}F(c-a,c-b;c;x)\\
&=&(1-x)^{ -a }F\left( a,c-b;c;\frac{x}{x-1}\right)\\
&=&(1-x)^{ -b }F\left( b,c-a;c;\frac{x}{x-1}\right).
\end{eqnarray}


\section{Orthogonal polynomials}

Many systems or sequences of functions may serve as a {\em basis of linearly independent functions}
which are capable to ``cover'' -- that is, to approximate -- certain functional classes
\cite{herman-sc,Marcellan}.
We have already encountered at least two such prospective bases [cf. Eq. (\ref{2011-m-fa-e1fc})]:
\begin{equation}
\begin{array}{l}
\{1,x,x^2,\ldots ,x_k,\ldots \} \textrm { with } f(x) =\sum_{k=0}^\infty c_k x^k, \\
\left\{e^{ikx} \mid k\in {\Bbb Z} \right\} \quad \textrm{ for } f(x+2\pi)=f(x) \\
\qquad \textrm {  with }
f(x)= \sum _{k=-\infty}^\infty c_k e^{ikx},\\
\qquad  \textrm{  where }
c_k=\frac{1}{2\pi}\int_{-\pi}^\pi f(x) e^{-ikx} dx.
\end{array}
\label{2011-m-ch-sfe1}
\end{equation}

In particular, there exist systems of orthogonal functions of that kind.
In order to claim this, let us first define what  {\em orthogonality} means in the  functional context.
\index{orthogonal functions}
Just as for linear vector spaces, we can define an
{\em inner product}
or {\em scalar product}
\index{inner product}
\index{scalar product}
of two real-valued functions $f(x)$ and $g(x)$ by the integral \cite{Wilf}
\begin{equation}
\langle   f \mid g\rangle
=
\int_a^b f(x)g(x) \rho(x) dx
\label{2011-m-ch-sfesp}
\end{equation}
for some suitable {\em weight function} $\rho (x)\ge 0$.  \index{weight function}
Very often, the weight function is set to unity; that is,
$\rho(x) =\rho =1$.
We notice without proof that $\langle   f \mid g\rangle  $ satisfies all requirements of a scalar product.
A system of functions $\{\psi_0,\psi_1,\psi_2,\ldots ,\psi_k,\ldots \}$
is orthogonal if
\begin{equation}
\langle   \psi_j \mid \psi_k\rangle
=
\int_a^b \psi_j(x)\psi_k(x) \rho(x) dx
=\delta_{jk}.
\label{2011-m-ch-sfespof}
\end{equation}


Suppose, in some generality,
that
 $\{f_0,f_1,f_2,\ldots ,f_k,\ldots \}$
is a sequence of nonorthogonal functions.
Then we can apply a {\em Gram-Schmidt orthogonalization process} to these functions
\index{Gram-Schmidt process}
and thereby obtain orthogonal functions
$\{\phi_0,\phi_1,\phi_2,\ldots ,\phi_k,\ldots \}$
by
\begin{equation}
\begin{array}{l}
\phi_0 (x) =f_0(x), \\
\phi_k (x)
=
f_k(x)
-
\sum_{j=0}^{k-1}\frac{\langle f_k\mid \phi_j \rangle}{\langle \phi_j   \mid \phi_j \rangle}\phi_j (x).
\end{array}
\label{2011-m-ch-sfegs}
\end{equation}
Note that the proof of the {  Gram-Schmidt  process} in the functional
context is analoguous to the one in the vector context.

\section{Legendre polynomials}

The system of polynomial functions $\{1,x,x^2,\ldots ,x_k,\ldots \}$
is such a non orthogonal sequence in this sense,
as, for instance,  with $\rho =1$ and $b=-a=1$,
\begin{equation}
\langle   1 \mid x^2\rangle
=
\int_{a=-1}^{b=1} x^2 dx
=\frac{b^3-a^3}{3} =\frac{2}{3}.
\end{equation}
Hence, by the   Gram-Schmidt  process we obtain
\begin{equation}
\begin{array}{l}
\phi_0(x) =1,       \\
\phi_1(x) = x - \frac{\langle x \mid 1 \rangle}{\langle 1   \mid 1 \rangle}1   \\
\qquad  = x - 0 =x,   \\
\phi_2(x) = x^2 - \frac{\langle x^2 \mid 1 \rangle}{\langle 1   \mid 1 \rangle}1
 - \frac{\langle x^2 \mid x \rangle}{\langle x   \mid x \rangle}x
 \\
\qquad  =  x^2 - \frac{2/3}{2}1 -0x    =    x^2 - \frac{1 }{ 3},\\
\vdots
\end{array}
\end{equation}
If we are ``forcing'' a ``normalization'' of
\begin{equation}
\phi_k(1) =1,
\end{equation}
then this system of orthogonal polynomials is the classical
{\em Legendre polynomials}
\index{Legendre polynomials}
\begin{equation}
\begin{array}{l}
P_0(x) =1,\\
P_1(x) =x,\\
P_2(x) =  \left( x^2 - \frac{1 }{ 3}\right)/\frac{2 }{ 3}
       =  \frac{1 }{ 2} \left( 3x^2 - 1\right)
,\\
\vdots
\end{array}
\label{2011-m-ch-sfelp}
\end{equation}

Why should we be interested in orthonormal systems of functions?
Because, as pointed out earlier,
they could be the eigenfunctions and solutions of certain differential equation,
such as, for instance, the Schrdinger equation, which may be subjected to a separation of variables.
For Legendre polynomials the associated differential equation is the  {\em Legendre equation}
\index{Legendre equation}
\begin{equation}
(x^2 -1)[P_l(x)]''+2x[P_l(x)]' =l(l+1)P_l(x) \textrm{, for }l\in {\Bbb N}_0
\label{2011-m-ch-sfelpede}
\end{equation}
whose Sturm-Liouville form has been mentioned earlier in Table \ref{2011-m-sl-t-varieties}
on page \pageref{2011-m-sl-t-varieties}.
For a proof, we refer to the literature.


\subsection{Rodrigues formula}
\index{Rodrigues formula}

We just state the  Rodrigues formula for Legendre polynomials
\begin{equation}
P_l(x)=\frac{1}{2^ll!}\frac{d^l}{dx^l}(x^2-1)^l \textrm{, for }l\in {\Bbb N}_0.
\label{2011-m-ch-sfrf}
\end{equation}
without proof.

For even $l$, $P_l(x)=P_l(-x)$ is an even function of $x$,
whereas
for odd $l$, $P_l(x)=-P_l(-x)$ is an odd function of $x$;
that is, $P_l(-x)=(-1)^lP_l(x)$.
Moreover,
 $P_l(-1)=(-1)^l$ and  $P_{2k+1}(0)=0$.




{\color{OliveGreen}
\bproof

This can be shown by  the
substitution
 $t=-x$, $dt=-dx$, and insertion into  the  Rodrigues formula:
\begin{eqnarray*}
   P_l(-x)&=&\left.{1\over 2^ll!}{d^l\over du^l}(u^2-1)^l\right|_{u=-x}
   =[u\to-u]=\\
   &=&\left.{1\over(-1)^l}{1\over2^ll!}{d^l\over du^l}(u^2-1)^l
   \right|_{u=x}=(-1)^lP_l(x).
\end{eqnarray*}

Because of the ``normalization'' $P_l(1)=1$ we obtain $$P_l(-1)=(-1)^lP_l(1)=(-1)^l.$$

And as $P_l(-0)=P_l(0)=(-1)^lP_l(0)$, we obtain $P_l(0)=0$ for odd $l$.


\eproof
}



\subsection{Generating function}
\index{generating function}

For
$\vert x\vert<1$ and
$\vert 1\vert<1$ the  Legendre polynomials have the following generating function
\begin{equation}
g(x,t) =\frac{1}{\sqrt{1-2xt+t^2}}=\sum_{l=0}^\infty t^l P_l(x).
\end{equation}
No proof is given here.

\subsection{The three term and other recursion formulae}
\index{three term recursion formula}

Among other things, generating functions are useful for the derivation of certain recursion relations involving Legendre polynomials.

For instance, for $l=1,2,\ldots$, the   three term recursion formula
\begin{equation}
(2l+1)x P_l(x) = (l+1) P_{l+1}(x)+lP_{l-1}(x) ,
\end{equation}
or, by substituting $l-1$ for $l$,  for $l=2,3\ldots$,
\begin{equation}
(2l-1)x P_{l-1}(x) = l P_{l}(x)+(l-1)P_{l-2}(x),
\end{equation}
can be proven as follows.

{\color{OliveGreen}
\bproof

$$
   g(x,t)={1\over\sqrt{1-2tx+t^2}}=\sum_{n=0}^\infty t^nP_n(x)
$$
$$
   {\partial\over\partial t}g(x,t)=-{1\over 2}(1-2tx+t^2)^{-{3\over 2}}
   (-2x+2t)={1\over\sqrt{1-2tx+t^2}}\,{x-t\over1-2tx+t^2}
$$
$$
   {\partial\over\partial t}g(x,t)={x-t\over1-2tx+t^2}
   \sum_{n=0}^\infty t^nP_n(x)=\sum_{n=0}^\infty nt^{n-1}P_n(x)
$$
$$
   (x-t)\sum_{n=0}^\infty t^nP_n(x)-(1-2tx+t^2)
   \sum_{n=0}^\infty nt^{n-1}P_n(x)=0
$$
$$
   \sum_{n=0}^\infty xt^nP_n(x)-
   \sum_{n=0}^\infty t^{n+1}P_n(x)-
   \sum_{n=1}^\infty nt^{n-1}P_n(x)+
$$
$$
   \hspace*{5cm}+\,\sum_{n=0}^\infty 2xnt^nP_n(x)-
   \sum_{n=0}^\infty nt^{n+1}P_n(x)=0
$$
$$
   \sum_{n=0}^\infty (2n+1)xt^nP_n(x)-
   \sum_{n=0}^\infty (n+1)t^{n+1}P_n(x)-
   \sum_{n=1}^\infty nt^{n-1}P_n(x)=0
$$
$$
   \sum_{n=0}^\infty (2n+1)xt^nP_n(x)-
   \sum_{n=1}^\infty nt^{n}P_{n-1}(x)-
   \sum_{n=0}^\infty (n+1)t^nP_{n+1}(x)=0,
$$
$$
   xP_0(x)-P_1(x)+\sum_{n=1}^\infty t^n\Bigl[(2n+1)xP_n(x)-nP_{n-1}(x)
   -(n+1)P_{n+1}(x)\Bigr]=0,
$$
hence
$$
    xP_0(x)-P_1(x)=0, \qquad (2n+1)xP_n(x)-nP_{n-1}(x)-
   (n+1)P_{n+1}(x)=0,
$$
hence
$$
  P_1(x)=xP_0(x), \qquad (n+1)P_{n+1}(x)=
   (2n+1)xP_n(x)-nP_{n-1}(x).
$$

\eproof
}


Let us prove
\begin{equation}
P_{l-1}(x)=P'_l(x)-2xP'_{l-1}(x)+P'_{l-2}(x) .
\end{equation}

{\color{OliveGreen}
\bproof


$$
   g(x,t)={1\over\sqrt{1-2tx+t^2}}=\sum_{n=0}^\infty t^nP_n(x)
$$
$$
   {\partial\over\partial x}g(x,t)=-{1\over 2}(1-2tx+t^2)^{-{3\over 2}}
   (-2t)={1\over\sqrt{1-2tx+t^2}}\,{t\over1-2tx+t^2}
$$
$$
   {\partial\over\partial x}g(x,t)={t\over1-2tx+t^2}
   \sum_{n=0}^\infty t^nP_n(x)=\sum_{n=0}^\infty t^{n}P'_n(x)
$$
$$
   \sum_{n=0}^\infty t^{n+1}P_n(x)=\sum_{n=0}^\infty t^{n}P'_n(x)-
   \sum_{n=0}^\infty 2xt^{n+1}P'_n(x)+\sum_{n=0}^\infty t^{n+2}P'_n(x)
$$
$$
   \sum_{n=1}^\infty t^{n}P_{n-1}(x)=\sum_{n=0}^\infty t^{n}P'_n(x)-
   \sum_{n=1}^\infty 2xt^{n}P'_{n-1}(x)+\sum_{n=2}^\infty t^{n}P'_{n-2}(x)
$$
$$
   tP_0+\sum_{n=2}^\infty t^{n}P_{n-1}(x)=P'_0(x)+tP'_1(x)+
   \sum_{n=2}^\infty t^{n}P'_n(x)-
$$
$$
   \hspace*{5cm}-\,2xtP'_0-\sum_{n=2}^\infty 2xt^{n}P'_{n-1}(x)+
   \sum_{n=2}^\infty t^{n}P'_{n-2}(x)
$$
$$
   P'_0(x)+t\Bigl[P'_1(x)-P_0(x)-2xP'_0(x)\Bigr]+\hspace*{3cm}
$$
$$
   \hspace*{3cm}+\,\sum_{n=2}^\infty t^{n}[P'_n(x)-2xP'_{n-1}(x)+P'_{n-2}(x)-
   P_{n-1}(x)]=0
$$
$$
   P'_0(x)=0\textrm{, hence } P_0(x)={\rm const.}
$$
$$
   P'_1(x)-P_0(x)-2xP'_0(x)=0.
$$
Because of $P'_0(x)=0$ we obtain $P'_1(x)-P_0(x)=0$, hence $P'_1(x)=P_0(x)$, and
$$
   P'_n(x)-2xP'_{n-1}(x)+P'_{n-2}(x)-P_{n-1}(x)=0.
$$
Finally we substitute $n+1$ for $n$:
$$
   P'_{n+1}(x)-2xP'_{n}(x)+P'_{n-1}(x)-P_{n}(x)=0,
$$
hence
$$
    P_n(x)=P'_{n+1}(x)-2xP'_{n}(x)+P'_{n-1}(x).
$$

\eproof
}

Let us prove
\begin{equation}
P'_{l+1}(x)-P'_{l-1}(x)=(2l+1)P_l(x) .
\end{equation}

{\color{OliveGreen}
\bproof

\begin{eqnarray*}
   (n+1)P_{n+1}(x)&=&(2n+1)xP_n(x)-nP_{n-1}(x)\quad\left|
   {d\over dx}\right.\\
   (n+1)P'_{n+1}(x)&=&(2n+1)P_n(x)+(2n+1)xP'_n(x)-nP'_{n-1}(x)
   \quad\Bigl|\cdot\,2\\
   \textrm{(i):}\quad(2n+2)P'_{n+1}(x)&=&2(2n+1)P_n(x)+2(2n+1)xP'_n(x)-2nP'_{n-1}(x)
\end{eqnarray*}
$$
   P'_{n+1}(x)-2xP'_{n}(x)+P'_{n-1}(x)=P_{n}(x)\quad\Bigl|
   \cdot\,(2n+1)
$$
$$
   \textrm{(ii):}\quad (2n+1)P'_{n+1}(x)-2(2n+1)xP'_{n}(x)+(2n+1)P'_{n-1}(x)=
   (2n+1)P_{n}(x)
$$
We subtract (ii) from (i):
$$
   P'_{n+1}(x)+2(2n+1)xP'_n(x)-(2n+1)P'_{n-1}(x)=
$$
$$
   \hspace*{5cm}=\,(2n+1)P_n(x)+2(2n+1)xP'_n(x)-2nP'_{n-1}(x);
$$
hence
$$
   P'_{n+1}(x)-P'_{n-1}(x)=(2n+1)P_n(x).
$$
\eproof
}

\subsection{Expansion in Legendre polynomials}

We state without proof  that square integrable functions $f(x)$
can be written as series of Legendre polynomials
as
\begin{equation}
\begin{array}{l}
 f(x)=\sum_{l=0}^\infty a_lP_l(x)\textrm{, with expansion coefficients}\\
\qquad a_l={2l+1\over 2}
\int\limits_{-1}^{+1}f(x)P_l(x)dx.
 \end{array}
\end{equation}

{
\color{blue}
\bexample
Let us expand the Heaviside function defined in Eq. (\ref{2011-m-di-edhf})
\index{Heaviside function}
\begin{equation}
H(x)
=
\left\{
\begin{array}{rl}
1&\textrm{ for } x\ge  0\\
0&\textrm{ for } x <  0
\end{array}
\right.
\end{equation}
in terms of Legendre polynomials.

We shall use the recursion formula $(2l+1)P_l=P'_{l+1}-P'_{l-1}$ and rewrite
\begin{eqnarray*}
 a_l &=& {1\over 2}\int\limits_0^1\bigl(P'_{l+1}(x)-
              P'_{l-1}(x)\bigr)dx=
              {1\over 2}\bigl(P_{l+1}(x)-P_{l-1}(x)\bigr)
              \biggr|_{x=0}^1=\\
            &=& {1\over 2}\underbrace{\bigl[P_{l+1}(1)-P_{l-1}(1)\bigr]}
                _{\mbox{$=0$ because of}\atop \mbox{``normalization''}}-
                {1\over 2}\bigl[P_{l+1}(0)-P_{l-1}(0)\bigr]
.
\end{eqnarray*}
Note that $P_n(0)=0$ for {\em odd} $n$; hence $  a_l=0$ for
{\em even} $l\ne0$. We shall treat the case $l=0$ with $P_0(x)=1$ separately.
Upon substituting $2l+1$ for $l$ one obtains
$$
   a_{2l+1}=-{1\over 2}\biggl[P_{2l+2}(0)-P_{2l}(0)\biggr].
$$
We shall next use the formula
$$
   P_l(0)=(-1)^{l\over 2}{l!\over
2^l\left(\left({l\over2}\right)!\right)^2},
$$
and for {\em even} $l\geq 0$ one obtains
\begin{eqnarray*}
   a_{2l+1}&=&-{1\over 2}\left[{(-1)^{l+1}(2l+2)!\over 2^{2l+2}((l+1)!)^2}
              -{(-1)^l(2l)!\over 2^{2l}(l!)^2}\right]=\\
   &=&(-1)^l{(2l)!\over 2^{2l+1}(l!)^2}\left[{(2l+1)(2l+2)\over 2^2(l+1)^2}
               +1\right]=\\
   &=&(-1)^l{(2l)!\over 2^{2l+1}(l!)^2}\left[{2(2l+1)(l+1)\over 2^2(l+1)^2}
               +1\right]=\\
   &=&(-1)^l{(2l)!\over 2^{2l+1}(l!)^2}\left[{2l+1+2l+2\over 2(l+1)}\right]=\\
   &=&(-1)^l{(2l)!\over 2^{2l+1}(l!)^2}\left[{4l+3\over2(l+1)}\right]=\\
   &=&(-1)^l{(2l)!(4l+3)\over 2^{2l+2}l!(l+1)!}\\
   a_0&=&{1\over 2}\int\limits_{-1}^{+1} H (x)\underbrace{P_0(x)}_
               {\mbox{$=1$}}dx={1\over 2}\int\limits_0^1dx={1\over 2};
\end{eqnarray*}
and finally
$$
  H (x)={1\over 2}+\sum_{l=0}^\infty
   (-1)^l{(2l)!(4l+3)\over2^{2l+2}l!(l+1)!}P_{2l+1}(x).
$$
\eexample
}


\section{Associated Legendre polynomial}
\index{associated Legendre polynomial}

Associated Legendre polynomials $P_l^m(x)$ are the solutions of the
{\em general Legendre equation}
\index{general Legendre equation}

\begin{equation}
\begin{array}{l}
\left\{
(1-x^2)\frac{d^2}{dx^2}
-2x  \frac{d }{dx }
+
\left[ l(l+1)-\frac{m^2}{1-x^2} \right] \right\} P_l^m(x)= 0 \textrm{, or}
\\
\frac{d }{dx }\left((1-x^2)\frac{d }{dx }P_l^m(x)\right)
+
\left[ l(l+1)-\frac{m^2}{1-x^2} \right]  P_l^m(x)= 0
\end{array}
\label{2011-m-ch-sfgle}
\end{equation}
Eq. (\ref{2011-m-ch-sfgle})
reduces to the Legendre equation
 (\ref{2011-m-ch-sfelpede})
on page \pageref{2011-m-ch-sfelpede} for  $m=0$;
hence
\begin{equation}
P_l^0(x)=P_l(x).
\end{equation}
More generally,
by differentiating $m$ times the Legendre equation (\ref{2011-m-ch-sfelpede})
it can be shown that
\begin{equation}
P_l^m(x)=(-1)^m(1-x^2)^\frac{m}{2} \frac{d^m}{dx^m}P_l(x).
\end{equation}
By inserting $P_l(x)$ from the
{\em Rodrigues formula}
\index{Rodrigues formula}
for Legendre polynomials (\ref{2011-m-ch-sfrf})
we obtain
\begin{equation}
\begin{array}{l}
P_l^m(x)=
(-1)^m(1-x^2)^\frac{m}{2} \frac{d^m}{dx^m} \frac{1}{2^ll!}\frac{d^l}{dx^l}(x^2-1)^l
\\
\qquad
=
\frac{(-1)^m(1-x^2)^\frac{m}{2}}{2^ll!} \frac{d^{m+l}}{dx^{m+l}}(x^2-1)^l
.
\end{array}
\end{equation}

In terms of the Gauss hypergeometric function
\index{hypergeometric function}
the associated Legendre polynomials can be generalied to
arbitrary complex indices $\mu$, $\lambda$ and argument $x$ by
\begin{equation}
P^\mu_\lambda (x) =
\frac{1}{\Gamma (1-\mu )}\left(\frac{1+x}{1-x}\right)^\frac{\mu}{2}
{}_2F_1
\left(
-\lambda , \lambda  +1; 1-\mu ;\frac{1-x}{2}
\right).
\end{equation}
No proof is given here.

\section{Spherical harmonics}
\index{spherical harmonics}
\label{2011-m-ch-sfshar}

%http://en.wikipedia.org/wiki/Associated_Legendre_polynomials

Let us define the {\em spherical harmonics} $Y_l^m (\theta ,\varphi )$ by
\begin{equation}
Y_l^m (\theta ,\varphi ) =\sqrt{\frac{(2l+1)(l-m)!}{4\pi (l+m)!} }
P_l^m(\cos \theta )e^{im\varphi }\textrm{ for } -l\le m\le l.
.
\end{equation}

Spherical harmonics are solutions of the differential equation
\begin{equation}
[\Delta + l(l+1)] Y_l^m (\theta ,\varphi ) =0
.
\end{equation}
This equation is what typically remains after separation and ``removal'' of the
radial part of the Laplace equation $\Delta \psi(r,\theta ,\varphi)=0$ in three dimensions
when the problem is invariant (symmetric) under rotations.

%\section{Bessel functions}

{
\color{blue}
\bexample

\section{Solution of the Schr\"odinger equation for a hydrogen atom}
\index{Schr\"odinger equation}

Suppose Schr\"odinger, in his 1926 {\it annus mirabilis}
which seem to have been initiated by a trip to Arosa with `an old girlfriend from Vienna'
(apparently it was neither his wife Anny who remained in Zurich, nor Lotte, Irene and Felicie \cite{Moore-Schroedinger}),
came down from the mountains or from whatever realm he was in with that woman -- and
handed you over some partial differential equation  for the hydrogen atom
-- an equation
\begin{equation}
\begin{array}{l}
 \frac{1}{2\mu }\left({\cal P}_x^2 +{\cal P}_y^2 +{\cal P}_z^2\right) \psi = \left( E-V \right)\psi \textrm{ , or, with } V=-\frac{e^2}{4\pi \epsilon_0 r}, \\
 -\left[ \frac{\hbar^2}{2\mu }\Delta +  \frac{e^2}{4\pi \epsilon_0r} \right]\psi ({\bf x})= E\psi \textrm{ , or}\\
 \left[ \Delta + \frac{2\mu }{\hbar^2} \left(\frac{e^2}{4\pi \epsilon_0r} + E \right)\right]\psi ({\bf x})=0,
\end{array}
\label{2011-m-ch-qae-sebf}
\end{equation}
which would later bear his name  -- and asked you if you could be so kind to please solve it for him.
Actually, by Schr\"odinger's own account \cite{ANDP:ANDP19263840404} he handed  over this eigenwert equation to Hermann Klaus Hugo Weyl;
in this instance he was not dissimilar from Einstein, who seemed to have employed a (human) computator on a very regular basis.
He might also have hinted that $\mu$, $e$, and $\epsilon_0$ stand for some (reduced) mass, charge, and the  permittivity of the vacuum, respectively,
$\hbar$ is a constant of (the dimension of) action,
and $E$ is some eigenvalue which must be determined from
the solution of (\ref{2011-m-ch-qae-sebf}).

So, what could you do?
First, observe that the problem is spherical symmetric,
as the potential   just depends on the radius $r=\sqrt{{\bf x}\cdot {\bf x}}$,
and also the Laplace operator $\Delta =
\nabla \cdot \nabla $ allows spherical symmetry.
Thus we could write   the Schr\"odinger equation (\ref{2011-m-ch-qae-sebf})
in terms of spherical coordinates
$(r, \theta ,\varphi )$ with
$x  = r\sin \theta \cos \varphi$,
$y = r\sin \theta \sin \varphi$,
$z = r\cos \theta $,
whereby  $\theta$ is the polar angle in the $x$--$z$-plane measured
from the $z$-axis, with $0 \le \theta \le \pi$,
and $\varphi $ is  the azimuthal angle in the $x$--$y$-plane, measured
from the $x$-axis with $0 \le \varphi < 2 \pi$
\index{spherical coordinates}
(cf page \pageref{2011-m-spericalcoo}).
In terms of spherical coordinates the Laplace operator
essentially ``decays into'' (i.e. consists addiditively of)
a radial part and an angular part
\begin{equation}
\begin{array}{l}
\Delta =
\left( \frac{\partial}{\partial x}\right)^2
+
\left( \frac{\partial}{\partial y}\right)^2
+
\left( \frac{\partial}{\partial z}\right)^2
\\
\qquad
=
\frac{1}{r^2} \left[ \frac{\partial}{\partial r}\left( r^2\frac{\partial}{\partial r}\right)  \right. \\
\qquad \quad
+  \left.
\frac{1}{\sin \theta}   \frac{\partial}{\partial \theta }
\sin \theta \frac{\partial}{\partial \theta }
+
\frac{1}{\sin^2 \theta} \frac{\partial^2}{\partial \varphi^2 }
\right].
\end{array}
\label{2011-m-ch-qae-losc}
\end{equation}

\subsection{Separation of variables {\it Ansatz}}

This can be exploited for a
{\em separation ov variable} {\it Ansatz},
which, according to  Schr\"odinger, should be well known
(in German {\em sattsam bekannt})
by now (cf chapter \ref{2011-m-ch-sv}).
We thus write the solution $\psi$ as a product of functions
of separate variables
\begin{equation}
\psi (r, \theta ,\varphi ) = R(r)Y_l^m ( \theta ,\varphi )
=R(r)\Theta(\theta)\Phi(\varphi)
\label{2011-m-ch-qaesva}
\end{equation}
The spherical harmonics $Y_l^m ( \theta ,\varphi )$  has been
written already as a reminder of what has been mentioned earlier
on page  \pageref{2011-m-ch-sfshar}.
We will come back to it later.

\subsection{Separation of the radial part from the angular one}

For the time being, let us first concentrate on
the radial part $R(r)$.
Let us first totally separate the variables of
the Schr\"odinger equation (\ref{2011-m-ch-qae-sebf})
in radial coordinates
\begin{equation}
\begin{array}{l}
\left\{ \frac{1}{r^2} \left[ \frac{\partial}{\partial r}\left( r^2\frac{\partial}{\partial r}\right)  \right.\right.  \\
\qquad
+  \left.
\frac{1}{\sin \theta}   \frac{\partial}{\partial \theta }
\sin \theta \frac{\partial}{\partial \theta }
+
\frac{1}{\sin^2 \theta} \frac{\partial^2}{\partial \varphi^2 }
\right]   \\
  \qquad +
\left.
\frac{2\mu }{\hbar^2} \left(\frac{e^2}{4\pi \epsilon_0 r} + E \right)\right\}
\psi (r, \theta ,\varphi  )=0,
\end{array}
\label{2011-m-ch-qa1e}
\end{equation}
and multiplying it with $r^2$
\begin{equation}
\begin{array}{l}
\left\{  \frac{\partial}{\partial r}\left( r^2\frac{\partial}{\partial r}\right) +
\frac{2\mu r^2}{\hbar^2} \left(\frac{e^2}{4\pi \epsilon_0 r} + E \right) \right.  \\
\qquad
+  \left.
\frac{1}{\sin \theta}   \frac{\partial}{\partial \theta }
\sin \theta \frac{\partial}{\partial \theta }
+
\frac{1}{\sin^2 \theta} \frac{\partial^2}{\partial \varphi^2 }
\right\}
\psi (r, \theta ,\varphi  )=0
,
\end{array}
\label{2011-m-ch-qae2}
\end{equation}
so that, after division by $\psi (r, \theta ,\varphi  )=Y_l^m ( \theta ,\varphi )$
and writing separate variables on separate sides of the equation,
\begin{equation}
\begin{array}{l}
\frac{1}{R( r )}
\left\{  \frac{\partial}{\partial r}\left( r^2\frac{\partial}{\partial r}\right) +
\frac{2\mu r^2}{\hbar^2} \left(\frac{e^2}{4\pi \epsilon_0 r} + E \right) \right\} R(r)
\\ \qquad =
-\frac{1}{Y_l^m ( \theta ,\varphi )} \left\{
\frac{1}{\sin \theta}   \frac{\partial}{\partial \theta }
\sin \theta \frac{\partial}{\partial \theta }
+
\frac{1}{\sin^2 \theta} \frac{\partial^2}{\partial \varphi^2 }
\right\}
Y_l^m ( \theta ,\varphi )
\end{array}
\label{2011-m-ch-qae3}
\end{equation}
Because the left hand side of this equation is independent of the angular variables
$\theta $ and $\varphi$, and its right hand side is independent of the radius $r$,
both sides have to be constant; say $\lambda $.
Thus we obtain two
differential equations for the radial and the angular part,
respectively
\begin{equation}
\left\{  \frac{\partial}{\partial r} r^2\frac{\partial}{\partial r}  +
\frac{2\mu r^2}{\hbar^2} \left(\frac{e^2}{4\pi \epsilon_0 r} + E \right) \right\} R(r)
 =  \lambda  R( r )  ,
\label{2011-m-ch-qae4a}
\end{equation}
and
\begin{equation}
\left\{
\frac{1}{\sin \theta}   \frac{\partial}{\partial \theta }
\sin \theta \frac{\partial}{\partial \theta }
+
\frac{1}{\sin^2 \theta} \frac{\partial^2}{\partial \varphi^2 }
\right\}
Y_l^m ( \theta ,\varphi )   =  -  \lambda  Y_l^m ( \theta ,\varphi ).
\label{2011-m-ch-qae4b}
\end{equation}


\subsection{Separation of the polar angle $\theta$ from the azimuthal angle $\varphi $}

As already hinted in Eq. (\ref{2011-m-ch-qaesva})
The angular portion can still be separated by the {\em Ansatz}
$Y_l^m ( \theta ,\varphi )   = \Theta(\theta)\Phi(\varphi)$,
because, when multiplied by $\sin^2 \theta /[\Theta(\theta)\Phi(\varphi)]$,
Eq.   (\ref{2011-m-ch-qae4b})
can be rewritten as
\begin{equation}
\left\{
\frac{\sin \theta}{\Theta(\theta)}
\frac{\partial}{\partial \theta }
\sin \theta \frac{\partial \Theta(\theta)}{\partial \theta }
+  \lambda  \sin^2 \theta   \right\}
+
\frac{1}{\Phi(\varphi)} \frac{\partial^2\Phi(\varphi)}{\partial \varphi^2 }
= 0,
\label{2011-m-ch-qae4bc}
\end{equation}
and hence
\begin{equation}
\begin{array}{l}
\frac{\sin \theta}{\Theta(\theta)}
\frac{\partial}{\partial \theta }
\sin \theta \frac{\partial \Theta(\theta)}{\partial \theta }
+  \lambda  \sin^2 \theta
  = -
\frac{1}{\Phi(\varphi)} \frac{\partial^2\Phi(\varphi)}{\partial \varphi^2 }
=  m^2,
\end{array}
\label{2011-m-ch-qae8}
\end{equation}
where $m$ is some constant.

\subsection{Solution of the equation  for the azimuthal angle factor $\Phi(\varphi )$}

The  resulting differential equation  for $\Phi(\varphi )$
\begin{equation}
\frac{   d   ^2\Phi(\varphi )}{   d    \varphi^2 }
=  -m^2\Phi(\varphi),
\label{2011-m-ch-qaephi}
\end{equation}
has the general solution
\begin{equation}
\Phi(\varphi) = Ae^{im\varphi}+B e^{-im\varphi}.
\label{2011-m-ch-qae11}
\end{equation}
As $\Phi$ must obey the periodic poundary conditions $\Phi(\varphi)=\Phi(\varphi  +2\pi)$,
$m$ must be an integer.
The two constants $A,B$ must be equal if we require the system of functions $\{e^{im\varphi}\vert m \in {\Bbb Z}\}$
to be orthonormalized.
Indeed, if we define
\begin{equation}
\Phi_m(\varphi) = Ae^{im\varphi}
\label{2011-m-ch-qae11def}
\end{equation}
and require that it normalized, it follows that
\begin{equation}
\begin{array}{l}
\int_0^{2\pi} \overline {\Phi}_m(\varphi) \Phi_m(\varphi)d \varphi \\
\qquad     =
\int_0^{2\pi} \overline {A}e^{-im\varphi}Ae^{im\varphi} d \varphi \\
\qquad    =
\int_0^{2\pi}\vert A\vert^2 d \varphi \\
\qquad  = 2\pi  \vert A\vert^2  \\
\qquad
= 1,
\end{array}
\label{2011-m-ch-qae11normexpl}
\end{equation}
it is consistent to set
\begin{equation}
A= \frac{1} {\sqrt{2\pi } };
\label{2011-m-ch-qae11normexpln}
\end{equation}
and hence,
\begin{equation}
\Phi_m(\varphi) = \frac{e^{im\varphi}} {\sqrt{2\pi }  }
\label{2011-m-ch-qae11normexplnendg}
\end{equation}
Note that, for different $m\neq n$,
\begin{equation}
\begin{array}{l}
\int_0^{2\pi} \overline {\Phi}_n(\varphi) \Phi_m(\varphi)d \varphi \\
\qquad =
\int_0^{2\pi} \frac{e^{-in\varphi}} {\sqrt{2\pi }  } \frac{e^{im\varphi}} {\sqrt{2\pi }}  d \varphi \\
\qquad =
\int_0^{2\pi} \frac{e^{i(m-n)\varphi}} { 2\pi  }   d \varphi \\
\qquad =
\left. -\frac{i e^{i(m-n)\varphi}} { 2(m-n)\pi  } \right|_0^{2\pi}\\
\qquad = 0,
\end{array}
\label{2011-m-ch-qae11normexplnoni}
\end{equation}
because $m-n\in {\Bbb Z}$.

\subsection{Solution of the equation  for the  polar angle factor $\Theta (\theta )$}

The left hand side of
Eq. (\ref{2011-m-ch-qae8}) contains only the polar coordinate.
Upon division by $\sin ^2 \theta$ we obtain
\begin{equation}
\begin{array}{l}
\frac{1}{\Theta(\theta)\sin \theta}
\frac{   d   }{   d    \theta }
\sin \theta \frac{   d    \Theta(\theta)}{   d    \theta }
+  \lambda
= \frac{m^2}{\sin^2\theta}\textrm{, or}\\
\frac{1}{\Theta(\theta)\sin \theta}
\frac{   d   }{   d    \theta }
\sin \theta \frac{   d    \Theta(\theta)}{   d    \theta }   -\frac{m^2}{\sin^2\theta }
= -  \lambda    ,\\
\end{array}
\label{2011-m-ch-pcde}
\end{equation}

Now, first, let us consider the case $m=0$.
With the variable substitution
$x = \cos \theta$, and thus
$\frac{dx}{d\theta}= -\sin \theta$ and  $dx= -\sin \theta d\theta$, we obtain from (\ref{2011-m-ch-pcde})
\begin{equation}
\begin{array}{l}
\frac{   d   }{   d    x }
\sin^2 \theta \frac{   d    \Theta(x)}{   d    x }
= -  \lambda  \Theta(x)   ,\\
\frac{   d   }{   d    x }
(1-x^2) \frac{   d    \Theta(x)}{   d    x } +  \lambda  \Theta(x)
=  0 ,\\
\left(x^2-1 \right)\frac{   d   ^2 \Theta(x)}{   d    x^2 } + 2 x \frac{   d    \Theta(x)}{   d    x } =  \lambda  \Theta(x)
,\\
\end{array}
\label{2011-m-ch-pcde1}
\end{equation}
which is of the same form as the {\em Legendre equation}
\index{Legendre equation}
(\ref{2011-m-ch-sfelpede})
mentioned on page \pageref{2011-m-ch-sfelpede}.

Consider the series {\it Ansatz}
\begin{equation}
\Theta(x) = a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots
\label{2011-m-ch-pcde12}
\end{equation}
for solving (\ref{2011-m-ch-pcde1}).
\marginnote{This is actually a ``shortcut'' solution of the Fuchian Equation mentioned earlier.}
Insertion into  (\ref{2011-m-ch-pcde1}) and comparing the coefficients of $x$
for equal degrees
yields the recursion relation
\begin{equation}
\begin{array}{l}
\left(x^2-1 \right)\frac{   d   ^2  }{   d    x^2 }
[a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ]    \\
\qquad \quad   + 2 x \frac{   d    }{   d    x }[a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ]  \\
\qquad =  \lambda [a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ] ,\\
\left(x^2-1 \right)  [ 2a_2   + \cdots + k(k-1)a_kx^{k-2} +\cdots  ]  \\
 \qquad \quad   + [2 x a_1  +2 x  2a_2 x  + \cdots + 2 x k a_kx^{k-1} +\cdots  ]  \\
\qquad =  \lambda [a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ] ,\\
\left(x^2-1 \right)  [ 2a_2   + \cdots + k(k-1)a_kx^{k-2} +\cdots  ]    \\
 \qquad \quad   +  [2 a_1 x  +4a_2 x^2  + \cdots + 2  k a_kx^{k} +\cdots  ]  \\
\qquad =  \lambda [a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ] ,  \\
\;[ 2a_2x^2   + \cdots + k(k-1)a_kx^{k} +\cdots  ]  \\
 \qquad \quad  - [ 2a_2   + \cdots + k(k-1)a_kx^{k-2} +\cdots  ]    \\
 \qquad \quad   +  [2 a_1 x  +4a_2 x^2  + \cdots + 2  k a_kx^{k} +\cdots  ]  \\
\qquad =  \lambda [a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ] , \\
\;[ 2a_2x^2   + \cdots + k(k-1)a_kx^{k} +\cdots  ]  \\
 \qquad \quad  - [ 2a_2   + \cdots + k(k-1)a_kx^{k-2}\\
 \qquad \qquad +  (k+1)k a_{k+1}x^{k-1}+ (k+2)(k+1)a_{k+2}x^{k} +\cdots  ]    \\
 \qquad \quad   +  [2 a_1 x  +4a_2 x^2  + \cdots + 2  k a_kx^{k} +\cdots  ]  \\
\qquad =  \lambda [a_0 +a_1x +a_2 x^2 + \cdots + a_kx^k +\cdots  ] ,
\end{array}
\label{2011-m-ch-pcde123}
\end{equation}
and thus, by taking all polynomials of the order of $k$ and proportional to $x^k$,
so that, for $x^k\neq 0$ (and thus excluding the trivial solution),
\begin{equation}
\begin{array}{l}
k(k-1)a_kx^{k} - (k+2)(k+1)a_{k+2}x^{k} +  2ka_kx^{k}  -\lambda  a_kx^k =0,\\
k(k+1)a_k  - (k+2)(k+1)a_{k+2}    -\lambda  a_k  =0,\\
a_{k+2} = a_k\frac{k(k+1) - \lambda}{(k+2)(k+1)}.
\end{array}
\label{2011-m-ch-pcde1236}
\end{equation}

In order to converge also for $x=\pm 1$, and hence for $\theta =0$ and $\theta= \pi$,
the sum in (\ref{2011-m-ch-pcde12})
has to have only {\em a finite number of terms}.
Because  if the sum would be infinite, the terms $a_k$, for large $k$,
would converge to $a_k \stackrel{ k  \rightarrow \infty}{\longrightarrow} a_\infty$ with constant $a_\infty \neq 0$,
and thus $\Theta$ would diverge as
$\Theta (1) \stackrel{ k  \rightarrow \infty}{\approx} k a_\infty  \stackrel{ k  \rightarrow \infty}{\longrightarrow}  \infty$ .
That means that, in Eq. (\ref{2011-m-ch-pcde1236})
for some $k=l\in {\Bbb N}$, the coefficient  $a_{l+2}=0$ has to vanish; thus
\begin{equation}
\lambda = l(l+1).
\label{2011-m-ch-pcde12361}
\end{equation}
This results in {\it Legendre polynomials} $\Theta (x) \equiv P_l(x)$.
\index{Legendre polynomial}


Let us now shortly mention the case $m\neq 0$.
With the same variable substitution  $x = \cos \theta$, and thus
$\frac{dx}{d\theta}= -\sin \theta$ and  $dx= -\sin \theta d\theta$ as before,
the equation for the polar dependent factor (\ref{2011-m-ch-pcde})
becomes
\begin{equation}
\begin{array}{l}
\left\{
\frac{   d   }{   d    x }
(1-x^2) \frac{   d    }{   d    x }  +  l(l+1)   -\frac{m^2}{ 1-x^2 }
\right\}
\Theta(x)  =0,\\
\end{array}
\label{2011-m-ch-pcde9}
\end{equation}
This is exactly the form of the
general Legendre equation (\ref{2011-m-ch-sfgle}), whose solution is a multiple
of the associated Legendre polynomial   $\Theta_l^m(x) \equiv P_l^m(x)$, with $\vert m\vert \le l$.


\subsection{Solution of the equation  for radial factor $R(r)$}

% http://www.eng.fsu.edu/~dommelen/quantum/style_a/nt_hydr.html

The solution of the equation   (\ref{2011-m-ch-qae4a})
\begin{equation}
\begin{array}{l}
\left\{  \frac{   d   }{   d    r}  r^2\frac{   d   }{   d    r}   +
\frac{2\mu r^2}{\hbar^2} \left(\frac{e^2}{4\pi \epsilon_0r} + E \right) \right\} R(r)
 =  l(l+1)  R( r ) \textrm{ , or}\\
-\frac{1}{R(r)} \frac{d}{   d    r}  r^2\frac{   d   }{   d    r} R( r ) +    l(l+1)
-\frac{2\mu e^2}{4\pi \epsilon_0\hbar^2} r
 = \frac{2\mu  }{ \hbar^2}  r^2 E
\end{array}
\label{2011-m-ch-qae4a19}
\end{equation}
for the radial factor $R(r)$
turned out to be the most difficult part for Schr\"odinger
\cite{Moore-Schroedinger}.

Note that, since the additive term  $ l(l+1) $ in (\ref{2011-m-ch-qae4a19}) is dimensionless,
so must be the other terms.
We can make this more explicit by the substitution of variables.

First, consider $y =\frac{r}{a_0}$ obtained by dividing $r$ by the
{\em Bohr radius}
\index{Bohr radius}
\begin{equation}
a_0= \frac{4\pi \epsilon_0 \hbar^2}{m_e e^2}\approx 5\; 10^{-11} m,
\label{2011-m-ch-qaebohrr}
\end{equation}
thereby assuming that the reduced mass is equal to the electron mass $\mu \approx m_e$.
More explicitly,
$r=y  \frac{4\pi \epsilon_0 \hbar^2}{m_e e^2}$.
Second, define $\varepsilon = E \frac{2\mu a_0^2}{\hbar^2}$.

These substitutions yield
\begin{equation}
\begin{array}{l}
-\frac{1}{R(y)} \frac{d}{   d    y}  y^2\frac{   d   }{   d    y} R( y ) +    l(l+1)
-2 y
 = y^2 \varepsilon \textrm{, or}\\
-y^2 \frac{d^2}{   d^2    y} R( y )  - 2 y \frac{   d   }{   d    y} R( y )
+ \left[   l(l+1) -2 y   -\varepsilon   y^2  \right] R( y )
 = 0.
\end{array}
\label{2011-m-ch-qae4a191}
\end{equation}

Now we introduce a new function $\hat{R}$  {\it via}
\begin{equation}
R(  \xi )=  \xi ^l e^{-\frac{1}{2}  \xi }\hat{R}(  \xi ) ,
\label{2011-m-ch-qae4a19s}
\end{equation}
with $  \xi =\frac{2y}{n}$ and by replacing the energy variable with
$\varepsilon =-\frac{1}{n^2}$, with $n\in {\Bbb N}-0$,
so that
\begin{equation}
\begin{array}{l}
\xi  \frac{d^2}{   d^2    \xi}\hat{R}( \xi )  +[ 2 (l+1)-\xi] \frac{   d   }{   d    y} \hat{R}( \xi )
+ ( n-l-1  ) \hat{R}( \xi )
 = 0.
\end{array}
\label{2011-m-ch-qae4a191ssAe}
\end{equation}

The discretization of $n$ can again be motivated by requiring physical properties from
the solution; in particular, convergence.
Consider again a series solution {\it Ansatz}
\begin{equation}
\hat{R}(  \xi ) =c_0 +c_1\xi  +c_2\xi^2 +\cdots +c_k\xi^k  +\cdots,
\label{2011-m-ch-qae4a19sssA}
\end{equation}
which, when inserted into (\ref{2011-m-ch-qae4a191}),
yields
\begin{equation}
\begin{array}{l}
\xi  \frac{d^2}{   d^2    \xi} [c_0 +c_1\xi  +c_2\xi^2 +\cdots +c_k\xi^k  +\cdots]\\
\qquad \quad  +[ 2 (l+1)-\xi] \frac{   d   }{   d    y} [c_0 +c_1\xi  +c_2\xi^2 +\cdots +c_k\xi^k  +\cdots]\\
\qquad \quad + ( n-l-1  ) [c_0 +c_1\xi  +c_2\xi^2 +\cdots +c_k\xi^k  +\cdots]\\
 \qquad  = 0,\\
\xi   [ 2c_2  +\cdots k(k-1) c_k\xi^{k-2}  +\cdots]\\
\qquad \quad  +[ 2 (l+1)-\xi]   [   c_1   +2c_2\xi  +\cdots +k c_k\xi^{k-1}  +\cdots]\\
\qquad \quad + ( n-l-1  ) [c_0 +c_1\xi  +c_2\xi^2 +\cdots +c_k\xi^k  +\cdots] \\
 \qquad = 0,\\
  \;[ 2c_2\xi    +\cdots +k(k-1) c_k\xi^{k-1}  +\cdots]\\
\qquad \quad  +  2 (l+1)   [   c_1   +2c_2\xi  +\cdots +k +c_k\xi^{k-1}  +\cdots]\\
\qquad \qquad   -  [   c_1 \xi    +2c_2\xi^2  +\cdots +k c_k\xi^{k }  +\cdots]\\
\qquad \quad + ( n-l-1  ) [c_0 +c_1\xi  +c_2\xi^2 +\cdots c_k\xi^k  +\cdots] \\
 \qquad = 0,\\
  \;[ 2c_2\xi    +\cdots +k(k-1) c_k\xi^{k-1}  +k(k+1) c_{k+1}\xi^{k } +\cdots]\\
\qquad \quad  +  2 (l+1)   [   c_1   +2c_2\xi  +\cdots +k c_k\xi^{k-1}  +(k+1) c_{k+1}\xi^{k } +\cdots]\\
\qquad \qquad   -  [   c_1 \xi    +2c_2\xi^2  +\cdots +k c_k\xi^{k }  +\cdots]\\
\qquad \quad + ( n-l-1  ) [c_0 +c_1\xi  +c_2\xi^2 +\cdots+ c_k\xi^k  +\cdots] \\
 \qquad = 0,\\
\end{array}
\label{2011-m-ch-qae4a191ssA}
\end{equation}
so that, by comparing the coefficients of $\xi^k$, we obtain
\begin{equation}
\begin{array}{l}
k(k+1) c_{k+1}\xi^{k }   + 2 (l+1) (k+1) c_{k+1}\xi^{k }
=
k c_k\xi^{k }  - ( n-l-1  )c_k\xi^k ,\\
c_{k+1}   [k (k+1)   + 2 (l+1)(k+1) ]
=
c_k   [k - ( n-l-1  )]  ,\\
c_{k+1}  (k+1) (k  + 2l + 2  )
=
c_k   (k -   n+l+1   )  ,\\
c_{k+1}
=
c_k   \frac{k -   n+l+1   }{(k+1) (k  + 2l + 2  )}  .\\
\end{array}
\label{2011-m-ch-qae4a191ssA5}
\end{equation}
The series terminates at some $l=q$ when  $q =   n-l-1$,
or  $ n=  q+l+1$. Since $q,l$, and $1$ are all integers,
$n$ must be an integer as well.
And since $q\ge 0$, $n$ must be at least $l+1$, or
\begin{equation}
l\le n-1 .
\label{2011-m-ch-qae4a191ssA5hqz}
\end{equation}


Thus,  we end up with an {\em associated Laguerre equation}
\index{associated Laguerre equation} of the form
\begin{equation}
\left\{
  \xi    \frac{d^2}{   d     \xi  ^2 }
+[2(l+1)-  \xi  ]  \frac{d }{   d       \xi  }
+(n-l-1)
\right\}    \hat{R}(   \xi  ) =0
\textrm{, with } n \ge l+1\textrm{, and } n,l\in {\Bbb Z}.
\label{2011-m-ch-qaeale}
\end{equation}
Its   solutions are  the {\it associated Laguerre polynomials}
$L^{2l+1}_{n+l}$
which are the  the $(2l+1)$-th derivatives of the
Laguerre's polynomials  $L^{2l+1}_{n+l}$; \index{Laguerre polynomial}
that is,
\begin{equation}
\begin{array}{l}
 L_n(x)=e^x   \frac{d^n }{   d     x^n }  \left (x^ne^{-x}\right),\\
 L_n^m(x)=   \frac{d^m }{   d     x^m }  L_n(x).
\end{array}
\label{2011-m-ch-qaelp}
\end{equation}
This yields a normalized wave function
\begin{equation}
\begin{array}{l}
R_n(r) =  {\cal N}
\left( \frac{2 {r}}{n a_0 }\right)^l e^{-\frac{r}{a_0 n}}
L^{2l+1}_{n+l} \left( \frac{2 {r}}{n a_0 }\right)\textrm{, with}\\
{\cal N}   =-\frac{2}{n^2}\sqrt{\frac{(n-l-1)!}{[(n+l)!a_0]^3}} ,
\end{array}
\label{2011-m-ch-qaecsrp}
\end{equation}
where
${\cal N}$ stands for the normalization factor.

\subsection{Composition of the general solution of the Schr\"odinger Equation}

Now we shall coagulate
\marginnote{Always remember the alchemic  principle of {\it solve et coagula}!}
and combine the factorized solutions (\ref{2011-m-ch-qaesva})
into a complete solution of the Schr\"odinger equation
\begin{equation}
\begin{array}{l}
\psi_{n,l,m} (r, \theta ,\varphi ) \\
\quad = R_n(r)Y_l^m ( \theta ,\varphi )\\
\quad = R_n(r)\Theta_l^m(\theta)\Phi_m(\varphi)  \\
\quad = -\frac{2}{n^2}\sqrt{\frac{(n-l-1)!}{[(n+l)!a_0]^3}}
\left( \frac{2 {r}}{n a_0 }\right)^l e^{-\frac{r}{a_0 n}}
L^{2l+1}_{n+l} \left( \frac{2 {r}}{n a_0 }\right)
 P_l^m(x)
\frac{e^{im\varphi}} {\sqrt{2\pi }  } .
\end{array}
\label{2011-m-ch-qaesva}
\end{equation}

\eexample
}

\begin{center}
{\color{olive}   \Huge
%\decofourright
 %\decofourright
\decofourleft
%\aldine X \decoone c
%\floweroneright
% \aldineleft ]
% \decosix
%\leafleft
% \aldineright  w  \decothreeleft f \leafNE
% \aldinesmall Z \decothreeright h \leafright
% \decofourleft a \decotwo d \starredbullet
%\decofourright
% \floweroneleft
}
\end{center}
