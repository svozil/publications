%%tth:\begin{html}<LINK REL=STYLESHEET HREF="http://tph.tuwien.ac.at/~svozil/ssh.css">\end{html}
\documentclass[pra,preprint,showpacs,showkeys,amsfonts]{revtex4}
\usepackage{graphicx}
%\documentstyle[]{article}
\RequirePackage{times}
\RequirePackage{courier}
\RequirePackage{mathptm}
%\renewcommand{\baselinestretch}{1.3}


\begin{document}

\def\ttt{{\rm Tr} }
\def\diag{{\rm diag} }
%\def\frak{\cal }
%\def\Bbb{\bf }
%\sloppy




\title{Censorship and the peer review system}
\author{Karl Svozil}
 \email{svozil@tuwien.ac.at}
\homepage{http://tph.tuwien.ac.at/~svozil}
\affiliation{Institut f\"ur Theoretische Physik, University of Technology Vienna,
Wiedner Hauptstra\ss e 8-10/136, A-1040 Vienna, Austria}

\begin{abstract}
In the best of all worlds, peer review amounts to benign measure of quality control,
saving trees, human efforts and money
spent by attempts to cope with erroneous or badly written papers.
In the worst case, peer review amounts to malign censorship,
impede progress, and hence to a waste of human efforts and (mostly taxpayer's) money.
It is argued that, in the way it is commonly executed by editorial boards
and funding agencies, peer review does often more bad than good.
Alternatives to peer review are briefly suggested and discussed.
\end{abstract}


\pacs{01.70.+w,01.65.+g}
\keywords{Philosophy of science; History of science}

\maketitle

\section{What is peer review?}

How would you explain peer review (PR) to a layman?
Maybe like so:
Scientific results are usually reported in articles in specific newspapers called (scientific) journals.
The authors of the articles do what they consider to be scientific research,
then write up a summary of it and send this (mostly) unsolicited text, often called ``paper,'' to a journal.
An  editorial board consisting of fellow scientists
decides whether or not
this research report is published; i.e., printed as journal article.

The decision procedure is as follows.
The manuscript is sent out to other ``peer'' researchers in that area called ``referees.''
The referees review the manuscript and submit an evaluation to the editorial board.
Most of the time, this evaluation will contain critical remarks and suggestions to improve the manuscript.
And it includes suggestions to refuse or accept publication of the manuscript,
maybe in a revised form.
Based on but not restraint by
the recommendation(s) of the referee(s), the editors decide about refusal or acceptance.
Usually, the referee report is send out anonymized to the authors,
either with a request to revise the manuscript, or to motivate the editorial board's decision.
This procedure can be iterated, either with the same or with another scientific journal.
(Many journals also have official appeals procedures.)
Thus, taken at face value,
PR appears to be a sort of censorship which assures and certifies the quality of research
by sending reports back and forth between authors and their ``peers.''
This complicated procedure could improve articles,
prevent the authors from publishing an embarrassing mistake,
and the community at large from erroneous or low-quality work.



PR has been explained for publications, but most of this applies to the dissemination of
money; i.e.,  research funding, as well.
This is very important, because besides ideas and concepts,
money steers research projects more than everything else does (with the possible
exception of the researcher's passion to pursue a project).
Without money, no scientist could survive; especially not the experimentalists.
They could not buy the equipment, pay the room rent, the stationary,
their communication links et cetera.
Most of the time money comes from agencies which are more or less directly funded by
taxes; both in civilian and military research.
(Of course, there is much applied industrial research as well, directed mainly at increasing profits
and share value. This is a slightly different world with a somewhat different approach to
research funding, which we shall not discuss here.)

I would like to emphasize this fact, because
PR is the principal method by which tax money is distributed to the scientific community.
Therefore, at least as far as  taxpayers are concerned,
PR has a public political dimension.
It is not only the business of the scientific community,
but it is the taxpayers who pay the bill.
Hence, they should also care about the efficiency of PR,
its quality, and its possible alternatives.

Whereas most scientific insiders, scientists and science administrators alike,
may have either been subconsciously brainwashed
or have rationally convinced themselves   into  accepting PR as a sacrosanct
demarcation criterion between ``good'' and ``bad'' science
(and are coping with it by various strategies),
laymen, in particular politicians and managers, are usually less convinced.
Yet, they accept the claim that the scientific community manages itself
properly and cost-effectively without much interference from the outside;
mostly by benign censorship such as PR.
Direct political intervention is considered to be a bad sign,
resulting in wasteful investments of research money.
Moreover,among administrative bodies and bureaucrats,
PR serves as a convenient method to distribute and diffuse responsibility,
and to  make decisions appear ``objective'' and based on consensus
\cite{2001-foerster}.

However, some doubts remain.
The Swiss {\em Wissenschaftsrat,} an official body advising the Swiss government,
for instance, started a monumental initiative to find future hot spots of research.
Systematically, hundreds of professors were asked to locate them.
After time passed by the recommendations could be compared with what actually happened,
and these recommendations turned out not to be very helpful,
in some cases even distractive \cite[in German]{swizz-science}.


Historically, PR was not always executed exactly in the way it is implemented presently.
Introduced in the 1660's by the scholarly {\em Journal des Savants} and by
the {\em Philosophical Transactions} published by the {\em Royal Society of London,}
it always relied on direct judgments and decisions of its editors and on fellow researchers.
In 1858, a communication of the late Michael Faraday (on the transition from gravitation
into other forces), who had just been approached by  the {\em Royal Society of London}
to become its president,
was for instance rejected by the {\em Philosophical Transactions} on the grounds that it
obtained only negative results.

The year 1931 saw a paper \cite{beck-bethe-riezler} by G. Beck, H. Bethe, and W. Riezler in {\em Die Naturwissenschaften},
a highly respected PR journal
(e.g., Erwin Schrödinger published his famous series of articles
{``Die gegenw{\"{a}}rtige {S}ituation in der {Q}uantenmechanik''} there \cite{schrodinger} in 1935),
in which the later Nobel laureate Hans Bethe and his co-authors parody the type of ``numerology''
practiced
by the late Sir Arthur Eddington.
The editors of {\em Die Naturwissenschaften} accepted this article in good faith.
It is quite remarkable that this spoof paper, after it had beed disclosed as a hoax, was taken with a good sense of humor at the time,
something notably lacking in the recent Sokal case.

In 1937, Albert Einstein sent a manuscript on gravitational waves to {\em Physical Review}
 published by the {\em American Physical Society.}
After receiving a lengthy referee report
asking for clarifications (citation from Abraham Pais' book \cite[pp. 494-495]{pais}), {\em
``Einstein was enraged and wrote to the editor that he
   objected to his paper being shown to colleagues prior
   to publication.  The editor courteously replied that
   refereeing was a procedure generally applied to all
   papers submitted to his journal, adding that he regretted
   Einstein may not have been aware of this custom.  Einstein
   sent the paper to the Journal of the Franklin Institute
   and, apart from one brief note of rebuttal, never
   published in the Physical Review again .''}

It is important that,
as has been stated by Paul Ginsparg \cite{2001-ginsparg},
{\em ``it is also useful to bear in mind that much of the entrenched
current method is a post-World War II construct,
including the large-scale entry of commercial publishers
and the widespread use of peer review for mass production quality control
(neither necessary to, nor a guarantee of, good science).''}



\section{What scientists can expect when publishing their results:
Anecdotal cases of  peer review}

To set the stage, let me first tell some anecdotes about what awaits scientists
having to cope with PR.
Most scientists have their favorite, more or less funny little stories
about their encounter with PR.
Here are some anecdotes that have bean told by trustworthy colleagues.
I shall anonymize the plots, as some of them might be considered
to be upsetting to authors, referees and editors, but I assure the reader that
all of them are authentic.
Highly respected journals are involved, which rank among the top in
the science citation index.
Upon request, I could disclose details to every single one of them.

A paper  received the following, contradictory evaluations:
the first report basically stated that the idea was crazy but the paper was nicely written
and the formalism correct; the second report stated that, just to the contrary,
the paper technically was unsatisfactory but the idea was very original.

In another case,
the reviewer explicitly expressed his opinion that if he did not know that
its author was such a highly respected
researcher, he would not accept the claims of the paper.
He  did not give too many technical details as to why he resented the paper.
The reviewer contacted the author ``sideways'' (not through the editor but directly),
declaring his role in the review process
and kindly attempted to direct the author's attention to a totally unrelated
treatise written by the reviewer.

Another  renown researcher, after his retirement,
wanted to know the scientific value of his recent research articles.
One issue was to test PR.
He therefore attempted to publish some papers not under his own ``brand,`` but invented
completely new author names.
Many of these papers were rejected immediately, for various reasons,
which was certainly not this author's experience when publishing under his true name.


Another  renown researcher stated that he does not submit research papers
to PR journals any more, because he simply refused to cope with the
not very helpful, sometimes mean (as he perceived it) comments of most reviewers.
Instead, he publishes things only when invited to contribute to collections of papers.
(He often receives invitations.)
This compares with the examples of Faraday and Einstein mentioned above.


A team of researcher had a very important result.
They decided not to publish
the finding in a ``letter'' journal but rather securely publish
it in an rather arbitrary conference proceeding,
thereby effectively and on purpose avoiding the risks of PR.
The paper sparked off an avalanche of papers in very prestigious journals, among them
the ``letter'' journal.

Scientist ``Alice'' suggested to author ``Bob'' to review a paper written by another author ``Eve''
who had challenged some of Alice's findings. Upon this request
(and by scientific interest), Bob decided to write a paper.
Throughout the writing of the paper, Bob had always been in contact with Alice, exchanging ideas related to the paper.
When submitted, the referees of the first journal rejected the paper immediately.
They did not give specific reasons but just claimed that Bob did not at all understand
the original paper by Alice. (Remember that Bob wrote the paper on Alice's request and guidance.)
In the second round of peer review of the second journal, one referee called the paper
``perverse'' and therefore recommended rejection. Although it was a paper
in mathematical physics, the editor
decided to communicate this judgment to the author and based his rejection
on this judgment of the referee.
Finally, after a delay of over one year, a third journal accepted the paper almost immediately.
Since then this ``perverse'' paper has been cited by various researchers in the area.

It took the assistant editor of a
``letter'' journal devoted (by its own understanding)
to the rapid dissemination of research
results,  1.5 months just to decide that the paper was too long to fit as a letter
(the paper exceeded negotiable 5 percent of the acceptable length).
During that time, it was not even sent out to PR.
After shortening, it was rejected because although one reviewer recommended publication,
the other reviewer suggested
mainly that this paper was the outcome of
``a cottage industry'' of researchers writing similar papers.
In a similar mood, another paper was rejected because the referee
suggested that next time the group of experimentalists might
consider ``chicken soup'' as their research object.

In reviewing a research proposal, one referee pointed out that
the popularity of a particular website
presenting a scientific result is totally irrelevant
as a criterion for the need of funding the ongoing research in that area.
The referee also pointed out that the applicant had published recently
many papers in what the referee considered as
``hardly refereed research journals,''
whereby he completely overlooked other papers in more prestigious journals.
and also did not realize that these papers
were published as volumes of conference proceedings (biannual meetings of a scientific society),
and one was by invitation in the honor of a very renown researcher.
Although two other referee reports recommended funding,
the board reviewing this proposal decided that this criticism was severe enough and refused funding.
The comments, together with other, mostly intimidating statements of the referee,
were communicated to the author as basis of the decision.


Many more such stories could be and have been told, probably the most stunning ones
dealing with papers which were rejected and later earned its author the Nobel prize
\cite{npp-reject}.
In order not to be boring,
I shall continue with some basic observations and arguments pro and contra
PR without much discussion.
The arguments, of course, cannot be induced from such anecdotes but are subjective evaluations.


\section{Some empirical studies and model calculations}

In what follows, some empirical findings are reviewed.
For more references and detailed
discussions, see the articles by Gerhard Fr{\"{o}}hlich
\cite[Section 4.1-4.4, in German]{2002-froehlich}
and Sergio Della Sala and Jordan Grafman
 \cite{sala-2002} (including the contributions to the discussion forum on PR in {\em Cortex}, volume 38, third issue, June 2002).

In one of the most striking studies \cite{1982-petersceci}, twelve (psychology) journals
(which have one of the highest rejection rates) were selected,
and a single one article per journal was taken out at random.
These articles were then given other headers (title, authors, affiliations), and minor
cosmetic changes.
They were re-submitted to the very same journals which had printed them 1.5-3 years ago.
From these twelve groups of editors and referees, only three (!)
realized that this was an obvious hoax of a copycat.
All the other nine papers underwent PR again. From these, only a single one was
re-accepted; the other eight were rejected on the basis of the new referee reports;
mainly because they allegedly suffered from ``grave methodological errors.''

In another study \cite{1988-baxt}, a fictious medical manuscript was generated, in which on purpose ten serious and
thirteen not so serious mistakes had been embedded.
PR of this study resulted in the following results:
15 referees advised acceptance
and found 17 percent of the serious and 12 percent of the small mistakes.
117 referees advised rejection
and found 39 percent of the serious and 25 percent of the small mistakes.
The authors conclude that, ``sixty-eight percent of the reviewers did not realize that the conclusions
of the work were not supported by the results.
Peer reviewers in this study failed to identify two thirds of
the major errors in such a manuscript.''

A 1981 study on research projects in physics, chemistry and economics \cite{1981-cole}
was summarized by the authors as follows:
{\em ``An experiment in which 150 proposals submitted to the National Science
Foundation were evaluated independently by a new set of reviewers indicates
that getting a research grant depends to a significant extend on chance.''}
They proceed by stating that,  {\em ``the degree of disagreement within the population of eligible reviewers
is such that whether or not a proposal is funded depends in a large proportion
of cases upon which reviewers happen to be selected for it.''}

Another study discusses the low correlation (0.2-0.3 \cite{1991-lindsay})
of advises from referee reports,
and the resulting difficulty for the editor to make a decision based on them.

There is indication \cite{1994-nylenna} that the tendency to accept a paper tends is
correlated with the age of a referee; the younger the referee,
the higher is the rejection rate. (I resent from speculating why this is the case.)

Over 600 authors were questioned about their experiences with
PR \cite{1981-bradley}.
They expressed their frustration over low-quality idiosyncratic reports
which concentrated on trivialities while did not grasp essentials, and
lamented about incompetence of the referees, which treated them inferiorly.
Many referee reports seemed to have been written to impress the editors
rather than improve the quality of the report.

In a 1997 investigation  \cite{1997-armstrong}, the author states that {\em
``current procedures ... seem to discourage scientific advancements,
especially important innovations,
because findings that conflict with current beliefs are often judged to have defects.}
(see also \cite{1992-yamazaki,1995-yamazaki}.)

A very recent study \cite[in German]{2002-gorraiz-schloegl} by Gorraiz and Christian Schl{\"{o}}gl
investigated the connection
between ranking schemes of scientific journals and actual usage statistics in
terms of documents delivered by subito \footnote{www.subito-doc.com},
a document service which is widely used in German speaking area (Germany/Switzerland/Austria),
with approximately 700,000 orders per year.
%Table \ref{gorraiz-schloegel} lists
The authors compare the TOP-50
ranking of subito with the {\em Journal of Citation Reports} (JCR) ranking.
The Pearson correlation is 0.61 and a Kendall coefficient of 0.28.
The most requested journal, Annals of the New York Academy of Sciences,
is ranked 99 by JCR; the forth journal, Proceedings of the Society of Photo-Optical Instrumentation
Engineers is not even listed by JCR.
%\begin{table}[htbp]
%{\scriptsize
%%\setlength{\tabrowsep}{0pt}
%\renewcommand{\arraystretch}{0.5}
%\begin{center}
%\begin{tabular}
%{|c|l|c|}
%\hline\hline
%\textbf{Ranking}&
%\textbf{Journal}&
%\textbf{Ranking JCR} \\
%\hline\hline
%1&
%Annals of the New York Academy of Sciences&
%99 \\
%2&
%The journal of biological chemistry&
%1 \\
%3&
%The lancet (London)&
%12 \\
%4&
%Proceedings of the Society of Photo-Optical Instrumentation Engineers&
%- \\
%5&
%Nature (London)&
%2 \\
%6&
%Proceedings of the National Academy of Sciences of the USA&
%3 \\
%7&
%Science&
%4 \\
%8&
%Journal of the American Chemical Society&
%5 \\
%9&
%The New England journal of medicine&
%9 \\
%10&
%Neurology&
%48 \\
%11&
%Analytical biochemistry&
%65 \\
%12&
%The journal of the American Medical Association / Engl. Ausg.&
%22 \\
%13&
%Biochemical and biophysical research communications&
%30 \\
%14&
%Cancer research&
%15 \\
%15&
%Analytical chemistry&
%45 \\
%16&
%Biochimica et biophysica acta&
%- \\
%17&
%Circulation&
%16 \\
%18&
%The American journal of gastroenterology&
%205 \\
%19&
%Expert opinion on investigational drugs&
%- \\
%20&
%Methods in enzymology&
%85 \\
%21&
%Biochemistry&
%14 \\
%22&
%Annals of internal medicine&
%61 \\
%23&
%Advances in experimental medicine and biology&
%- \\
%24&
%Pharmaceutical research&
%446 \\
%25&
%The journal of organic chemistry&
%29 \\
%26&
%Journal of biomedical materials research&
%389 \\
%27&
%Journal of applied polymer science&
%168 \\
%28&
%Oncogene&
%64 \\
%29&
%American journal of physiology&
%211 \\
%30&
%Tetrahedron letters&
%33 \\
%31&
%The British journal of cancer&
%122 \\
%32&
%Angewandte Chemie / International edition in English&
%34 \\
%33&
%Nucleic acids research&
%36 \\
%34&
%Journal of clinical oncology&
%63 \\
%35&
%Gastroenterology&
%46 \\
%36&
%Blood&
%18 \\
%37&
%Journal of medicinal chemistry&
%123 \\
%38&
%Journal of applied physics&
%25 \\
%39&
%Clinical orthopaedics and related research&
%147 \\
%40&
%Neuroreport&
%203 \\
%41&
%BioTechniques&
%522 \\
%42&
%Chest&
%112 \\
%43&
%The American journal of clinical nutrition&
%111 \\
%44&
%Journal of rheumatology&
%219 \\
%45&
%Rapid communications in mass spectrometry&
%647 \\
%46&
%The journal of immunology&
%13 \\
%47&
%Cell&
%8 \\
%48&
%Alimentary pharmacology {\&} therapeutics&
%699 \\
%49&
%Mutation research&
%844 \\
%50&
%The journal of clinical psychiatry&
%358 \\
%\hline\hline
%\end{tabular}
%\end{center}
%}
%\caption{subito-TOP-50 (the most requested and delivered journals
%throughout the subito document service which delivered documents 700,000 in 2001),
%as compared to citation index ranking JCR-TOP-50 (from~\cite[in German, Tabelle 4]{2002-gorraiz-schloegl}).
%\label{gorraiz-schloegel}
%Here the correlation among comparable data is about $1/2$.}
%\end{table}



\section{The transformation of scholarly communication into big business}


Science publishing in its present form is very big business,
so one cannot expect from the publishers to give up their cash cow voluntarily.
``I think scientists all over would be shocked to realize
what a phenomenally lucrative business scientific publishing can be,''
Nicholas Cozzarelli, editor-in-chief of the Proceedings of the National Academy of Sciences
of the USA, told Scientific American recently \cite{2001-siam-Karow},
"There are huge sums of money to be had in this field."
The American Association for the Advancement of Science,
for example, finances most of its activities with income from
Science magazine.
Whereas the US Consumer Price Index in the period from  1986 to 1998 increased by 49 percent,
the average journal cost increased more than three times as much; i.e., by 175 percent
\cite[in Swedish]{2001-rabow}.


Indeed, few researcher know that the average revenue of the publisher
from every published article is US\$ 4,000 \cite{1995-odlyzko,1997-odlyzko}.
Paul Ginsparg estimates the revenues for "high end" commercial journals
("high end" refers to the pricing) to be US\$10,000--US\$20,000 per published article
 \cite{2001-ginsparg2}.
For a  typical ``non-profit'' publisher, the revenue is US\$1,000--US\$2,000 per  article.
An electronic start-up venture may have revenues in the US\$500--US\$1,000 per  article range.
One web printer
(an operation that takes the data feed from an existing print publisher
and converts it to HTML and/or PDF)
operates at  US\$500 per article.
Ginsparg estimates
the cost per current submission to {\em arXiv.org} to be in the US\$1-US\$5 range.
At the high end of this scale, he assumes a
minimum US\$50,000 on average to produce the underlying research for the article,
money typically in the form of salary and overhead,
and also for experimental equipment.
In \cite{1997-odlyzko}, Andrew Odlyzko comes to the conclusion that
{\em ``the monetary cost of the time that scholars put into the journal
business as editors and referees is about as large as the total revenue
that publishers derive from sales of the journals.
Scholarly journal publishing could not exist in its
present form if scholars were compensated financially for their work. ''}

The Association of Research Libraries (ARL)
is a not-for-profit membership organization comprising the leading research libraries in North America,
including, among many other venerable libraries,
the libraries of the University of California, the University of Chicago, Cornell University,
Harvard University, the Massachusetts Institute of Technology, and Yale University.
In a remarkable statement \cite{arl-transf}, ARL observes,
{\em ``Scholarly communication has been transformed
from a means of communicating research results to a multi-billion dollar business.

Each year, commercial publishers expand their control
of the scholarly communication market through acquisitions and mergers.
A significant means of expansion is the purchase of individual titles from scholarly societies.

Currently, 121 members of North America's
Association of Research Libraries spend about US\$480
million per year on their journal collections.
To keep these collections at current levels,
by the year 2015 they will have to spend US\$1.9 billion.
It is not unreasonable to assume that all North American
libraries will be spending four billion dollars on
journals alone by 2015, assuming they continue to
receive current levels of support.

The profit margins of commercial publishers of scholarly
information are estimated to run up to 40 percent per year.
Profit is difficult to calculate from the outside of any industry.
It is further complicated in the scholarly communication business
by the fact that most commercial scholarly publishing companies are,
in fact, only one part of a much larger company.''}

%Table \ref{table-arl1} of an article by Brendan J. Wyly  lists some characteristic research data (some estimated)
%of commercial scholarly publishers \cite{wyly-2001,wyly-2001t,arl-income}.
%\begin{table}[htbp]
%{\scriptsize
%%{|p{61pt}|p{77pt}|p{72pt}|p{72pt}|p{72pt}|p{72pt}|}
%\renewcommand{\arraystretch}{0.5}
%\begin{center}
%\begin{tabular}
%{|p{130pt}|c|c|c|c|c|c|c|c|c|c|}
%\hline\hline
%&{\bf Reed Elsevier}&{\bf  Wolters Kluwer}&{\bf  J. Wiley \& Sons}&{\bf Plenum Publishing}&{\bf Totals}                                                                                                           \\
%&December 31, 1997&December 31, 1997&April 30, 1997&December 31, 1997&                                                                                                           \\
%\hline
%Net Sales&\$5,603,880,000 &\$2,569,808,000 &\$431,974,000 &\$52,634,000 &\$8,658,296,000                                                                                              \\
%\hline
%Percentage of Sales from Scholarly Publishing&17\%&14\%&47\%&63\%&                                                                                                                   \\
%\hline
%Sales from Scholarly Publishing&\$952,659,600 &\$359,773,120 &\$203,027,780 &\$33,159,420 &\$1,548,619,920                                                                            \\
%\hline
%Operating Income (before interest \& taxes \& excluding extraordinary items)&\$1,451,400,000 &\$548,101,000 &\$34,797,000 &\$17,626,000 &\$2,051,924,000                                \\
%\hline
%Net Income (excluding extraordinary items)&\$998,760,000 &\$285,644,000 &\$20,340,000 &\$12,824,000 &\$1,317,568,000                                                                  \\
%\hline
%Net Income Available for Common Shareholders&\$997,120,000 &\$285,644,000 &\$20,340,000 &\$12,824,000 &\$1,315,928,000                                                                \\
%\hline
%Assumed Percent of Net Income from Scholarly Publishing&26\%&13\%&47\%&63\%&                                                                                                         \\
%\hline
%Assumed Net Income from Scholarly Publishing&\$259,677,600 &\$37,133,720 &\$9,559,800 &\$8,079,120 &\$314,450,240                                                                     \\
%\hline
%Assumed Net Income Available for Common Shareholders from Scholarly Publishing&\$259,251,200 &\$37,133,720 &\$9,559,800 &\$8,079,120 &\$314,023,840                                   \\
%\hline
%Common Shareholder Equity (prior year)&\$3,534,570,000 &\$685,235,000 &\$117,982,000 &\$63,399,000 &\$4,401,186,000                                                                   \\
%\hline
%Assumed Pecent of Equity in Scholarly Publishing&17\%&14\%&47\%&63\%&                                                                                                                \\
%\hline
%Assumed Equity in Scholarly Publishing&\$600,876,900 &\$95,932,900 &\$55,451,540 &\$39,941,370 &\$792,202,710                                                                         \\
%\hline
%Assumed Net Margin on Scholarly Publishing&27.30\%&10.30\%&4.70\%&24.40\%&                                                                                                           \\
%\hline
%Hypothetical Net Income at 5\% Net Margin on Scholarly Publishing&\$47,632,980 &\$17,988,656 &\$10,151,389 &\$1,657,971 &\$77,430,996                                                  \\
%\hline
%Hypothetical (5\% margin) Savings/(Costs) from Assumed Actual Net Income on Scholarly Publishing&\$212,044,620 &\$19,145,064 &(\$591,589)&\$6,421,149 &\$237,019,244                   \\
%\hline
%Percent Savings for Hypothetical (5\% margin) on Scholarly Publishing&22.30\%&5.30\%&-0.30\%&19.40\%&15.30\%                                                                           \\
%\hline
%Hypothetical Net Income at 18.8\% ROE on Scholarly Publishing&\$112,964,857 &\$18,035,385 &\$10,424,890 &\$7,508,978 &\$148,934,109                                                    \\
%\hline
%Hyptothetical (18.8\% ROE) Savings/(Costs) from Assumed Actual Net Income on Scholarly Publishing&\$146,286,343 &\$19,098,335 &(\$865,090)&\$570,142 &\$165,089,731                    \\
%\hline
%Percent Savings for Hypothetical (18.8\% ROE) on Scholarly Publishing&15.40\%&5.30\%&-0.40\%&1.70\%&10.70\%                                                                            \\
%\hline\hline
%\end{tabular}
%\end{center}
%}
%\caption{Data of some scholarly commercial publishers
%\label{table-arl1}
%(the currency unit is US\$; from Brendan J. Wyly \cite{wyly-2001,wyly-2001t}).}
%\end{table}
ARL also provides sample letters for faculty to refuse to read/referee (\cite{arl-refusal},
for faculty to  resign from journal board, and from faculty members to journals.

\section{More analytic criticism}

The connection between PR and the necessity to pay for scientific information is
evident; for good or bad.
Yet, the very argument that money is necessary to keep and improve
the quality of the publications through PR may be a reason against it.
It is not only a moralistic issue whether or not
the high profits from scholarly publications are justified.
These profits may cripple science in many ways,
just as PR may make science ineffective.
The disadvantages may by far outweigh the positive effects of PR.
Of course, as long as the market tolerates the situation and these very high revenues are not challenged,
justification is obviously not a pressing necessity.
It comes as no surprise that those, like ARL, who have to pay the bill, disagree.
The high prices of scholarly publications
is in striking contrast to the desire of researcher for  easily obtainable information.
Ease includes no or very little charges or costs.
Steven Harnad once summed up this information desire \cite{1999-del-sm,1995-harnard},
{\em ``It's easy to say what would be the ideal online
resource for scholars and scientists: all papers in all fields,
systematically interconnected, effortlessly accessible and
rationally navigable, from any researcher's desk, worldwide for free.''}

%\begin{itemize}

%\item[(i)]
Individually, PR neither means more money nor more scientific recognition
for the anonymous referee.
PR is not paid work and is done voluntarily.
Professional indicators do not measure it
and therefore it is not very relevant for a scientist's credentials.
Its only reward is a (mostly not very well recognizable and measurable) recognition for the reviewer.
In a social environment in which achievements tend to be recognized only when
measurable, and the ultimate measure tends to become money
(although not too many researchers would concede that)
the motivation to put much efforts in PR become lower.
Recall that, different from science,
in private industry and business, consulting tasks are very expensive and highly valued.
So, the more business-like science becomes, either PR must be reimbursed, or it
will eventually break down because no one is willing to work for nothing.
This should be compared to the statement by Andrew Odlyzko in \cite{1997-odlyzko} above.

%\item[(ii)]
{PR is very time-consuming if taken seriously.
Yet, most referees have no time.
Rather, they have to write papers or research proposals which itself are subject to PR.}

%\item[(iii)]
{Editors often are able to ``steer'' PR and its outcome by choosing the ``proper'' reviewers.}
This should be compared to the statement by Cole {\it et al.} \cite{1981-cole} above.

%\item[(iv)]
{Editors do not sufficiently review the report of the reviewers.
They take personally discriminating and intimidating PR as a fact; i.e., they decide accordingly.
For the sake of consistency with its own values,
PR needs to be reviewed in order to controll the controllers, and to increase quality.
This however is not done.}

%\item[(v)]
{PR is a very decisive criterion for professional carriers,
such as the decision to get tenure or not.
Ideally, they are an almost indispensable tool for science managers implementing funding policies.
Realistically, such decisions are as good as PR.
There are even claims that PR is largely for administrative rather than
purely scientific purposes.}
%http://www.mathpages.com/home/albro/albro27.htm
However, this academic necessity of ``publish or perish'' may have the
effect of compelling many people to publish work of marginal
value, not for the scientific reasons, but simply
out of necessity to sustain their academic careers.\footnote{
http://www.mathpages.com/home/albro/albro27.htm }
One aspect of this is
the
tendency on the part of authors towards ``least punishable units,''
as noticed by Paul Ginsparg \cite{2001-ginsparg}.

%\item[(vi)]
{Established researchers would have more chances to publish the same paper as as unknown newbie.}
Recall the experience of a well-established author
who attempted to publish under a new ``label.''

%\item[(vii)]
{Paper is an unimportant limiting cost factor in the dissemination of research reports.
Research is increasingly published electronically---such as
the physics and mathematics preprint server at
arxiv.org \cite{2001-ginsparg}
or attempts towards medical databases such as PubMed
at {pubmedcentral.nih.gov}
\cite{1995-LaPonte}---and reports are printed out on a ``on demand'' basis.
All efforts have to be made to preserve these archives, either electronically,
and even by comprehensive paper printouts for the future generations.}

%\item[(viii)]
{Research journals based on PR effectively become less and less
important for the everyday scientific practice as non-PR preprint servers take over.
This is due to the almost unlimited availability and the homogeneity of manuscripts fetched through
the preprint servers on the one hand, and
the many different complicated accounting systems of most PR journals on the other hand,
which are account- and user restricted on the other hand.
It is, for instance, mostly impossible to fetch any PR research article from home internet connections
(which use an IP-address different from the university contingent)
without using proxy servers which effectively circumvent the restrictions of the publishing houses.
}

%\item[(ix)]
{Authors have very little means to cope with incorrect or even mean PR.
PR effectively acts god-like.
The appeals procedures are sometimes meaningless and a lip service to the community.
Overall, very little attention is given to the quality of the review process.
Notice that, just as for teaching talents, there may be very bad reviewers who could be very good scientists; and vice versa.
}

%\item[(x)]
{The danger to the community from bad quality paper by ``quacks'' are overestimated.
Most ``quacks'' are not even able to produce a properly formatted
manuscript and upload it to a preprint server.}

%\item[(xi)]
{PR unnecessarily prolongs publication of research articles.}

%\item[(xii)]
{PR unnecessarily binds energy of researchers to cope with unreasonable reports.}

Researchers  may favor projects confirming their own views
and well-established conjectures.
The ``best'' (with respect to PR) kind of paper actually extends an already
well respected (by the ``peers'') theory or concept or method in a mildly
original way. Too original thoughts can hardly be distinguished from outlandish speculations
and are therefore punished.
The ``peers'' favor those findings which they expect and anticipate.
The proverb comes to the mind that one should not underestimate
the joy people feel by listening to something they already know.
A typical case is the one of a young AT\&T scientist,
who not long ago had been considered as one of the biggest experts in his field,
but later conceded to have cooked up data. His ``results'' had been subject to PR and accepted by
``highest quality standards'' journals.
But whereas the Sokal case sparked off a debate,
this soon-to-be-forgotten affair hardly raised eyebrows outside of the scientific community.
In this atmosphere it might be quite easy to cook up a research article filled with
conformistic commitments of the kind that
the ``standard Copenhagen interpretation'' is fully satisfactory;
in fact there is no need for too much interpretation of the quantum formalism at all;
that relativistic causality is firmly established,
one could establish quantum coherence up to macroscopic dimensions, and so on.
On the contrary, it would be very difficult to publish articles considering,
as Albert Einstein believed,
a more complete theory than quantum mechanics, or aether theories, or superluminal
information and matter transmission.
Those things are treated just in the same way as claimes that $1+1=5$.
Although mostly it may be a wise strategy not to bother oneself with
outrageous claims, this may delay paradigm changes for rather long times.


PR discriminates underprivileged groups \cite{wenneras-wold-97}.
%\end{itemize}

Finally, let me just mention without going into details the dilemmas of scientometry
\cite[in German]{froehlich-1999e},
the quantitative science of scientific output performance.
Many of its statements are embraced and uncritically used by administration bodies to
objectivize decision procedures.
Despite obvious biases or mistakes, many of these attempts of
data mining do not at all take into account
century-old debated on the progress of science.


\section{Alternative decision methods}



Some defenders of PR may consider any one criticizing PR a ``winer,''
who cannot cope with the constructive criticism of the anonymous peers.
Others, while in principle accepting the fact that PR sometimes fails and in
such cases does more harm than good,
will nevertheless point out that,
to  adapt Sir Winston Churchill's famous dictum about democracy
(\cite{churchill-democracy}; btw., I totally agree with Sir Winston Churchill),
``it has been said that peer review is the worst form of evaluation of scientific research,
except for all those other forms that have been tried from time to time.''


As concerns fast and efficient publication of research reports,
the preprint servers may take over the job of dissemination of scientific results altogether.
They are cheap, fast, effective, and available to researchers or the interested public also
in poorer countries or research institutions which have internet access.


And there are very concrete alternatives to PR, some of which will be briefly mentioned here,
which mostly do not have the negative effects described above.
Some substitute for ``quality'' control
and certification by the peers will come from additional features
of preprint servers such
as anonymous and/or nonanonymous comments associated with every paper version \cite{1995-LaPonte}.



Presently the preprint servers,
such as {\em arXiv.org}, lack the commitment and the legal assurance necessary
for a trustworthy permanent repository of scientific information.
What if, for instance, the {\em National Science Foundation}
stops the software support of this archive?
How is the legal status of the programs and scripts executing  {\em arXiv.org}?
Is it public domain, or GNU
(GNU is a recursive acronym for ``GNU's Not Unix;'' it is pronounced ``guh-NEW''), or freeware?
And, even more pressing:
How is the legal status of the manuscripts published in {\em arXiv.org}?
There are quite a few manuscripts which make it to the database even
after publication of the journal article.
If, for instance, any one of these journals would threaten to make any provider of
{\em arXiv.org}, in particular Cornell University,
liable for all possible copyright infringements,
then, I believe, the expectable reaction of this service provider
(and maybe of all other mirrors)
would be a complete shutdown of services.
Recall that big money is involved which pushes up the stakes.
If these suspicions were correct, the scientific community, in particular
the physics community, presently depends on the good will of the commercial
publishing houses to tolerate copyright infringements;
a situation which apparently is highly
unsatisfactory.

There could only be one answer to that situation: to put articles published
in {\em arXiv.org} under something similar to the {\em gnu.org}
{\em Free Documentation License} \footnote{http://www.gnu.org/licenses/licenses.html\#FDL};
a measure which is not even acceptable to the {\em American Physical Society}
\cite{blume-aps-copyright}. So, there may be troubles ahead.



With regards to the funding of scientific research,
Paul Feyerabend proposed to distribute research
money by the implementation of the grand jury system for making decisions,
a method which is already practiced in the courtrooms.
This would prevent the distribution of money by
pressure groups consisting of peers, whose members are both applicants and evaluators (with varying roles).
Also, it would guarantee more chances to innovative, sometimes crazy-looking
research proposals, which may or may not be progressive, and which  would
have very little chances in PR.

I would even
like to propose a much more radical way of alternate research funding:
to distribute a certain amount of money to research programs by a random
selection, such as by throwing dice.
The random selection could for instance be managed by a lottery.
For such a procedure, it would be almost mandatory to establish very
open and mild preselection procedures to make intentional abuses difficult.
(I am aware that this amounts also to a censorship, albeit a very weak one.)
A model for this could be the advisory board of {\em arXiv.org}
which screens every contribution before its public release.

Some colleagues may find any method of research funding based on
a random selection totally inappropriate.
But notice that there are
findings  \cite{1981-cole} indicating that the present PR-based funding already
 depends to a significant extend on chance.
Also, because of the mere scarcity of resources,
traditional funding practices may have effectively reached this stage already.
Take, for example, the {\em Sixth Framework Programme} and other research funding of the {\em European Union (EU)},
which will accept merely a very tiny fraction
of all applications.           PR fails because even the committee members privately
concede that PR  cannot select and separate the
``best''  research proposals from the ``majority of worse ones,''
therefore effectively creating a scenario where most of the research funding
is randomly distributed by decisions which have to be rationalized nevertheless.
This arbitrariness in the selection procedure, together with pseudo-explanations which have
to serve the goal of creating a pseudo-objective reasoning to
the distribution of research money,
creates mostly frustration within the group of applicants.
It would be much wiser and less embarrassing to tell them
that a lottery has decided by a random procedure that they do not get the money they applied for.
(Some researcher even calculated that it would be more profitable to invest the efforts
that go into EU research proposals into a casino, since there the chances
to get a higher overall return on investments are better.)

In further contradiction with EU guidlines to concentrate research funding of the
{\em Sixth Framework Programme of the European Community} to fewer research areas
which would receive more money than  before,
I would even like to suggest to broaden the funding for research activities
in a ``watering can''-type of way.
Innovative proposals which would have lesser chances
to get funding, might do much better. (This argument  is analogous to  one
against {\it numerus clausus} and access restrictions to university education
via ``quality measures'' such as high school or other scores.)


My personal preference for a division of the money spent by different selection methods
would start from 70:20:10 for
peer review/jury selected/randomly selected, respectively.
A post mortem
evaluation of all three funding groups should be imposed.
This analysis
should, as much as possible, be independent of the (pressure) groups
distributing and receiving the money; maybe
again by grand juries.


It should never been forgotten that there are strong pressure groups
which defend PR because they profit from it, financially and otherwise.
The ever increasing revenues of publishing houses directly depend on PR.
Also, the researchers in editorial boards and selection committees derive much influence and
gratification from these positions and the privileges associated with them.

And it should not be forgotten that the individual researcher enjoys the pursuit of truth.
While few will resent positive and helpful suggestions to improve their manuscripts,
many researchers often experience PR as an unjustified, frustrating fight with ignorant,
mean ``peers'' which sometimes bring misery to those wishing to explore new ideas.
This often amounts to a loss of productivity, especially of innovative, creative inventiveness,
which translates into an impediment of science and to a waste of money.


Almost needless to say, any deficiency of the methods, including PR,
by which (mostly public) money is disseminated to the scientific community,
amounts to a waste of resources.
In case of public money, this is a very delicate matter,
because these resources are primarily taken away from
the common voter and by taxation in general.
Therefore, the methods have to be carefully chosen,
not only to foster science, but also for political reasons.


%\appendix
%
%\section{ARL sample letter for faculty:
%refusal to read/referee (reprinted from \cite{arl-refusal})}
%
%
%Dear ...:
%
%It is with great regret that I notify you that I am no longer able to serve as a reader/referee for articles submitted to Title of Journal.
%
%I am brought to this decision because your pricing policy for this journal is at odds with a fundamental value of scholarship, to make scholarly research as widely available as possible. Because of the journal's extraordinarily high cost and astonishingly high annual price increases, it has effectively been placed out of reach of many of my colleagues whose libraries can no longer afford it.
%
%I feel that you have lost touch with the core purposes of scholarly communication, and I cannot, in conscience, participate in an enterprise that apparently values profit more than the goals of scholarship.
%
%Moreover, I shall now seek to support, through my submissions and my reviewing activities, alternatives to Title of Journal that maintain affordable costs, as well as cost increases that are clearly related to actual production costs and added value -- in short, costs that promote the widest possible availability of my work and the work of my colleagues.
%
%Should you change your pricing policies so that they are more in line with scholarly values, please let me know.
%
%Sincerely,   ...




\bibliography{svozil}
\bibliographystyle{apsrev}
%\bibliographystyle{unsrt}

\end{document}
