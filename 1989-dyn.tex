\documentstyle[12pt]{article}
\begin{document}
\title{Are chaotic systems dynamically random ?}
\author{Karl Svozil\thanks{Computer address:
Bitnet (EARN): E1360DAB at AWIUNI11.}\\
{\small \sl Institute for Theoretical Physics,}\\
{\small \sl Technical University Vienna,}\\
{\small \sl Karlsplatz 13, A--1040 Vienna, Austria.}
}

\maketitle
\begin{abstract}
Physical systems can be characterized by several types of complexity
measures which indicate the computational resources employed.
With respect to these measures, several chaos classes may be
distinguished.
There exists a constructive approach to random physical motion which
operates with computable initial values and deterministic evolution
laws.
For certain limits, these chaos classes render identical forms of
random physical motion.
These observations may have some implications on a unique time
direction for macroscopic reversible systems.
\end{abstract}
\vfill \eject
1.
The classical deterministic continuum physics induces an
indeterminism which is at least as strong as the
probabilistic interpretation of the Schr\"odinger wave
function---``Almost all'' (with respect to an arbitrary measure)
elements of the continuum are uncomputable, i.e., they cannot be
calculated by an algorithm on a universal computational device
\cite{rogers1}.
Therefore, if one assumes equidistribution, the initial configuration of
a classical system must be represented by an uncomputable number with
probability one.
Since present--day definitions of uncomputability are essentially
equivalent to (normalized) randomness \cite{alekseev,svozil1}, this
renders chaotic motion for deterministic evolution functions capable of
``unfolding'' the randomness of the initial values.
A sufficient criterion for such an evolution function is the instability
of trajectories towards variations of the initial configuration $\delta
X_0$, such that at later times $t$ and for positive Lyapunov exponent
$\lambda^+$, $\delta X_t\approx \delta X_0 \exp (\lambda^+ t)$.
In this sense the ``deterministic chaos'' of classical physics
originates in the assumption of the continuum (see also refs.
\cite{ford1,svozil1}).

Quantum theory partially circumvents these uncomputabilities
by postulating a discrete phase space. Nevertheless, despite a discrete
state space for bounded systems, the Schr\"odinger wave function is
represented as element of a continuum.
Moreover, the probabilistic interpretation of the Schr\"odinger wave
function, which undergoes a deterministic evolution between state
preparation and measurement, is generally perceived as
an expression of indeterminism.

2.
Rather than attempting a deeper investigation of the differences between
classical and quantum physics with respect to the random evolution
of the Schr\"odinger wave function (see
for instance refs.
\cite{krylov1,chirikov3,casati1,casati2,casati3,svozil1}),
this Letter deals with a specification of the appropriateness of formal
notions of randomness for physical chaotic motion.
Thereby, techniques from algorithmic complexity theory and the theory of
recursive functions provide a powerful basis.

Heuristically speaking, complexity is a measure of the resources
necessary to perform a computation.
These resources can be grouped into the following two categories.
{\it (i)}
Dynamic or computational complexity measures characterize the minimal
amount of time (and storage capacity), whereas
{\it (ii)}
static or algorithmic complexity measures specify the minimal
program size (and loop depth) necessary to perform a computational task.
The associated definitions of randomness are based upon intuitive
notions of incompressibility---either in time resources, such that no
computational ``shortcut'' exists \cite{wolfram1}, or in program size,
such that no shorter description interpretable as generating law
\cite{chaitin1} may reproduce a random timeflow.
The formal definitions will be given next.
They rest upon the representation of an experimental sequence in
a symbolic string $x$ \cite{alekseev}.

The {\sl static complexity} $H(x)$ of a string $x$ is defined to be the
length
of the shortest program $p$ which runs on a computer $C$ and generates
the output $x$, i.e., $H(x)=\inf_{C(p)=x} {\rm length}(p).$
If no program makes a computer output $x$, then $H(x)=\infty $.

A sequence $x$ is {\sl absolutely Chaitin random} (ACR)
\cite{chaitin1,chaitin2,chaitin3}
if the  static complexity
of the initial segment $x(n)=x_1\ldots x_n$ of length $n$
does not drop arbitrarily far below n, i.e.,
$\lim_{n\rightarrow \infty}   H[x(n)]-n>-\infty $.

It has been proved \cite{chaitin3} that an ACR sequence {\sl passes
all statistical tests} of randomness, such as frequency tests and that
like. Therefore, ACR is equivalent to previous notions of
randomness proposed by Martin--L\"of, Solovay and others, based upon
statistical criteria \cite{chaitin3,svozil1}.

For physical applications, {\sl normalized} ACR, henceforth called
CR randomness, is very important \cite{alekseev}.
An infinite sequence $x$ is  CR random, if
$K(x)=\lim_{n\rightarrow \infty } H(x(n))/n>0$.
This notion of randomness is {\sl equivalent to uncomputability}.

The {\sl normalized dynamical (computational) complexity}
$K_D(x(n))$
of a sequence $x(n)=x_1\ldots x_n$ is the number of computing steps
it
takes for the fastest program $p$ running on machine $\cal M$ to
calculate an arbitrary $i$'th position $x_i$ of $x(n)$, devided by $n$,
i.e.,\\
$K_D(x(n))=\sup_{i=1,\cdots ,n}\inf_{{\cal M}(p)=x_i} [{{\rm computing
\; steps}({\cal M} (p))]/ n}$.


An infinite sequence $x$ is {\em T--random}
(TR)
iff for the fastest program running on $\cal M$ the number of computing
steps $\tau
$ for calculating an arbitrary $n$--th position $x_n$ of $x$ is of the
order of or greater then $n$; that is $\tau (n)\ge {\cal O} (n)$, or
$K_D(x)=\lim_{n\rightarrow \infty}K_D(x(n))=\lim \sup_{n\rightarrow
\infty } {\tau (n)/ n}>0$.

Both $K$ and $K_D$ are intractable, i.e., there
exists no ``systematic'' way to derive them. This is
ultimately a consequence of G\"odel's celebrated incompleteness theorem
\cite{godel1,rogers1,calude1}.
Moreover, TR is a machine dependent concept
(for more details, see ref. \cite{svozil1}).
Table 1 schematically shows the various forms of complexity and the



associated types of randomness.
\begin{table}
\begin{tabular}{|l|l|l|l|} \hline
complexity & static & algorithmic/ & Chaitin/Martin--L\"of/Solovay \\
           &        & program size & randomness \\  \cline{3-4}
           &        & loop depth   &---\\ \cline{2-4}
           & dynamic & computational/ & T--randomness \\
           &         & time           &               \\ \cline{3-4}
           &         & storage size   &---         \\  \hline
\end{tabular}
\caption{Forms of complexity and their associated types of randomness}
\end{table}


Several attempts have been made in the literature to propose
complexity
measures which grasp the intuitive notion of ``organization''.
These measures shall not be critically discussed here, but their
enumeration seem in order.
The notion of ``logical depth'' was introduced by Bennett, ref.
\cite{bennett1}. It comes close to time complexity.
A notion of ``self--generating'' complexity was proposed by Grassberger
in ref. \cite{grassberger3}.
A criterion called ``thermodynamic depth'' has been introduced
by Lloyd and Pagels, ref. \cite{pagels} and is critically reviewed in
\cite{svozil1}.

3.
In what follows, a classification of chaotic motion with respect to the
computability of the initial values and the evolution functions,
together with the type of randomness, will be given.


{\it (i)}
{\sl Chaos I is generated by a computable evolution of a system with
uncomputable (CR) initial values.}
If the initial value is element of the continuum, the probability that
it is random is one, for ``almost all'' initial values are random
reals. The randomness of the
initial value ``unfolds'' in the deterministic time evolution \cite{1}.
This is precisely the signature for chaos in classical, deterministic
continuum mechanics---the
evolution of suitable (positive Lyapunov
exponents)
deterministic ($=$ computable) functions with initial values from a
continuous spectrum, which serves as a kind of ``pool of random reals''.
Therefore, the randomness of a classical deterministic chaos resides in
its initial configuration.

{\it (ii)}
{\sl Chaos II is generated by the uncomputable evolution of a system
with computable initial values}.
It operates with computable initial values and uncomputable
evolution laws.

{\it (iii)}
{\sl Chaos III is generated by the uncomputable evolution of a system
with uncomputable initial values.}

Whereas chaos of class I, II and III supports CR,
it assumes unconceivably complex physical systems.
The following chaos class can, for finite times, only support
TR. It has
the advantage of requireing merely computability, in some cases
only finite resources.

{\it (iv)}
{\sl Chaos IV is generated by the computable evolution of a system with
computable initial values.}
The (incompressible) dynamic complexity of TR sequences is
generated by the unfolding of a computable, but TR initial value
(the associated evolution law must have positive Lyapunov exponent(s)),
or by a dynamically incompressible algorithm and arbitrary initial
values.
One relevant result of the theory of computability is that
{\sl computable algorithms may
have uncomputable limits} \cite{rogers1}.
Therefore, with ``suitable'' evolution functions and in the limit of
infinite time, chaos IV is capable of becoming CR random.
In Table 2 the various aspects of the four classes of chaos are
represented schematically.

\begin{table}
\begin{tabular}{|l||l|l|}
\hline
\multicolumn{1}{|l||}{    } & \multicolumn{1}{l|}{deterministic} &
\multicolumn{1}{l|}{indeterministic} \\ \hline \hline
computable & {\bf chaos IV} & {\bf chaos II} \\
initial & {\it T--random} & {\it Chaitin random}\\
values & {\it (Chaitin random)} & nonrecursive\\
 &    recursive resources & resources \\
 & {\sl Cellular} & {\sl single quantum} \\
 & {\sl Automata} & {\sl events ?} \\
\hline
uncomputable & {\bf chaos I} & {\bf chaos III}\\
initial & {\it Chaitin random} & {\it Chaitin random}\\
values & nonrecursive & nonrecursive \\
 & resources & resources \\
 & {\sl deterministic} & {\sl single quantum}\\
 & {\sl continuum theory} & {\sl events ?} \\ \hline
\end{tabular}
\caption{Schematic representation of the features of chaos classes}
\end{table}


4.
One central result of symbolic dynamics \cite{alekseev} can be
formulated as follows.
For chaos I and with probability one (i.e., for random initial values),
the normalized static complexity $K(x)$ of single trajectories
(representable as symbolic string $x=x_0x_1x_2\cdots $) is equal to the
overall metric entropy measure $h_\mu (f)$ of a dynamic system with
evolution function \cite{2}
$f$, and to the sum of all positive
Lyapunov exponents, $K(x)=h_\mu (f)=\sum_{\lambda^+>0}\lambda^+$.
This connection between entropy measure and the algorithmic complexity
measure of single trajectories provide a powerful link
of algorithmic
information theory and the theory of computability on the one hand and
statistical physics and thermodynamics on the other hand.

In what follows, I shall concentrate on speculations concerning these
connections for the constructive chaos IV.
The capability of computable functions to ``produce'' uncomputable
output on computable initial values may have some far--reaching
consequences in the physical perception of reversibility.
Heuristically speaking, algorithmic complexity may be ``created''
by an investment of dynamic complexity, for instance by an (infinite)
amount of time.
One may therefore define the ratio $R=\delta K/\delta K_D$ and call a
system
for which on the average $R>0$, ``creative'', expressing the fact that
algorithmic complexity is created.
In this sense, the above equivalence between $K$ of single trajectories
and the overall entropy measure $h_\mu $ may also hold for a suitable,
i.e., ``creative'', chaos IV.
It may not be unjustified to speculate that creativity induces a unique
time direction,
and that the creation of algorithmic
complexity is a formal aspect of irreversibility.

Since both $K$ and $K_D$ are uncomputable, $R$ is uncomputable.
One may, nevertheless, employ heuristic measures such as standard type
of compression algorithms for a bound from above on $K$ and $K_D$, and
hence approximate $R$---such a method is not unfamiliar
in physics, when one is forced to
apply operational entropy measures which need not coincide with the
exact ones.
This is demonstrated by the following example.
Fig. 1 shows Pascal's triangle, mod 2, representing even and odd
binomial coefficients, which may be locally generated by
an asymmetric Cellular Automaton with the following nontrivial rules
(all others zero)
$1/0/0\rightarrow 1,\quad 0/1/0\rightarrow 1,\quad
  1/0/1\rightarrow 1,\quad 0/1/1\rightarrow 1$.
Fig. 2 shows a heuristic study of $K$ and $R$ on this structure.
On the average, there is an increase of $K$, corresponding to a positive
$R$.
Hence, the heuristic compression algorithm
for the determination of $K$ and $R$ induces
a time arrow.
From this point of view, one may expect that further
investigations will, for deterministic reversible systems with
computable
initial values, yield new insight into the second law of
thermodynamics.

5.
Besides a classification of chaos, a constructive, i.e., computable
approach to random physical motion has been attempted.
All chaos classes may yield identical forms of
random physical motion.  Chaos IV has
the advantage that it is conceivable and that it is capable of rendering
a limit which can be directly linked to entropy measures.

\vskip 0.3 true cm
{\it This work was supported in part by the
Erwin--Schr\"odinger--Gesellschaft.}


\vskip 1 true cm
\section*{Figure captions}
.

{\sc Fig.1} {Pascal's triangle (mod 2) is equivalent to the evolution
of
a one dimensional state--2 Cellular Automaton. Dots and blanks indicate
the digits 0 and 1, respectively.}

{\sc Fig.2} {Heuristic toy model study of  $R=\delta K/\delta K_D$
on Pascal's triangle (mod 2), drawn in Fig. 1.
A standard (Huffman) compression algorithm for the calculation of the
algorithmic
complexity was used. This can however yield only a bound from above on
$H$.}
\begin{thebibliography}{999}

\bibitem{rogers1}
H. Rogers, {\sl Theory of Recursive Functions and Effective
Computability} (MacGraw--Hill, New York 1967)

\bibitem{alekseev}
V. M. Alekseev and M. V. Yakobson, {\sl Physics Reports}
{\bf 75}, 287 (1981)

\bibitem{svozil1}
K. Svozil, {Logical Physics I: Foundations of Chaos},
Technical University Vienna preprint, Feruary 1989

\bibitem{ford1}
J. Ford, {\sl Chaos: solving the unsolvable, predicting the
unpredictable}, in {\sl Chaotic Dynamics and Fractals}, ed. by M. F.
Barnsley and S. G. Demko (Akademic Press, New York 1986)

\bibitem{krylov1}
N. S. Krylov, {\sl Works in the Foundations of Statistical
Mechanics}
(Princeton University Press, Princeton 1979)

\bibitem{chirikov3}
B. V. Chirikov, F. M. Izrailev and D. L. Shepelyansky,
{\sl Soviet Scientific Review} {\bf 2C}, 209 (1981);

\bibitem{casati1}
G. Casati, B. V. Chirikov and D. L. Shepelyanski,
{\sl Phys. Rev. Lett.} {\bf 53}, 2525 (1984)

\bibitem{casati2}
G. Casati, B. V. Chirikov, I. Guarneri and D. L. Shepelyanski,
{\sl Phys. Rev. Lett.} {\bf 57}, 823 (1986)

\bibitem{casati3}
G. Casati, B. V. Chirikov, I. Guarneri and D. L. Shepelyanski,
{\sl Milano university preprint, 1986;
Novosibirsk preprint 87--30}

\bibitem{wolfram1}
St. Wolfram, {\sl Physical Review Letters} {\bf 54}, 735 (1985)

\bibitem{chaitin1}G. J. Chaitin, {\sl J. Assoc. Comput. Mach.}  {\bf 22},
329 (1975);
{\sl Advances in Applied
Mathematics}  {\bf 8}, 119 (1987) and references cited

\bibitem{chaitin2}
G. J. Chaitin, {\sl Information, Randomness and Incompleteness}
(World Scientific, Singapore 1987)

\bibitem{chaitin3}
G. J. Chaitin, {\sl Algorithmic Information Theory}
(Cambridge University press, Cambridge 1987)

\bibitem{godel1}
K. G\"odel, {\sl Monatshefte f\"ur Mathematik und Physik}
{\bf 38}, 173 (1931).

\bibitem{calude1}
C. Calude, {\sl Theories of Computational Complexity} (North--Holland,
Amsterdam 1988)

\bibitem{bennett1}
Ch. H. Bennett, in {\it Emerging Synthesis in Science}, ed. by D. Pines
(Academic Press, New York 1985).

\bibitem{grassberger3}
P. Grassberger, {\sl International Journal of Theoretical Physics} {\bf
25}, 907 (1986)

\bibitem{1}
This can be seen by considering a specific form of the logistic equation
$x_{n+1}=\alpha x_n (1-x_n)$;
for $\alpha =4$ and after the variable transformation $x_n=\sin^2(\pi
X_n)$ one obtains a map $f:X_n\rightarrow X_{n+1}=2X_n$ (mod 1),
where (mod 1) means that one has to drop the integer part of $2X_n$.
By assuming a starting value $X_0$, the formal solutions to $n$
iterations is $f^{(n)}(X_0)=X_n=2^nX_0$ (mod 1).
Notice that $f$ is computable and linear.
If $X_0$ is in binary representation, this is just n times a left shift
of the digits of $X_0$, followed by a left truncation before the decimal
point.
Now assume $X_0\in (0,1)$ is CR.
Then the computable function $f^{(n)}(X_0)$ yields a random map onto
itself.
The point is that although the evolution function $f$ itself is
recursive and linear, $X_0$ is random, and $f$ ``unfolds'' the
``information'' contained in $X_0$.

\bibitem{2}
$f$ has to be a $C^2$--diffeomorphism preserving an ergodic Borel
measure $\mu $.

\bibitem{pagels}
S. Lloyd and H. Pagels, {\sl Annals of Physics (N.Y.)} {\bf 188}, 186
(1988)
\end{thebibliography}
\end{document}
