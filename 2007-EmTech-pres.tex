%\documentclass[pra,showpacs,showkeys,amsfonts,amsmath,twocolumn]{revtex4}
\documentclass[amsmath,blue,handout,table]{beamer}
%\documentclass[pra,showpacs,showkeys,amsfonts]{revtex4}
\usepackage[T1]{fontenc}
\usepackage{beamerthemeshadow}
%\usepackage[dark]{beamerthemesidebar}
%\usepackage[headheight=24pt,footheight=12pt]{beamerthemesplit}
%\usepackage{beamerthemesplit}
%\usepackage[bar]{beamerthemetree}
\usepackage{graphicx}
\usepackage{pgf}
%\usepackage[usenames]{color}
%\newcommand{\Red}{\color{Red}}  %(VERY-Approx.PANTONE-RED)
%\newcommand{\Green}{\color{Green}}  %(VERY-Approx.PANTONE-GREEN)

%\RequirePackage[german]{babel}
%\selectlanguage{german}
%\RequirePackage[isolatin]{inputenc}

\pgfdeclareimage[height=0.5cm]{logo}{tu-logo}
\logo{\pgfuseimage{logo}}
\beamertemplatetriangleitem
\begin{document}

\title{\bf \textcolor{yellow}{Emerging Technologies}}
%\subtitle{Naturwissenschaftlich-Humanisticher Tag am BG 19\\Weltbild und Wissenschaft\\http://tph.tuwien.ac.at/\~{}svozil/publ/2005-BG18-pres.pdf}
\subtitle{\textcolor{yellow!60}{http://tph.tuwien.ac.at/$\sim$svozil/publ/2007-EmTech-pres.pdf}}
\author{Karl Svozil}
\institute{Institut f\"ur Theoretische Physik, University of Technology Vienna, \\
Wiedner Hauptstra\ss e 8-10/136, A-1040 Vienna, Austria\\
svozil@tuwien.ac.at
%{\tiny Disclaimer: Die hier vertretenen Meinungen des Autors verstehen sich als Diskussionsbeiträge und decken sich nicht notwendigerweise mit den Positionen der Technischen Universität Wien oder deren Vertreter.}
}
\date{SS 2007}
\maketitle

\frame{\tableofcontents}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Foundations of Computer Science}


%\subsection{What is an algorithm?}

\frame{
\frametitle{What is an algorithm?}

Informally, the concept of an algorithm is often illustrated by the example of a recipe for accomplishing
some task; e.g., cooking.


}


\frame[shrink=2]{
\frametitle{Church-Turing Thesis}

The informal notion of ``algorithm'' can be formalized by the formalized notion of
``recursive function.''

What is a ``recursive function?''

Problem:
 As Deutsch puts it,

{\em
 ``The reason why we find it possible to construct, say, electronic
 calculators, and indeed why we can perform mental arithmetic, cannot
 be found in mathematics or logic. {\em
 The reason is that the laws of physics `happen to' permit the
 existence of physical models for the operations of arithmetic}
 such as addition, subtraction and multiplication.
 If they did not, these familiar operations would be
 noncomputable functions. We might still
 know {\em of} them and invoke them in mathematical proofs
 (which would presumably be called `nonconstructive') but we could
 not perform them.''
 }

D.~Deutsch, {\it Quantum theory, the {C}hurch-{T}uring principle and the
  universal quantum computer}, Proceedings of the Royal Society London
  \textbf{A 400}, 97--119 (1985).

}


\frame{
\frametitle{algorithm cntd.}
Davis:

 {\em `` $\ldots$ how can we ever exclude the possibility of our
 presented,
 some day (perhaps by some extraterrestrial visitors), with a (perhaps
 extremely complex) device or ``oracle'' that ``computes'' a
 noncomputable function?''
 }

M.~Davis, {\it Computability and Unsolvability} (McGraw-Hill, New York, 1958).
}


\frame{
\frametitle{Turing computability}

Alan Turing enshrined that part of mathematics, which can be ``constructed''
by paper and pencil operations, into a Turing machine which possesses a potentially
unbounded one-dimensional tape divided into cells,
some finite memory and some
read-write head which transfers back and forth information from the tape to this memory.
A table of transition rules figuring as the ``program'' steers the machine deterministically.
The behaviour of a Turing machine may also be determined by its initial state.
%            http://plato.stanford.edu/entries/turing-machine/  http://www.abelard.org/turpap2/tp2-ie.asp

Furthermore, a universal Turing machine is capable
of simulating all other Turing machines (including itself).

A.~M. Turing, {\it On computable numbers, with an application to the
  {E}ntscheidungsproblem,} Proceedings of the London Mathematical Society,
  Series 2 \textbf{42 and 43}, 230--265 and 544--546 (1936-7 and 1937).

}



\frame{
\frametitle{Universality and robustness}

Universality: a universal computer can simulate all other ones (including itself ;-)

Robustness: any ``robust'' formalizations are essentially equivalent; i.e.,
any formalism can be somehow ``translated'' one-to-one into any other one of that ``robust'' class ;-)
}

%\subsection{Uncomputability}

\frame[shrink=2]{
\frametitle{Turing uncomputability and the halting problem}

 Consider a universal computer $U$ and  an arbitrary algorithm
$B(X)$ whose input is a string of symbols $X$.  Assume that there exists
a ``halting algorithm'' ${\tt HALT}$ which is able to decide whether $B$
terminates on $X$ or not.
The domain of ${\tt HALT}$  is the set of legal programs.
The range of ${\tt HALT}$ are classical bits.

Using ${\tt HALT}(B(X))$ we shall construct another deterministic
computing agent $A$, which has as input any effective program $B$ and
which proceeds as follows:  Upon reading the program $B$ as input, $A$
makes a copy of it.  This can be readily achieved, since the program $B$
is presented to $A$ in some encoded form
$\ulcorner B\urcorner $,
i.e., as a string of
symbols.  In the next step, the agent uses the code
$\ulcorner B\urcorner $
 as input
string for $B$ itself; i.e., $A$ forms  $B(\ulcorner B\urcorner )$,
henceforth denoted by
$B(B)$.  The agent now hands $B(B)$ over to its subroutine ${\tt HALT}$.
Then, $A$ proceeds as follows:  if ${\tt HALT}(B(B))$ decides that
$B(B)$ halts, then the agent $A$ does not halt; this can for instance be
realized by an infinite {\tt DO}-loop; if ${\tt HALT}(B(B))$ decides
that $B(B)$ does {\em not} halt, then $A$ halts.

The agent $A$ will now be confronted with the following paradoxical
task:  take the own code as input and proceed to determine whether or not it halts.
Then, whenever $A(A)$
halts, ${\tt HALT}(A(A))$, by the definition of $A$, would force $A(A)$ not to halt.
Conversely,
whenever $A(A)$ does not halt, then ${\tt HALT}(A(A))$ would steer
$A(A)$ into the halting mode.  In both cases one arrives at a complete
contradiction.  Classically, this contradiction can only be consistently
avoided by assuming the nonexistence of $A$ and, since the only
nontrivial feature of $A$ is the use of the peculiar halting algorithm
${\tt HALT}$, the impossibility of any such halting algorithm.
}


\frame[shrink=2]{
\frametitle{Undecidability of the rule inference (induction) problem}

Induction in physics is the inference of general rules
dominating and generating physical behaviors from these behaviors.
For any deterministic system strong enough to support
universal computation, the general induction problem
is provable unsolvable.
Induction is thereby reduced to the unsolvability of
the rule inference problem,

Informally, the algorithmic idea of the proof is to take any sufficiently powerful
rule or method of induction and, in using it, define some
functional behavior which is not identified by it.
This amounts
to constructing an algorithm which
(passively!)
 ``fakes'' the ``guesser'' by simulating some particular function $\varphi $
until the guesser
pretends to guess this function correctly.
In a second,  diagonalization step, the ``faking'' algorithm then switches to a different
 function $\varphi^\ast  \neq \varphi $, such that the guesser's guesses become incorrect.



}



\frame[shrink=2]{
\frametitle{Busy Beaver Number}

The busy beaver function
addresses the following
question: given a finite system;
i.e., a system whose algorithmic description is of finite length.
What is the biggest number producible by such a system before halting?

Let $\Sigma (n)$ denote the busy beaver function of $n$.
 Originally, T. Rado
 asked how
 many $1$'s a Turing machine with $n$ possible states and an empty
 input tape
 could print on that tape before halting.

 The first values of the Turing busy beaver function $\Sigma _T(x)$
 are finite and are known:                       \\
 $\Sigma _T(1)=1$,                               \\
 $\Sigma _T(2)= 4$,                              \\
  $\Sigma _T(3)=6$,                              \\
 $\Sigma _T(4)= 13$,                             \\
 $\Sigma _T(5) \ge 1915$,                        \\
 $\Sigma_T(7)\ge 22961$,                         \\
 $\Sigma_T(8)\ge 3\cdot (7\cdot 3^{92}-1)/2$.    \\


}


\frame{
\frametitle{Omega Number}

Omega $\Omega$, the halting probability, is the sum
$$\sum_{U(p) \downarrow} 2^{-\vert p \vert}$$
of all halting, prefix-free program of some universal computer $U$.


}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\frame[shrink=2]{
\frametitle{Continuum urn}

With probability 1, a real initial value ``taken from the continuum urn'' is uncomputable (indeed, algorithmically incompressible = random).

In the measure theoretic sense, ``almost all'' reals are
 uncomputable. This can be demonstrated by the following argument:
 Let $M=\{ r_i\}$ be an  infinite point set (i.e., $M$ is a
 set of
 points $r_i$) which is denumerable and which is the subset of a dense
 set. Then, for instance, every $r_i\in M$ can be enclosed in the
 interval \begin{equation}
 I(i,\delta)= [r_i-2^{-i-1}\delta
 ,
 r_i+2^{-i-1}\delta]\quad ,
 \end{equation}
 where $\delta $ may be arbitrary small (we choose $\delta$ to be
 small enough that all intervals are disjoint).
 Since $M$ is denumerable, the measure $\mu$ of these intervals can
 be summed up, yielding
  \begin{equation}
 \sum_i \mu( I(i,\delta))= \delta \sum_{i=1}^\infty 2^{-i}=\delta \quad
 . \end{equation}
 From $\delta \rightarrow 0$ follows $\mu (M)=0$.


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Karp-Cook Thesis}


\frame{
\frametitle{NP complexity class}

In computational complexity theory, NP (``Non-deterministic Polynomial time'')
is the set of problems solvable

\begin{itemize}
\item<+->
by non-deterministic ``oracles''
and
\item<+->
polynomial time verifiability
\end{itemize}
}
\frame{
\frametitle{NP completeness}

An NP-complete problem is one which is robust in the following sense:
it is in NP and
it is NP-hard, i.e. every other problem in NP is reducible to it.

Example: ``travelling salesman''

Garey, M. and D. Johnson, Computers and Intractability; A Guide to the Theory of NP-Completeness, 1979


}



\frame{
\frametitle{Karp-Cook Thesis}

$NP\neq P$

No proof so far.



}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Physical foundations of computation}


\frame[shrink=1.01]{
\frametitle{Maxwell's Demon}

\includegraphics{MaxwellsDemon.pdf}

}


\frame[shrink=1.01]{
\frametitle{Maxwell's Demon}

\includegraphics{MaxwellsDemonPicture.pdf}

}

\frame[shrink=1.01]{
\frametitle{Maxwell's Demon}

\includegraphics{MaxwellsDemonPicture2.pdf}

}

\frame[shrink=1.01]{
\frametitle{Maxwell's Demon}

\includegraphics{MaxwellsDemonPicture3.pdf}

}

\frame[shrink=1.01]{
\frametitle{Maxwell's Demon}
\includegraphics{MaxwellsDemonPicture4.pdf}
}


\frame{
\frametitle{Information theoretic ``solution'' to Maxwell's Demon}

R. Landauer,  {Irreversibility and Heat Generation in the Computing Process},
{IBM Journal of Research and Development} {\bf 3},  {183-191} (1961)

\begin{itemize}

\item<+->
 logical irreversibility of in connection with information-discarding processes ---
``cleared'' memory can be from a variety of previous states

\item<+->
Each logical step must somehow correspond to a physical state

\item<+-> (``the bad news'')
logical irreversibility is associated with physical ``heat dissipation''
and ``entropy increase''  ;-(

\item<+-> (``the good news'')
logically reversibile operations need not be associated with physical ``heat dissipation''
and ``entropy increase'' ;-)

\end{itemize}


}

\frame{
\frametitle{Reversible computation from irreversible one}

Charles H. Bennett, Logical Reversibility of Computation,
{IBM Journal of Research and Development} {\bf 17}, {525-532} (1973).
\\
Charles H. Bennett,  {The Thermodynamics of Computation---A Review},
{International Journal of Theoretical Physics} {\bf 21}, {905-940} (1982).


\begin{itemize}

\item<+->
 Every (irreversible) computer can be made logically reversible at every step

\item<+->
saving of all intermediate results, avoiding erasure

\item<+->
copy of computation ``result;''  outcome

\item<+->
reverse computation to ``get rid'' of the intermediate results,

\item<+->
one is left with the original ``input'' and one copy of the ``output''

\item<+->
splitting up the computation into many steps results in less memory requirements

\end{itemize}

}

\frame[shrink=1.01]{
\frametitle{Reversible computation from irreversible one}
\includegraphics{MaxwellsDemonBennett71.pdf}
}

\frame[shrink=1.01]{
\frametitle{Reversible computation from irreversible one}
\includegraphics{MaxwellsDemonBennett71-2.pdf}
}

\frame{
\frametitle{Information theoretic ``solution'' to Maxwell's Demon cntd.}

\begin{itemize}

\item<+->
 As Maxwell's demon acquires information while performing its task, it ``heats up.''

\item<+->
Setting Maxwell's demon into its initial configuration means
erasure of informations, which in turn means energy dissipation.

\end{itemize}

}

\frame{
\frametitle{Why all this?}


\begin{itemize}

\item<+->
 Consider this: ``information is physical;''
i.e., has a physical representation.

\item<+->
Due to the (unitary) quantum evolution, quantum computation is reversible.

\end{itemize}


}




\frame{
\frametitle{Cellular Automata}

\begin{itemize}

\item<+->
John von Neumann, {Theory of Self-Reproducing Automata},
(A. W. Burks, editor),  {University of Illinois Press}, {Urbana}, 1966


\item<+->
Konrad Zuse,
{{R}echnender {R}aum},
{Elektronische Datenverarbeitung},
{\bf 8}, {336-344}, (1967)\\
  URL: http://www.idsia.ch/$\widetilde{\;}$juergen/digitalphysics.html

\end{itemize}

}

\frame[shrink=1.01]{
\frametitle{Cellular Automata}
\includegraphics{CellularAutomaton.pdf}
}

\frame[shrink=1.01]{
\frametitle{Billiard Ball Cellular Automata}
\includegraphics{BBCellularAutomaton.pdf}
}


\frame[shrink=1.01]{
\frametitle{Computational Complementarity and generalized urn model}

Edward F. Moore,
{Gedanken-Experiments on Sequential Machines},
in {Automata Studies},
ed. by {C. E. Shannon and J. McCarthy},
{Princeton  University Press},
 {Princeton},
(1956)
\includegraphics{SubwayAutomaton.pdf}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Quantum Mechanics}
\frame{
\frametitle{Hilbert space}

All quantum
mechanical entities are represented by objects
of Hilbert spaces. A {\em Hilbert space} is a linear
vector space ${\cal H}$ over the field $\Phi$ of complex numbers
(with vector addition
and scalar multiplication), together  with a complex function
$(\cdot ,\cdot
)$, the {\em scalar} or {\em inner product}, defined on ${\cal
H}\times{\cal H}$ such that
(i)
$(x,x)=0$ if and only if $x=0$;
(ii)
$(x,x)\ge 0$ for all $x \in{\cal H}$;
(iii)
$(x+y,z)=(x,z)+(y,z)$ for all $x,y,z \in {\cal H}$;
(iv)
$(\alpha x,y)=\alpha (x,y)$ for all $x,y \in {\cal H}, \alpha \in \Phi$;
(v)
$(x,y)=\overline{(y,x)}$ for all $x,y \in {\cal H}$
($\overline{\alpha }$ stands for the complex conjugate of $\alpha$);
(vi)
If $x_n\in {\cal H}$, $n=1,2,\ldots$, and if $\lim_{n,m\rightarrow
\infty} (x_n-x_m,x_n-x_m)=0$, then there exists an $x\in {\cal H}$ with
$\lim_{n\rightarrow \infty} (x_n-x,x_n-x)=0$.


}


\frame{
\frametitle{State}


 A pure {\em physical state} is represented by
a  vector of  the Hilbert space ${\cal H} $.
Therefore, if two vectors $x,y\in {\cal H}$ represent physical
states, their vector sum
$z=x+y\in{\cal H}$ represent a physical state as well.
This state $z$ is called the {\em coherent superposition} of state $x$
and
$y$. Coherent state superpositions will become most important in quantum
information theory.

}

\frame{
\frametitle{Observables}
{\em Observables} $A$ are represented by self-adjoint
operators $A$
on the Hilbert space ${\cal H}$ such that $(Ax,y)=(x,Ay)$ for all
$x,y\in {\cal H}$. (Observables and their corresponding operators are
identified.)

In what follows, unless stated differently, only
{\em finite} dimensional Hilbert spaces are considered.
 Then, the vectors
corresponding to states can be written as usual vectors in complex
Hilbert space.
Furthermore, bounded
self-adjoint operators are  equivalent to bounded Hermitean operators.
They can be represented by matrices, and the self-adjoint
conjugation
is just transposition and complex conjugation of the matrix elements.

}

\frame{
\frametitle{ }
Elements $b_i,b_j\in {\cal H}$ of the set of orthonormal base vectors
satisfy
$(b_i, b_j) =\delta_{ij}$,
where $\delta_{ij}$ is the Kronecker delta function.
Any state $x$ can be written as a linear
combination of
the set of orthonormal base vectors $\{b_1,b_2,\cdots \}$,
i.e.,
$x =\sum_{i=1}^N   \beta_i b_i$, where $N$ is the dimension of ${\cal
H}$ and
$\beta_i=(b_i,x) \in \Phi$.
In the Dirac bra-ket notation, unity is given by
${\bf 1}=\sum_{i=1}^N \vert b_i\rangle \langle b_i\vert $.
Furthermore,
any Hermitean operator has a spectral representation
$A=\sum_{i=1}^N \alpha_i P_i$,
where the $P_i$'s  are orthogonal projection operators onto the
orthonormal eigenvectors $a_i$ of $A$ (nondegenerate
case).
}




\frame{
\frametitle{Complementarity}
Observables are said to be {\em compatible} if they can be defined
simultaneously with arbitrary accuracy; i.e., if they are
``independent.'' A criterion for compatibility is the {\em commutator.}
Two observables ${A},{B}$ are compatible, if their {\em
commutator} vanishes; i.e.,
if $\left[
{A},
{B}
\right] =
{A}
{B}  -
{B}
{A}   =0$.
For example, position and momentum operators
$
\left[
{{\frak x}},
{{\frak p_x}}
\right] =
{{\frak x}}
{{\frak p_x}}-
{{\frak p_x}}
{{\frak x}} =
x
{\hbar \over i} {\partial \over \partial x}-
{\hbar \over i} {\partial \over \partial x}
x
=i\, \hbar
\neq 0
$
and thus do not commute. Therefore, position and momentum of a state
cannot be measured simultaneously with arbitrary accuracy.
It can be shown that this property gives rise to the {\em Heisenberg
uncertainty relations}
$
\Delta x
\Delta p_x \ge {\hbar \over 2}
$,
where
$
\Delta x
$
and
$
\Delta p_x
$
is given by
$
\Delta x =\sqrt{\langle x^2\rangle -\langle x\rangle ^2}
$
and
$
\Delta p_x =\sqrt{\langle p_x^2\rangle -\langle p_x\rangle ^2}
$,  respectively.
}


\frame{
\frametitle{Outcome}
The result of any single measurement of the observable $A$
on a state $x\in {\cal H}$
can only be one of the real eigenvalues of the corresponding
Hermitean operator $A$.
If $x$ is in a coherent superposition of eigenstates of $A$, the
particular outcome of any such single measurement is indeterministic;
i.e.,
it cannot be predicted with certainty. As a
result of the measurement,
the system is in the state which corresponds to the eigenvector $a_n$ of
$A$ with the associated real-valued eigenvalue
$\alpha_n$; i.e., $Ax=\alpha_n a_n$ (no summation convention here).


}


\frame{
\frametitle{Evolution}

This ``transition'' $x\rightarrow a_n$ has given rise to speculations
concerning the
``collapse
of the wave function (state).''  But, as has been argued recently,
 it is
possible to reconstruct coherence; i.e., to ``reverse the collapse of
the wave function (state)'' if the process of measurement is
reversible. After this reconstruction, no information about the
measurement must be left, not even in principle.
}

\frame[shrink=2]{
\frametitle{ }
How did Schr\"odinger, the creator of wave mechanics, perceive the
$\psi$-function? In his
1935 paper
``Die Gegenw\"artige
Situation in der Quantenmechanik'' (``The present situation in quantum
mechanics''), Schr\"odinger states,
\begin{quote}
{\em Die $\psi$-Funktion als Katalog der Erwartung:}
$\ldots$
Sie [[die $\psi$-Funktion]] ist jetzt das Instrument zur Voraussage der
Wahrscheinlichkeit von Ma\ss zahlen. In ihr ist die jeweils erreichte
Summe theoretisch begr\"undeter Zukunftserwartung verk\"orpert,
gleichsam wie in einem {\em Katalog} niedergelegt.
$\ldots$
Bei jeder Messung ist man gen\"otigt, der $\psi$-Funktion ($=$dem
Voraussagenkatalog) eine eigenartige, etwas pl\"otzliche Ver\"anderung
zuzuschreiben, die von der {\em gefundenen Ma\ss zahl} abh\"angt und
sich {\em nicht vorhersehen l\"a\ss t;} woraus allein schon deutlich
ist, da\ss~ diese zweite Art von Ver\"anderung der $\psi$-Funktion mit
ihrem regelm\"a\ss igen Abrollen {\em zwischen} zwei Messungen nicht das
mindeste zu tun hat. Die abrupte Ver\"anderung durch die Messung
$\ldots$ ist der interessanteste Punkt der ganzen Theorie. Es ist genau
{\em der} Punkt, der den Bruch mit dem naiven Realismus verlangt. Aus
{\em diesem} Grund kann man die $\psi$-Funktion {\em nicht} direkt an
die Stelle des Modells oder des Realdings setzen. Und zwar nicht etwa
weil man einem Realding oder einem Modell nicht abrupte unvorhergesehene
\"Anderungen zumuten d\"urfte, sondern weil vom realistischen Standpunkt
die Beobachtung ein Naturvorgang ist wie jeder andere und nicht per se
eine Unterbrechung des regelm\"a\ss igen Naturlaufs hervorrufen darf.
\end{quote}
It therefore seems not unreasonable to state that, epistemologically,
quantum mechanics is more a theory of knowledge of an
(intrinsic) observer rather than the platonistic physics ``God knows.''
The  wave function, i.e., the state of the physical system in a
particular
representation (base), is a representation of the observer's knowledge;
it is a representation or name or code or index of
the information or knowledge the observer has access to.
}

\frame{
\frametitle{Probability}
The probability $P_y(x)$ to find a system represented by state $x$
in some state $y$ of an orthonormalized basis is given by
$P_y(x)=\vert (x,y) \vert^2 $.
}

\frame{
\frametitle{Expectation value}
The {\em average value} or {\em expectation value} of an observable
$A$ in the state
$ x$
is given by
$\langle A\rangle_ x =
\sum_{i=1}^N \alpha_i
\vert (x,a_i) \vert^2$.
}

\frame{
\frametitle{ }
The dynamical law or equation of motion can be written in the form
$x (t) =Ux (t_0) $,
where $U^\dagger =U^{-1}$ (``$\dagger $ stands for transposition and
complex conjugation) is a
linear {\em unitary evolution operator}.

The {\em Schr\"odinger equation}
$
i\hbar {\partial \over \partial t}  \psi (t)    =
H \psi (t) $
 is obtained by identifying $U$ with
$U=e^{-iHt/\hbar }$,
where $H$ is a self-adjoint  Hamiltonian (``energy'') operator,
by differentiating the equation of motion
with respect to the time variable $t$;
i.e.,
$
 {\partial \over \partial t} \psi (t) =-\,{iH\over
\hbar
}e^{-i{H}t/\hbar}
\psi (t_0 ) = -\,{i{H}\over \hbar } \psi (t)
$.
}

\frame{
\frametitle{ }
In terms of the
set of orthonormal base vectors $\{ b_1, b_2, \ldots
\}$, the Schr\"odinger equation can be written as
$i\hbar {\partial \over \partial t} ( b_i , \psi (t) )   =
\sum_{j}
H_{ij}( b_j, \psi (t) )$.
In the case of position base states $\psi (x,t)=( x, \psi (t)
)$, the Schr\"odinger equation takes on the form
 $
i\hbar {\partial \over \partial t}  \psi (x,t) =
{H} \psi (x,t)=\left[{{{\frak p}} {{\frak p}}\over 2m}+
{V}(x)\right]\psi (x,t) = \left[-\,{\hbar^2
\over
2m}\nabla^2+V(x)\right] \psi (x,t)$.

}
\frame{
\frametitle{ }

For stationary $ \psi_n
(t)=
e^{-(i/\hbar )E_nt}  \psi_n $, the Schr\"odinger equation
can be brought into its time-independent form
$H\, \psi_n
=
E_n\, \psi_n $.
Here,
$i\hbar {\partial \over \partial t} \psi_n (t)
=
E_n \, \psi_n (t) $  has been used;
$E_n$
and $\psi_n $
stand for the $n$'th eigenvalue and eigenstate of
$H$, respectively.
}

\frame{
\frametitle{ }

Usually, a physical problem is defined by the Hamiltonian ${H}$.
The problem of finding the physically relevant states reduces to finding
a complete set of eigenvalues and eigenstates of ${H}$.
Most elegant solutions utilize the symmetries of the problem, i.e., of
${H}$. There exist two ``canonical'' examples, the $1/r$-potential
and
the harmonic oscillator potential, which can be solved wonderfully by
these methods (and they are presented over and over again in standard
courses of quantum mechanics), but not many more.
}



\end{document}


\frame{
\frametitle{ }



}

\frame{
\frametitle{ }



}

\frame{
\frametitle{ }



}

\frame{
\frametitle{ }



}

\frame{
\frametitle{ }



}

\frame{
\frametitle{ }



}

\frame{
\frametitle{ }



}



