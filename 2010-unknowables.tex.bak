 \documentclass[%
  reprint,
 %superscriptaddress,
 %groupedaddress,
 %unsortedaddress,
 %runinaddress,
 %frontmatterverbose,
 %preprint,
 %showpacs,preprintnumbers,
 %nofootinbib,
 %nobibnotes,
 %bibnotes,
  amsmath,amssymb,
  aps,
 % prl,
 %pra,
 %prb,
  rmp,
 %prstab,
 %prstper,
  longbibliography,
 %floatfix,
  lengthcheck,%
 ]{revtex4-1}
 \bibliographystyle{apsrev4-1long}

\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{eepic}
\usepackage[x11names]{xcolor}
\bibpunct{[}{]}{,}{a}{}{;}

\usepackage{pslatex}




\begin{document}
%\sloppy

\title{Physical unknowables\thanks{Contribution to
the international symposium ``Horizons of Truth''
celebrating the 100th birthday of Kurt G\"odel
at  the University of Vienna from April 27th-29th, 2006}}

\author{Karl Svozil}
\email{svozil@tuwien.ac.at}
\homepage{http://tph.tuwien.ac.at/~svozil}
\affiliation{Institute for Theoretical Physics, Vienna University of Technology,  \\
Wiedner Hauptstra\ss e 8-10/136, A-1040 Vienna, Austria}


\begin{abstract}
Provable physical unknowables are derived from reduction to problems which are known to be recursively unsolvable. ``Chaotic'' symbolic dynamic systems are unstable with respect to variations of initial states. Quantum unknowables include the random occurrence of single events, complementarity and value indefiniteness.
\end{abstract}


\pacs{01.70.+w,01.65.+g,02.30.Lt,03.65.Ta}
\keywords{Unknowables, Church-Turing thesis, induction and forecast, n-body problem, quantum indeterminism}

\maketitle

\tableofcontents


\begin{quote}
\begin{flushright}
{\footnotesize
$\ldots$ as we know, there are known knowns; \\
there are things we know we know. \\
We also know there are known unknowns; \\
that is to say we know there are some things we do not know. \\
But there are also unknown unknowns --\\
the ones we don't know we don't know.  \\
{\em United States Secretary of Defense Donald H. Rumsfeld \\
at a Department of Defense news briefing on February 12, 2002}
% http://www.defenselink.mil/Transcripts/Transcript.aspx?TranscriptID=2636
\\ $\;$
\\ $\;$
ei mihi, qui nescio saltem quid nesciam!\\
$[$Alas for me, that I do not at least know the extent of my own ignorance!$]$  \\
{\em Aurelius Augustinus, 354-430, ``Confessiones (Confessions),'' (Book XI, Chapter 25)}
%http://www.stoa.org/hippo/text11.html
%http://de.wikipedia.org/wiki/Confessiones
%http://en.wikipedia.org/wiki/Confessiones
%http://www.ccel.org/a/augustine/confessions/confessions.html
%http://www.ccel.org/ccel/augustine/confessions.xiv.html
%http://www.newadvent.org/fathers/110111.htm
 }
\end{flushright}
\end{quote}

\section{Rise and fall of determinism}

From antiquity onwards, various waves of (in)determinism have dominated human thought.
Regardless of whether they were shaped by some ``Zeitgeist,''
or whether, as G\"othe's {\it Faust} puts it,
{\it ``What you the Spirit of the Ages call,
Is nothing but the spirit of you all,
Wherein the Ages are reflected,''}
their proponents have sometimes vigorously defended them in irrational,  unscientific, and ideologic ways.
Indeed, from an emotional point of view, may it not appear frightening
to be imprisoned by remorseless, relentless predetermination,
even in a dualistic setup~\cite{descartes-meditation}; and, equally frightening,
to accept that one's fate depends on total arbitrariness and chance?
Does determinism expose freedom, self-determination and human dignity as an idealistic illusion?
And, on the other extreme, what kind of morale, merits and efforts appear worthy in a universe governed by pure chance?
Is there some ``reasonable in-between'' those extreme positions which may also be consistent with science?

We shall, for the sake of separating the scientific debate
from emotional overtones and possible bias, adopt a contemplative strategy of {\em evenly-suspended attention}
outlined by Freud~\cite{Freud-1912}, who admonishes analysts to be aware of the dangers
caused by {\it ``$\ldots$~temptations to project,
what [[the analyst]] in dull self-perception recognizes as the peculiarities of his own personality,
as generally valid theory into science~$\ldots$~.''}
Nature is thereby treated as a ``client-patient,'' and whatever comes up is accepted ``as is,'' without any
immediate emphasis or judgment.


\subsection{Toward explanation and feasibility}

Throughout history,
the human desire to foresee and manipulate the physical world for survival and prosperity,
and in accord with personal wishes and  fantasies
has been confronted with the inability to predict and manipulate
large portions of the habitat.
As time passed, people have figured out various ways to tune
ever increasing fragments of the world according to their needs.
From a purely behavioral perspective, this is brought about in the way of
pragmatic quasi-causal conditional rules of the following kind,
``if one does this, one obtains that.''
A typical example of such a rule is, ``if I rub my hands, they get warmer.''


How does one arrive at those kinds of rules?
Guided by suspicions, thoughts, formalisms and by pure chance,
enquiries start by ``roaming around,'' inspecting portions of the world
and examining their behavior.
Repeating patterns of behavior are observed and ``pinned down'' by reproducing them.
A physical behavior is anything that can be observed and thus operationally obtained and measured;
e.g., the rise and fall of the sun, the ignition of fire, the formation and the melting of ice.

%Note that, due to the finiteness of the resolution, all kinds of physical behaviors,
%even the ones that appear continuous, can be discretized.
%Ultimately, all physical experiences can be broken down into yes-no propositions
%representable by zeroes and ones, by sequences of single clicks in detectors.

As physical behaviors are observed,
people attempt to ``understand'' them by trying to figure out some
the ``cause''~\cite{frank} or ``reason'' for their occurrences.
Researchers invent virtual parallel worlds of thoughts
and intellectual concepts such as ``electric field'' or ``mechanical force''
to ``explain''  and manipulate the physical behaviors,
calling these creations of their minds ``physical theories.''
Contemporary physical theories are heavily formalized and spelled out in the language of mathematics.
A ``good theory'' provides people with the feeling of a ``key'' unlocking new ways of world comprehension and manipulation.
Ideally, an ``explanation'' should be as compact as possible
and should apply to as many behavioral patterns as possible.

Ultimately, theories of everything~\cite{barrow-TOE,Kragh-qg} should be able to predict and manipulate all phenomena.
In the extreme form, science becomes omniscience and omni-potent, and we envision ourselves almost as becoming empowered with ``magic:''
we presume that our ability to manipulate and tune the world is limited by our fantasies alone,
and any constraints whatsoever can be bypassed or overcome one way or another.
Indeed, some of what in the past has been called supernatural, mystery and the beyond has been realized in everyday life.
Many wonders of witchcraft have been transferred into the realm of the physical sciences.
Take, for example, our abilities to fly,
the capability to transmute mercury into gold~\cite{PhysRev.60.473},
to listen and speak to far away friends,
or to cure bacterial diseases with a few pills of antibiotics.

Until about 1900, the fastly growing natural sciences, guided  by
rational~\cite{Descartes-Discourse} and empirical~\cite{lock-thu,hume-thu} thinking,
and seconded by the European Enlightenment, prospered under the assumption of physical determinism.
Under the {\em aegis} of physical determinism, all incapacities to predict and manipulate physical behavior were
interpreted to be merely {\em epistemic} in nature, purporting that, with growing precision of measurements and
improvements of theory, all physical unknowables will eventually be overcome and turned into knowables.
That is,  ``everything'' should in principle be knowable.
Even ``statistical'' quantities would describe underlying deterministic behaviors.
Consequently, there could not exist any physical behavior or entity
without a cause ``stimulating'' or ``pushing'' it into existence.


The uprise of determinism culminated in the following statement by Laplace~\cite[Chapter II]{laplace-prob}:
\begin{quote}
{\em
Present events are connected with preceding ones
by a tie based upon the evident principle that a thing
cannot occur without a cause which produces it. This
axiom, known by the name of the principle of sufficient
reason, extends even to actions which are considered
indifferent $\ldots$


We ought then to regard the present state of the
universe as the effect of its anterior state and as the
cause of the one which is to follow. Given for one
instant an intelligence which could comprehend all the
forces by which nature is animated and the respective
situation of the beings who compose it an intelligence
sufficiently vast to submit these data to analysis it
would embrace in the same formula the movements of
the greatest bodies of the universe and those of the
lightest atom; for it, nothing would be uncertain and
the future, as the past, would be present to its eyes.
}
\end{quote}
The invention of (analytic) functions refects this paradigm quite nicely:
some ``coordinate''~\cite{hertz-94} $x(t)$ of a physical state is represented
as a (unique) function of physical time $t$.

Indeed, the possibility to formulate theories {\it per se};
and in particular the applicability of formal, mathematical models, comes as a ``mindboggling'' surprise and
cannot be taken for granted;
there appears to be what Wigner called an
``unreasonable effectiveness of mathematics in the natural sciences''~\cite{wigner}.
Even today there is a ``Pythagorean consensus'' that there is no limit to
dealing with physical entities in terms of mathematical formalism.
So, as mathematics increasingly served as a proper representation of reality,
algorithmics started to become a metaphor for physics.

The natural sciences succeeded to prosper uninhibited by any sense of limits until
about {\it fin de si\'ecle} around 1900.
In parallel, the formalization of mathematics progressed in an equally uninhibited way.
Hilbert demanded that nobody should ever expel mathematicians from the paradise created by Cantor's set theory,
and posed a challenge~\cite{hilbert-1900e}
to search for a consistent, finite system of formal axioms which would be able to render all
mathematical and physical truth; just as  quasi-finitistic ways to cope with infinitesimal calculus had been found.

This type of belief system claiming omniscience could be called ``deterministic conjecture;''
since no proof for its validity can be given;
nor is there any test for its falsification~\cite{popper-en} presented.
Actually, ``omniscience'' can be disproved on a daily basis by everbody tuning in to the local weather forecasts.

Furthermore, it seems to be an enduring desire of human nature to be able to trust
the rules and theories not merely syntactically and operationally~\cite{bridgman},
but to be able to semantically interprete them as implying and carrying some
ontological significance or ``truth;'' as if
``reality would communicate with us, mediated through our senses, thereby revealing the laws governing nature.''
Stated pointedly, we not only wish to accept physical theories as pure abstractions and constructions of our own mind~\cite{berkeley},
but we associate meaning and truth to them;
so much so that only very reluctantly we admit their preliminary, transient and changing character~\cite{lakatosch}.

\subsection{Rise of indeterminism}

Almost unnoticed  the tide of indeterminism started to build up toward the end of the nineteenth century~\cite{purrington,Kragh-qg}.
Mechanistic theories at that time faced an increasing number of ``anomalies'' surfacing in the last quarter century before 1900:
Poincar\'e's discovery of ``unstabilities'' of trajectories of celestial bodies, which made them extremely sensible to initial conditions,
radioactivity~\cite{Kragh-1997AHESradioact,Kragh-2009_RePoss5}, X rays, specific heats of gases and solids, emission and absorption of light, in particular blackbody radiation,
the (ir)reversibility dichotomy
between classical reversible mechanics and Boltzmann's statistical-mechanical theory of entropy {\it versus} the second law of thermodynamics,
as well as classical ``constructions'' of the ether and their experimental refutation.

After the year 1900 followed a short period of revolutionary new physics, in particular quantum theory and relativity theory,
without any strong inclination towards (in)determinism.
Then, indeterminism erupted with Born's claim that quantum mechanics has it both ways: the quantum state evolves deterministically,
whereas the individual outcome occurs indeterministically.
Born also stated that he {\em believed} that there is no cause for an individual quantum event;
i.e., such an outcome occurs irreducibly at random.

There followed a fierce controversy, with many researchers such as Born, Bohr, Heisenberg and Pauli taking the indetermistic stance,
while others, like Planck~\cite{born-55}, Einstein~\cite{epr,ein-reply}, Schr\"odinger and De Brogli, leaning toward determinism.
This latter position was pointedly put forward by Einstein's {\it dictum} in a letter to Born, dated December~12th, 1926~\cite[p.~113]{born-69},
{\em ``In any case I am convinced that he [[the Old One]] does not throw dice.''}
At present the situation is clearly in favor for the inteterminists, the canonical position being expressed by Zeilinger~\cite{zeil-05_nature_ofQuantum},
{\em ``the discovery that individual events are
irreducibly random is probably one of the
most significant findings of the twentieth
century. [[$\ldots$]]~for the individual event in quantum physics, not only do we not know the cause, there is no cause.''}

The last quarter of the twentieth century saw the rise of yet another form of physical indeterminism,
originating in Poincar\'e's aforementioned discovery of instabilities of the motion of classical bodies~\cite{poincare14,Diacu96-ce}
against variations of initial conditions.
This scenario of {\em deterministic chaos} resulted in a plethora of claims regarding indeterminism
which resonated well in a general public susceptible to fables and fairy tales~\cite{bricmont}.

In parallel, G\"odel's incompleteness theorems~\cite{godel1,tarski:32,davis-58,davis,smullyan-92},
as well as related findings in the computer sciences~\cite{turing-36,chaitin3,calude:02,gruenwald-vitanyi}
put an end to Hilbert's program of finding a finite axiom system for all of mathematics, as well as established formal
bounds on provability, predictability and induction.

Physical indeterminism can neither be proven, nor can there be given any reasonable criterion for its falsification.
After all, how can one check against all laws and find none applicable?
Unless one is willing to denote any system whose laws are currently unknown or whose behavior is hard to predict with present techniques as ``indeterministic,''
there is no scientific substance to such absolute claims; in
particular if one takes into account the bounds imposed by the theory of recursive functions discussed below.
So, just as in the deterministic case, one is again inclined to accept this position as conjectural.


In discussing the present status of physical (in)determinism,
we shall first consider provable unknowables through reduction to incompleteness theorems of recursion theory,
then discuss classical deterministic chaos, and finally deal with the three types of quantum indeterminism:
the occurrence of certain single events, complementarity and value indefiniteness.
The latter irreducible quantum unknowables are not commonly accepted by the entire community of physicists;
a minority is still hoping for a more complete quantum theory than the present statistical theory.


\section{Provable physical unknowables}

In the past century,
unknowability has been formally defined and {\em derived} in terms of a precise,
formal notion of unprovability~\cite{godel1,tarski:32,tarski:56,turing-36,rogers1,davis-58,odi:89,smullyan-92}.
This is a remarkable departure from informal suspicions and observations regarding the limitations
of our worldview.
No longer is one reduced to informal, heuristic contemplations and comparisons about what one knows and can do versus
one's unpredictability and incapability.
Formal unknowability is about formal proofs of unpredictability and impossibility.

Almost since its discovery, attempts~\cite{popper-50i,popper-50ii} have been made to translate
formal incompleteness into the physics,
mostly by reduction to some provable undecidable problem
of recursion theory, such as the halting
problem~\cite{wolfram84,kanter,moore,wolfram85b,dc-d91a,dc-d91b,suppes-1993,svozil-93,1994IJTP...33.1085H,casti:94-onlimits_book,casti:96-onlimits,barrow-impossibilities}.
Here the term {\em reduction} indicates that physical undecidability is linked or reduced to logical undecidability.
A typical example is the embedding of a Turing machine or any type of computer capable of
universal computation into a physical system.
As a consequence, the physical system inherits
any type of unsolvability derivable for universal computers, such as the
unsolvability of the halting problem derived below:
since the computer is part of the physical system, so are its behavioral patterns
(and {\em vice versa}~\cite{bridgman,landauer:86,landauer}).

Note that these ``logical and recursion theoretical''
types of physical unknowables are only derivable within deterministic systems which are
``strong enough'' to express {\em self-reference} and {\em substitution}~\cite[Chaprt~1]{smullyan-92}.
Indeterministic systems are {\em per se} not deterministic.
And ``too weak'' forms of expressibility are trivially ``incomplete''
in the sense that they are incapable of expressing self-reference and substitution.


G\"odel himself did not believe that his incompleteness theorems had any relevance for physics,
in particular not for quantum mechanics.
The author was told by professor Wheeler that G\"odel's resentments
(also mentioned in Ref.~\cite[pp. 140-141]{bernstein})
may have been due to Einstein's negative opinion of quantum theory;
to the extend that Einstein may have ``brainwashed'' G\"odel
into believing that all efforts in this direction were in vain.


\subsection{Intrinsic self-referential observers}


Embedded~\cite{toffoli:79}, intrinsic observes~\cite{svozil-94} cannot leave their ``Cartesian prison''~\cite[Meditation~1,12]{descartes-meditation}
and ``step outside'' the universe examining it from some ``Archimedian point''~\cite[\S~11, pp.405-409]{bos1}.
Thus every physical observation is reflexive~\cite{nagel-ViewFromNowhere,sosa-rk2} an circular~\cite{Kauffman198753}.
The self-referential and substitution capability of observers results in very diverse, unpredictable forms of behaviour, and in provable unknowables.

For the sake of the further analysis suppose that there exists observers measuring objects, and that
observer and object are distinct from one another; separated by a ``cut.''
Through that cut, information is exchanged.
Symbolically, we may regard the object as an agent contained in a ``black box,''
whose only relevant emanations are representable by finite strings of zeroes and ones
appearing on the cut, which can be modeled by any kind of screen or display.
According to this purely syntactic point of view,
a physical theory should be able to render identical symbols like the ones appearing through the cut.
That is, a physical theory should be able to mimic or emulate the black box it purports to apply to.
This view is often adapted in quantum mechanics~\cite{fuchs-peres},
where the question regarding any ``meaning'' (e.g., Ref.~\cite[p. 129]{feynman-law}, see below) of the quantum formalism is notorious.


A sharp distinction between a physical object and an extrinsic,
outside observer is a rarely affordable abstraction.
Mostly the observer is part of the system to be observed.
In such a case,
the measurement process is modeled symmetrically,
and information is exchanged between observer and object bidirectionally.
This symmetrical configuration makes a distinction between observer and object purely conventional.
The cut is constituted by the information exchanged.
We tend to associate with the ``measurement apparatus''
one of the two subsystems which in comparison is ``larger'' and ``more classical''
and ``up-linked'' with some conscious observer~\cite{wigner:mb}.
The rest of the system we call the ``measured object.''


Intrinsic observers face all kinds of paradoxicalself-referential situations.
These have been known
both informally as puzzling amusement and artistic perplexity,
as well as a formalized scientifically valuable resource.
The {\em liar paradox}, fo rinstance, is already mentioned in the Bible's Epistle to Titus, 1:12 stating that,
``one of Crete's own prophets has said it: `Cretans are always liars, evil brutes, lazy gluttons.'
He has surely told the truth.''
In what follows, paradoxical self-referentiality will be applied to argue
against the solvability of the general induction problem,
as well as for a pandemonium of undecidabilities related to physical systems
and their behaviors. All of them are based on intrinsic observers embedded
in the system they observe.

It is not totally unreasonable to speculate that the
limits of ``intrinsic self-expression'' seems to be
what G\"odel himself
considered the gist of his incompleteness theorems.
In a reply to a letter by Burks
(reprinted in Ref.~\cite[p. 55]{v-neumann-66}; see also Ref.~\cite[p.554]{fef-84}),
G\"odel states,
 \begin{quote}
 {\em
 ``$\ldots$ that a complete epistemological description
 of a language $A$ cannot be given in the same language $A$, because
 the concept of truth of sentences of $A$ cannot be defined in $A$. It
 is this theorem which is the true reason for the existence of
 undecidable propositions in the formal systems containing arithmetic.''}
 \end{quote}

One of the first researchers getting interested in the application
of paradoxical self-reference to physics
was the philosopher Popper,
who published two almost forgotten papers
\cite{popper-50i,popper-50ii}
discussing, among other issues, Russell's Paradox of
Tristram Shandy~\cite{sterne}:
In Volume 1, Chapter XIV, Shandy finds that he could publish
two volumes of his life every year,
covering a time span far smaller than the time it took him to write
these volumes. This de-synchronization, Shandy concedes,
will rather increase than diminish as he advances; and one may thus have serious doubts
whether he will ever complete his autobiography.
This relates to a question of whether there can be a physical computer that can be assured
of correctly {\em ``processing information faster than the universe does.''}
Wolpert states that~\cite[p.~016128-1]{PhysRevE.65.016128} (see also Ref.~\cite{CalCamSvo-Stef-1995} for an earlier result),
{\em ``In a certain sense, the universe is more powerful
than any information-processing system constructed within it
could be. This result can alternatively be viewed as a restriction
on the computational power of the universe—--the universe
cannot support the existence within it of a computer
that can process information as fast as it can.''}


\subsection{Unpredictability}
\label{2010-unknowable-s2}

For any deterministic system ``strong enough'' to support
universal computation,  the general forecast or prediction
problem is provable unsolvable.
This proposition will be argued by reduction to the halting problem which is provable unsolvable.
A straightforward embedding of a universal computer
into a physical system results in the fact that,
due to the reduction to the recursive undecidability of the halting problem,
certain future events cannot be forecasted
and are thus provable indeterministic.
Here reduction again means that physical undecidability is linked or reduced
to logical undecidability.

A clear distinction should be made between {\em determinism}
(such as {\em computable evolution laws}) and {\em predictability}~\cite{suppes-1993}.
Determinism is necessary for provable unpredictability; but determinism does not exclude unpredictability ``in the long run.''
Recursion theoretic unknowables correspond to ``global'' observables,
whereas the ``local'' (temporal) evolution of the system can be perfectly deterministic and computable.


Unpredictability in indeterministic systems is tautologic and trivial.
At the other extreme, one should also keep in mind that there exist rather straightforward
``pre-G\"odelian'' impossibilities~\cite{bruk-08}  to
express certain mathematical truth
 in ``weak'' systems which are incapable to
represent universal computation or Peano arithmetic.

For the sake of getting an (algorithmic) taste
of what paradoxical self-reference is like,
we present the sketch of an algorithmic proof
of the unsolvability of the halting problem.
The halting problem is the decision problem whether or not a computer will eventually ``halt;''
i.e., will evolve into a state indicating the ``completion'' of a computation task, or stop altogether.
Stated differently, a ``solution'' of the halting problem will be an algorithm which
decides whether another arbitrary algorith ``finishes running'' or will ``run forever.''

The scheme of the proof by contradiction is as follows:
the existence of a hypothetical halting algorithm
capable of solving the halting problem will be {\em assumed.}
This could be, for instance, be a ``subprogram'' of an unknown ``macro library''
which takes the code of an arbitrary program as input ant outputs ``yes'' or ``no,''
depending on whether or not the program halts.
One may also think of it as a sort of ``oracle'' or ``black box'' taking in the an arbitrary
program in terms of its symbolic code, and outputting to symbolic states, say ``yes'' or ``no.''

Based on this ``hypothetical halting algorithm'' we construct another ``diagonalization program'' as follows:
upon receiving some ``arbitrary input program'' code as input, the ``diagonalization program''
consults the ``hypothetical halting algorithm'' whether or not the
``arbitrary input program'' halts; upon receiving some answer it does the {\em opposite:}
if  the ``hypothetical halting algorithm'' decides that the ``arbitrary input program'' {\em halts,}
the ``diagonalization program'' does {\em not halt} (it may do so easily by entering an infinite loop).
Alternatively, if  the ``hypothetical halting algorithm'' decides that the ``arbitrary input program'' does {\em not halt,}
the ``diagonalization program'' {\em halts immediately.}

The ``diagonalization program'' can be forced to execute a paradoxical task by
receiving {\em its own program code} as ``input program.''
Because by considering the ``diagonalization program,''
the ``hypothetical halting algorithm'' steers the ``diagonalization program'' into
{\em halting} if it discovers that it {\em does not halt;}
conversely,  the ``hypothetical halting algorithm'' steers the ``diagonalization program'' into
{\em not halting} if it discovers that it {\em halts.}

In order to block this self-contradictory paradoxical behaviour, one has to get rid of the ``diagonalization program.''
Since all other operations are straightforward and ``innocent,'' the only nontrivial
assumption was the existence of the ``hypothetical halting algorithm.''
Hence, the only consistent way of avoiding the paradox is to
{\em postulate the impossibility} of such a ``hypothetical halting algorithm.''
(A slightly revised form of the proof holds for quantum diagonalization~\cite{1612095},
as quantum information could be in a fifty-fifty fixed point state.)


A universal computer
can in principle be embedded into or realized by physical systems.
An example for such a physical system is the computer on which I am currently typing this manuscript.
Assuming unbounded space (i.e., memory~\cite{calude-staiger-09}) and time,
it follows by
reduction~\cite{wolfram84,kanter,moore,wolfram85b,dc-d91a,dc-d91b,suppes-1993,svozil-93,1994IJTP...33.1085H,casti:94-onlimits_book,CalCamSvo-Stef-1995,casti:96-onlimits,barrow-impossibilities}.
that there exist physical observables,
in particular forecasts about whether or not an embedded computer will ever
halt in the sense sketched above,
which are provable undecidable.





\subsection{The busy beaver function as the maximal recurrence time}

The busy beaver function~\cite{rado,chaitin-ACM,dewdney,brady}
addresses the following
question: suppose one considers all  programs (on a particular computer)
up to length (in terms of the number of symbols) $n$.
What is the {\em largest number} producible by such a program before halting?
(Note that non-halting programs, possibly producing an infinite number (e.g., by a non-terminating loop), do not apply.)
This number may be called the {\em  busy beaver function} of $n$.
The first values of a Turing machine's busy beaver function with 2 states and n symbols
 are, for $n=$ 2, 3, 4, 5, 6 and 8, known to be, or estimated by~\cite{dewdney,brady}
 4, 6, 13, greater than $10^{3}$, greater than  $10^{4}$, and greater than
$10^{44}$.

Consider a related question: what is the upper bound of running time --- or,
alternatively, recurrence time --- of a program of length $n$ bits before
terminating, or, alternatively, recurring?
An answer to that question confers a feeling of how long we have to
wait for the most time-consuming program of length $n$ bits to
hold. That, of course, is a worst-case scenario. Many programs of
length $n$ bits will have halted long  before the maximal halting time.
We mention without proof~\cite{chaitin-ACM,chaitin-bb}  that
this bound can be represented by the busy beaver function.

Knowledge of the maximal halting time would ``solve'' the halting
problem quantitatively;
because if the maximal halting time would be known
and bounded by any computable function of the program size of $n$ bits,
one would have to wait
just a little bit longer than the maximal halting time to make sure
that every program of length $n$ --- also this particular program ---
would have terminated.
Otherwise, the program would run forever.
Since due to the recursive unsolvability of the halting problem the latter one does not exist,
we may expect that the maximal halting time cannot be a computable function.
Indeed, for large values of $n$, the maximal halting time ``explodes'' and
grows faster than any computable function  of $n$.


By reduction upper bounds for the recurrence of any kind of physical behavior can be obtained:
for deterministic systems representable by $n$ bits,
the recurrence time grows faster than any computable number
of $n$.
This bound from below for possible behaviors may be interpreted quite generally
as a ``measure''
of the impossibility to predict and forecast such behaviors by algorithmic means.


\subsection{Undecidability of the induction problem}

Induction in physics is the inference of general rules
dominating and generating physical behaviors from these behaviors alone.
For any deterministic system strong enough to support
universal computation, the general induction problem
is provable unsolvable.
Induction is thereby reduced to the unsolvability of
the rule inference problem~\cite{go-67,blum75blum,angluin:83,ad-91,li:92}
of identifying a rule or law reproducing the behavior of a deterministic system
by observing its input/output performance by purely algorithmic means
(not by intuition).

Informally, the algorithmic idea of the proof is to take any sufficiently powerful
rule or method of induction and, by using it, to define some
functional behavior which is not identified by it.
This amounts
to constructing an algorithm which
(passively!)
 ``fakes'' the ``guesser'' by simulating some particular function
until the guesser
pretends to be able to guess this function correctly.
In a second,  diagonalization step, the ``faking'' algorithm then switches to a different
 function to invalidate the guesser's guess.

%
%More formally, assume two (universal) computers $U$ and $U'$.
%Suppose that the second computer $U'$ executes an arbitrary
%algorithm $p$ unknown to computer $U$, the ``guesser.''
% The task of $U$,
% which is called the rule inference problem,
% is to conjecture the ``law'' or algorithm $p$ by analysing the
% behavior of $U'(p)$.
% The recursive unsolvability of the rule inference problem~\cite{go-67} states that this task cannot be
% performed by any effective computation.
%
%For the sake of contradiction, assume~\cite{li:92}
%that there exists a ``perfect guesser'' $U$ which can identify
%all total recursive functions (wrong).
%Then it is possible to construct a function $\varphi^\ast:{\Bbb N} \rightarrow
%\{0,1\}$, such that the guesses of $U$ are wrong infinitely often,
%thereby contradicting the above assumption.
%
%Define $\varphi^\ast (0)=0$.
%One may construct $\varphi^\ast $ by simulating $U$. Suppose the values
%$\varphi^\ast (0)$, $\varphi^\ast (1)$, $\varphi^\ast (2)$, $\cdots$,
%$\varphi^\ast (n-1)$ have already been constructed. Then, on input $n$,
%simulate $U$, based on the previous series
%$
%\{0, \varphi^\ast (0)\}$,
%$
%\{1, \varphi^\ast (1)\}$,
%$
%\{2, \varphi^\ast (2)\},
%\cdots ,
%\{n-1, \varphi^\ast (n-1)\}$,
% and define
%$\varphi^\ast (n)$ equal to 1 plus the guess of $U$ of
%$\varphi^\ast (n)$ mod 2. In this way, $U$ can never guess
%$\varphi^\ast $ correctly; thereby making an infinite number of mistakes.

One can also interpret this result in terms of the recursive
unsolvability of the halting problem, which in turn is related to the busy beaver function:
there is no recursive bound on the
time the guesser has to wait in order to make sure that his guess is
correct.

\subsection{Impossibility}

Physical tasks which would result in ``paradoxical''
physical behaviour~\cite{hilbert-26} are impossible to perform.
One of this tasks is the solution of the general halting problem, as discussed above.

Another such paradoxical task can be ``forced upon''  {\it La Bocca della Verit\'a} (in English, ``the Mouth of Truth''),
located in the {\em portico} of the church of {\it Santa Maria in Cosmedin} in Rome.
It is ofted believed that if one told a lie with one's hand in the mouth of the sculpture,
it would be bitten off; another less violent legend has it that anyone sticking a hand in the mouth slot and then
utters a false statement will never be able to pull the hand back out.
Rucker once allegedly put in his hand uttering~\cite[p.~178]{rucker} {\em ``I will not be able to pull my hand back out.''}
I leave it to the reader to imagine {\it La Bocca della Verit\'a}'s confusion when confronted with such as statement!

There is a {\em pandemonium} of conceivable physical tasks~\cite{barrow-impossibilities},
some quite entertaining~\cite{smullyan-78}, which would result in paradoxical behaviour and
are thus impossible to perform.
Some of these tasks are ``pre-G\"odelian'' and merely require paradoxical {\em substitution}~\cite[pp.~2-4]{smullyan-92}.

\subsection{Results in classical recursion theory with implications for theoretical physics}


The following theorems of recursive  analysis~\cite{aberth-80,Weihrauch} have some
implications to theoretical physics~\cite{kreisel}.
(i)
There exist recursive monotone bounded sequences of rational numbers
whose limit is no computable number
\cite{Specker49}.
A concrete example of such a number is Chaitin's Omega number~\cite{chaitin3,calude:02,calude-dinneen06},
the ``halting probability'' for a computer (using prefix-free code),
which can be defined by a sequence of rational numbers
with no computable rate of convergence.
(ii)
There exist a recursive real function which has its maximum in the unit interval
at no recursive real number~\cite{Specker57}.
This has implication for the principle of least action.
(iii)
There exists a real number $r$ such that $G(r) = 0$ is recursively undecidable for $G(x)$
in a class of functions which involves polynomials and the sine function
\cite{wang}.
This again has some bearing on  the principle of least action.
(iv)
There exist incomputable solutions of the wave equations for computable initial values
\cite{pr1,bridges1}.
(v)
Based on theorems of recursive analysis~\cite{Scarpellini-63,richardson68},
many questions in dynamical systems theory are provable undecidable~\cite{1985cfd..book.....F,dc-d93,Stewart-91}.
%\end{description}



\section{Deterministic chaos}

The wording {\em ``deterministic chaos''} appears to be a {\it contradictio in adjecto} (in English, ``a contradiction in itself '');
indicating a ``hybrid'' form of ``chaotic'' behavior in deterministic systems~\cite{li-83,nld-chaos}.
Operationally, it is characterized by the practical impossibility to forecast the future due to the fact
that the system is unstable~\cite{Lyapunov-92} and very sensitive with respect
to very small variations of the initial state, which can only be measured with finite accuracy.

\subsection{Instabilities in classical motion}

In 1885 King Oscar II of Sweden and Norway, stimulated by Weierstrass, Hermite and Mittag-Leffler
offered a prize to anybody contributing toward the solution of the so-called {\em $n$-body problem}~\cite{weierstrass-1885}:
\begin{quote}
{\em
Given a system of arbitrarily many mass points that attract each
according to Newton's law, try to find, under the assumption that no two points ever collide,
 a representation of the coordinates of each point
as a series in a variable that is some known function of time and for
all of whose values the series converges uniformly.
}
\end{quote}

The prize-winnging work was expected to render systematic techniques toward a solution to {\em stable} motion,
such that systems whose states start out ``close together'' will stay close together forever~\cite[p.~69]{Diacu96-ce}.
To everyone's surprise, the exciting course of events~\cite{peterson-NC,Diacu96,Diacu96-ce}
resulted in Poincar{\'e}'s prize-winning centennial contribution~\cite{poincare-1890}
predicting unexpected and irreducible {\em instabilities} in the mechanical motion of bodies.
%Stimulated by a hint of Phragm{\'e}n,
Poincar{\'e} was lead to the conclusion that sometimes small
variations in the initial state could lead to huge variations in the
evolution of a physical system at later times.
In Poincar{\'e}'s own words~\cite[Chapter 4, Sect. II, pp. 56-57]{poincare14}:
\begin{quote}
{\em
If we would know the laws of Nature and the state of the Universe precisely
for a certain time,
we would be able to predict with certainty
the state of the Universe for any later time.
But
[[~$\ldots$~]]
it can be the case that small differences in the initial values
produce great differences in the later phenomena;
a small error in the former may result in a large error in the latter.
The prediction becomes impossible and we have a ``random phenomenon.''}
\end{quote}

Note that Poincar{\'e} adheres to a Laplacian-type determinism,
but recognizes the possibility that systems whose states start out ``close together''
will stay close together {\em for a while}~\cite[p.~69]{Diacu96-ce}
and then diverge into totally different behaviors.
Today such behaviours are subsumed under the name ``deterministic chaos.''
In chaotic systems it is practically impossible to specify
the initial value precise enough to allow long-term predictions.

Already in 1873, Maxwell had mentioned~\cite[pp.~211-212]{Campbell-1882} that
\begin{quote}
{\em
$\ldots$ when an infinitely small variation in the present state may bring about a finite difference in the state of the
system in a finite time, the condition of the system is said to be unstable.
It is manifest that the existence of unstable conditions renders impossible the prediction of future events, if our
knowledge of the present state is only approximate, and not accurate.}
\end{quote}
Maxwell also discussed unstabile states of high potential energy whose
spontaneous~\cite{frank}  ``decay'' or ``change''
{\em ``requires an expenditure of work, which in certain cases may be
infinitesimally small, and in general bears no definite proportion to the energy developed in consequence thereof.''}

Today, after more than a century of research into unstable ``chaotic'' motion, {\em symbolic dynamics}
identified the
Poincar{\'e} {\em map near a homocyclic orbit},
the {\em horseshoe map}~\cite{smale-hm},
and the {\em shift map}
as equivalent origins of classical deterministic ``chaotic'' motion,
which is characterized by a {\em computable evolution law}
and the sensitivity and instability of the behavior on the
{\em initial value}~\cite{shaw,li-83,nld-chaos}.

This scenario can be demonstrated by considering the shift map $\sigma$ which
``pushes'' up successive bits of the sequence $s=0.s_1s_2s_3\cdots$;
i.e., $\sigma (s)= 0.s_2s_3s_4\cdots$,  $\sigma (\sigma (s))= 0.s_3s_4s_5\cdots$, and so on.
Suppose one starts with an initial ``measurement'' precision of, say, two bits after the comma,
indicated by a  ``window of measurability;''
all other information ``beyond the second bit after the comma'' is hidden to the experimenter at this point.
Consider two ``operationally'' identical initial states
$s=[0.s_1s_2]s_3\cdots$ and
$s'=[0.s_1s_2]s_3'\cdots$, with $s_3\neq s_3'$, and the square brackets indicate the ``window of measurability.''
Initially, $s$ and $s'$  cannot be distiguished ``operationally,''
since both start with the same ``window of measurability'' $0.s_1s_2$.
After just two iterations, $s$ and
$s'$
may result in different, diverging ``observables''
$\sigma (\sigma (s))= [0.s_3s_4]s_5\cdots$
and
$\sigma (\sigma (s'))= [0.s_3's_4']s_5'\cdots$.

If the initial values are {\em defined} to be elements of
a continuum, then ``almost all'' (of measure one) of them
are not representable by any algorithmically compressible number;
in short,  they are random~\cite{MartinLöf1966602,calude:02}.
Classical, deterministic chaos results from the ``unfolding'' of such a random initial value
--- drawn somehow (one needs the {\em axiom of choice}~\cite{wagon1} for doing this)
from the ``continuum urn'' --- by a recursive, deterministic function.
Of course, if one restricts the initial values to finite sets,
or to, say, the rationals, then the behaviour will be periodic.
So, the randomness of classical, deterministic chaos resides
in the {\em assumption of the continuum};
an assumption which might be considered a ``historic convenience.''
It is difficult to conceive of any convincing
physical ``operational'' evidence supporting the continuum assumption.
If the continuum assumption is dropped then what remains is Maxwell's
and Poincar{\'e}'s observation on the unpredictability
of the behaviour of a deterministic system
due to instabilities~\cite{Lyapunov-92}.


\subsection{Rate of convergence}

The connections between symbolic dynamical systems and universal computation
result in provable unknowables~\cite{dc-d93,Stewart-91}.
These symbolic dynamic unknowables are different in type from the dynamical instabilities,
and should be interpreted recursion theoretically, as outlined in Section~\ref{2010-unknowable-s2}.

Let us come back to the original $n$--body problem.
About one hundred years after its formulation as quoted above,
the $n$--body problem has been solved~\cite{1969VeLen...7..121B,Babadzanjanz-1979,Wang91,Diacu96,Wang01,Babadzanjanz-1993,Babadzanjanz-2006}.
The $3$--body problem was already solved in 1912~\cite{Sundman12}.
The solutions are given in terms of convergent power series.

Yet, in order to be practically applicable,
the rate of convergence of the series must be computable and even ``reasonably good.''
We might already expect from symbolic dynamics
that these series solutions in general could converge ``very slowly.''
Even the prediction of behaviors in insignificantly short times
may require the summation of a huge number of terms,
making these series unusable for any practical work
\cite{Diacu96,rousseau-2004}.

Alas, the complications regarding convergence may be more serious.
Consider a universal computer based on the $n$--body problem.
This can, for instance, be achieved by ballistic computation, such as the
``Billiard Ball'' model of computation
\cite{fred-tof-82,margolus-02}
which effectively ``embeds'' a universal computer into a system of $n$--bodies~\cite{svozil-2007-cestial}.
It follows by reduction that certain predictions,
say related to encoding of the general halting problem, are impossible.

What are the consequences of this reduction for the convergence of the series solutions?
It can be expected that not only do the series converge ``very slowly,''
like in deterministic chaos,
but that in general there does not exist any computable rate of convergence
for the series solutions of particular observables.
This is very similar to the busy beaver function or to Chaitin's Omega number~\cite{chaitin3,calude:02}
representing the halting probability of a universal computer.
The Omega number can be ``enumerated''
by series solutions from ``quasi-algorithms''
computing its very first digits~\cite{calude-dinneen06}.
Yet, due to the incomputable growth of the time
required to determine whether or not certain summation terms corresponding to halting programs possibly contribute,
the series lack any computable rate of convergence.

While it may be possible to evaluate
the state of the $n$ bodies by Wang's power series solution
for any finite time with a computable rate of convergence,
global observables, referring to (recursively) unbounded times, may be incomputable.
Examples of global observables correspond to solutions of certain decision problems,
like for instance the stability of some solar system (we do not claim that this is provable incomputable) or the
halting problem.

This, of course,
stems from the metaphor and robustness of universal computation
and the capacity of the $n$-body problem to implement universality.
It is no particularity and peculiarity of Wang's power series solution.
Indeed, the ``troubles'' reside in the capabilities to implement Peano arithmetic and
universal computation by $n$-body problems.
Because of this capacity, there cannot exist other formalizable methods,
analytic solutions or approximations capable to decide and compute certain decision problems
or observables for the $n$-body problem.

\section{Quantum unknowables}

After discussing provable physical unknowables by reduction to recursion theoretical ones,
and ``chaotic'' symbolic dynamics systems, a third group of physical unknowables arises in the quantum domain.
Although it has turned out to be a highly successful theory,
quantum mechanics, in particular its interpretation and meaning,
has been received controversially within the community.
Some of its founding fathers, like Schr\"odinger and in particular  Einstein,
considered quantum mechanics to be an unsatisfactory theory:
Einstein, Podolsky and Rosen argued~\cite{epr,ein-reply} that there exist ways to counterfactually~\cite{svozil-2006-omni,vaidman:2009} infer observables from experiment which, according to quantum mechanics, cannot co-exist simultaneously;
hence quantum mechanics cannot predict what experiment can (counterfactually) ``measure;''
thus quantum mechanics is {\em incomplete} and should eventually be substituted by a more complete theory.
Others, among them Born, Bohr and Heisenberg,
claimed that quantum unknowables are irreducible, ``ontic,'' and will stay with us forever.
Over the years, the latter view seems to have prevailed
\cite{fuchs-peres,Bub-1999}; although not totally unchallenged
\cite{jammer:66,jammer1,jammer-92}.
Already Sommerfeld warned his students not to get
into the ``meaning behind'' quantum mechanics,
and, as mentioned by Clauser~\cite{clauser-talkvie},
not long ago scientists working in that field
had to be very careful not to become discredited as {\em ``quacks.''}
Richard Feynman~\cite[p. 129]{feynman-law}
once mentioned the
\begin{quote}
{\em ``$\ldots$ perpetual torment that results
from [[the question]], `But how can it be like that?' which
is a reflection of uncontrolled but utterly vain desire to see
[[quantum mechanics]] in terms of an analogy with something familiar
$\ldots$
Do not keep saying to yourself, if you can possibly avoid it,
`But how can it be like that?'
because you will get `down the drain', into a blind alley from which nobody has yet
escaped.''}
\end{quote}
This anti-rationalistic postulate of irreducible indeterminism and ``meaninglessness'' came
after a period of fierce debate on the quantum foundations,
after decades of vain attempts to ``complete'' quantum mechanics in any operationally testable way,
and after the discovery of mathematical ``proofs'' of the incompatibility of local, realistic, context-independent ways to ``complete''
quantum mechanics~\cite{clauser,mermin-93}.


In what follows, we shall discuss three main quantum unknowables:
(i) randomness of single events,
(ii) complementarity, and
(iii) value indefiniteness.

\subsection{Random events}

In 1926, Born postulated that (cf. Ref.~\cite[p.~866]{born-26-1}, English translation in Ref.~\cite[p.~54]{wheeler-Zurek:83})
\begin{quote}
{  ``From the standpoint of our quantum mechanics, there is no quantity
which in any individual case causally fixes the consequence of the collision;
but also experimentally we have so far no reason to believe that there are some inner properties of the atom
which condition a definite outcome for the collision.
Ought we to hope later to discover such properties [[$\ldots$]]  and determine them in individual cases?
Or ought we to  believe that the agreement of theory and experiment --- as to the impossibility
of prescribing conditions? I myself am inclined  to give up determinism in the world of atoms.''
}
\end{quote}

Furthermore, Born suggested that, while {\em individual particles behave irreducibly indeterministic},
the {\em quantum state evolves deterministically} (even revesible; i.e., one-to-one) in a ``Laplacian'' causal way
(cf. Ref.~\cite[p.~804]{born-26-2}, English translation in Ref.~\cite[p.~302]{jammer:89}):
\begin{quote}
{  ``The motion of particles conforms to the laws of probability, but the probability itself
is propagated in accordance with the law of causality.
[This means that knowledge of a state in all points in a given time determines the distribution of
the state at all later times.]''
}
\end{quote}

Born did not specify the formal notion of ``indeterminism'' he was relating to.
So far, no mathematical characterization of quantum randomness has been proven~\cite{2008-cal-svo}.
In the absence of any indication to the contrary, it is mostly implicitly assumed
that quantum randomness is of the strongest possible type;
which amounts to postulating that the associated symbolic sequences are algorithmically incompressible.


The quantum formalism does not predict the outcome of single events
when there is a mismatch between the context in which a state was prepared,
and the context in which it is measured.
Here, the term ``context''~\cite{svozil-2006-omni,svozil-2008-ql}
denotes a maximal collection of commeasurable observables,
or, more technically,
the maximal operator from which all commuting operators can be functionally derived
\cite[\S 84]{halmos-vs}.
Ideally, a quantized system can be prepared
to yield exactly one answer in exactly one context~\cite{zeil-99,DonSvo01,svozil-2002-statepart-prl}.
Other outcomes associated with other contexts occur indeterministically~\cite{2008-cal-svo}.

Furthermore, the quantum formalism is incapable of predicting deterministically the radioactive decay of individual particles.
Attempts to find causal laws ``dried out''~\cite{Kragh-1997AHESradioact,Kragh-2009_RePoss5} at the time of Born's indeterministic interpretation measurement outcomes,
and nobody has been able to give a satisfactory answer since then.

In the absence of other explanations, it might thus be consistent with the present prevalent opinion among physicists
that these single events occur without any causation
and thus at random.
Such random ``quantum coin tosses''~\cite{svozil-qct,rarity-94,zeilinger:qct,stefanov-2000,0256-307X-21-10-027,wang:056107,fiorentino:032334,svozil-2009-howto}
have been used for various purposes, among them delayed choice experiments
\cite{wjswz-98,zeilinger:qct}.

Note that randomness of this type~\cite{Cris04,calude-dinneen05}
is postulated rather than proven; and thus, unless disproved, remain conjectural.
This is necessarily so, for any claim of randomness can only be corroborated
with respect to a more or less large class of laws or behaviors;
it is impossible to inspect the hypothesis against an infinity --- and even less so all --- of conceivable laws.
To rephrase a statement about computability~\cite[p. 11]{davis-58}, {\em ``how can we ever exclude the possibility of our
presented, some day (perhaps by some extraterrestrial visitors), with a (perhaps
extremely complex) device  that ``computes'' and ``predicts''
a certain type of hitherto ``random'' physical behavior?''}


\subsection{Complementarity}




Complementarity is the impossibility to measure
two or more complementary observables
with arbitrary precision simultaneously.

In 1933, Pauli gave the first explicit definition of complementarity stating that (cf. \cite[p.~7]{pauli:58},
partial English translation in \cite[p.~369]{jammer:89})
\begin{quote}
{  ``In the case of  an indeterminacy of a property of a system at a certain configuration
(at a certain state of a system), any attempt to measure the respective property (at least partially)
annihilates the influence of the previous knowledge of system on the (possibly statistical) propositions
about possible later measurement results.
[[$\ldots$]]
The impact
on the system by the  measurement apparatus for momentum (position) is such that
within the limits of the uncertainty relations
the value of the knowledge of the previous position (momentum) for the
prediction of later measurements of position and momentum is lost.''
}
\end{quote}

Einstein-Podolski-Rosen~\cite{epr} type arguments  utilizing a configuration
of two ``entangled'' particles~\cite{schrodinger,CambridgeJournals:1737068,CambridgeJournals:2027212}
claim to be able to infer two different contexts counterfactually simultaneously, thus circumventing complementarity.
Thereby, one context is measured on one side of the setup, whereas the other context on the other side of it.
By the uniqueness property~\cite{svozil-2006-uniquenessprinciple}  of certain two-particle states,
knowledge of a property of one particle entails the certainty
that, if this property were measured on the other particle as well, the outcome of the measurement would be
a unique function of the outcome of the measurement performed.

This makes possible the measurement of one context, {\em as well as} the {\em simultaneous counterfactual inference} of a different context.
Because, one could argue, although one has actually measured on one side a different, incompatible context compared to the context measured on the other side,
if on both sides the same  context {\em would be measured}, the outcomes on both sides {\em would be uniquely correlated}.
Hence, concludes the Einstein-Podolski-Rosen type argument,
measurement of one context per side is sufficient,
for the outcome could be counterfactually inferred on the other side.
In the opinion of these authors, quantm mechanics is ``incomplete,''
because it cannot predict what can be measured; thus a ``more complete'' theory is needed.

Complementarity was first encountered in quantum mechanics,
but it is a phenomenon also observable in the classical world.
To get a better intuition for complementarity, we shall consider generalized urn models~\cite{wright,wright:pent} or,
equivalently~\cite{svozil-2001-eua},
finite deterministic automata~\cite{e-f-moore,schaller-96,dvur-pul-svo,cal-sv-yu} in an unknown initial state.
Both quasi-classic examples mimic complementarity to the extent that even quasi-quantum cryptography
can be performed with them~\cite{svozil-2005-ln1e}.


A generalized urn model is
characterized by an ensemble of balls with black background color.
Printed on these balls are some color symbols.
Every ball contains just one single symbol per color.

Assume further some filters or eyeglasses which are
``perfect'' by totally absorbing light of all other colors
but a particular single one.
In that way, every color can be associated with a particular eyeglass and vice versa.
%This, of course, is a system science trick related to intrinsic color perception.

When a spectator looks at a particular ball through such an eyeglass,
the only operationally recognizable symbol will be the one in the particular
color which is transmitted through the eyeglass.
All other colors are absorbed, and the symbols printed in them will appear black
and therefore cannot be differentiated from the black background.
Hence the ball appears to carry a different ``message'' or symbol,
depending on the color at which it is viewed.



The difference between the balls and the quanta is the possibility
to view all the different symbols on the balls
in all different colors by taking off the eyeglasses;
also one can consecutively look at one and the same ball with different colors,
thereby identifying the ball completely.
Quantum mechanics does not provide us with  a possibility to ``look across the quantum veil,''
as it neither allows a ``global, simultaneous measurement'' of all complementary observables,
nor does it allow a measurement of one observable without disturbing the measurement of another complimentary observable
(with the exception of Einstein-Podolsky-Rosen type ``counterfactual measurements'').
On the contrary, there are strong formal arguments suggesting
that the assumption of a simultaneous
physical existence of such complementary observables yields a complete contradiction.
These issues will be discussed next.


\subsection{Value indefiniteness versus omniscience}

Still another quantum unknowable results from the fact that no ``global'' classical truth
assignment exists which is consistent with even a finite number of ``local'' ones.
That is, no consistent classical truth table can be given by pasting together commeasurable observables.
This phenomenon is also known as {\em value indefiniteness} or, by an option to interpret this result, {\em contextuality}  (see below).
Here the term ``local'' refers to a particular context~\cite{svozil-2008-ql},
which operationally should be thought of the collection of all co-comeasurable or co-preparable~\cite{zeil-99} observables.
The structure of quantum propositions~\cite{birkhoff-36,kochen3,kalmbach-83,kalmbach-86,pulmannova-91,nav:91,svozil-ql}
can be obtained by ``pasting'' contexts together.

As by definition only {\em one single} such context is directly measurable, arguments based on more than one contexts must necessarily involve counterfactuals~\cite{svozil-2006-omni,vaidman:2009}.
A {\em counterfactual} is an ``observable'' whis has not been measured but ``potientially'' copuld have been measured
if an observer ``would have'' decided to do so; alas the observer decided to measure a different, presumably complementary, observable.
Already scholastic philosophy~\cite{specker-60},
for instance Thomas Aquinas,
considered similar questions such as whether God has knowledge of
non-existing  things~\cite[Part 1, Question 14, Article 9]{Aquinas} or things
that are not yet~\cite[Part 1, Question 14, Article 13]{Aquinas}.
Classical omniscience, at least its naive expression that
``if a proposition is true, then an omniscient agent (such as God) knows that it is true''
is plagued by controversies and paradoxes.
Even without evoking quantum mechanics, there exist bounds on behaviors due to the self-referential
perception of intrinsic observers endowed with free will:
if such an observer is omniscient and has absolute predictive power,
then free will could counteract omniscience, and in particular the own predictions.
The only consistent alternative seems either to abandon free will,
stating that it is an idealistic illusion,
or to accept that omniscience and absolute predictive power is bound by paradoxical self-reference.

The empirical sciences implement classical omniscience by assuming that
in principle all observables of classical physics are (co-)measurable without any restrictions,
and regardless of whether they are actually measured or not.
No ontological distinction is made between an observable obtained by an ``actual'' and a ``potential'' or ``counterfactual'' measurement.
(In contrast compare Schr\"odinger's own epistemological interpretation of the wave function~\cite[\S  7]{schrodinger} as a
{\em ``catalogue of expectations.''})
Precision and commeasurability are limited only by the technical capacities of the experimenter.
The principle of empirical classical omniscience has given rise to the realistic believe that
all observables ``exist'' regardless of their observation; i.e., regardless and independent of
any particular measurement.
Physical (co-)existence is thereby related to the realistic assumption~\cite{stace}
(sometimes referred to as the ``ontic''~\cite{atman:05} viewpoint) that such physical entities exist
even without being experienced by any finite mind.

The formal expression of classical omniscience is the Boolean algebra of observable propositions~\cite{Boole},
and in particular the ``abundance'' of two-valued states interpretable
as omniscience about the system.
Thereby, any such ``dispersionless'' quasi-classical two-valued state --- associated with a ``truth table''
--- can be defined on all observables,
regardless of whether they have been actually observed or not.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

After the discovery of complementarity, a further indication against quantum omniscience came from Boole's
``conditions of possible experience''~\cite{Boole-62,Pit-94} for quantum probabilities and
expectation functions.
Bell was the first to point to experiments which,
based on counterfactually inferred elements of physical reality
discussed by Einstein, Podolsky and Rosen~\cite{epr},
seemed to indicate the impossibility
to faithfully embed quantum observables into classical Boolean algebras.
To state the issues pointedly, under some (presumably mild) side assumptions,
``unperformed experiments have no results''
\cite{peres222} --- there cannot exist a table enumerating all
actual and hypothetical context independent experimental
outcomes consistent with the observed quantum frequencies~\cite{zeilinger-epr-98}.
Any such table could be interpreted as omniscience with respect to
the observables in the Bell-type experiments.
The impossibility to construct such tables appears to be a very serious indication against
omniscience in the quantum domain.

The reason for the impossibility to describe all quantum observables
simultaneously by classical tables of experimental outcomes
can be understood in terms of a ``stronger'' result stating that,
for quantum systems whose Hilbert space is of dimension greater than two,
there does not exist any ``dispersionless'' quasi-classical, two-valued state
interpretable as truth table.
This result, which is known as the
Kochen-Specker theorem~\cite{specker-60,kochen1,ZirlSchl-65,Alda,Alda2,kamber64,kamber65,mermin-93,svozil-ql,svozil-tkadlec,cabello-96,svozil-2008-ql},
has a finitistic proof by contradiction.
Proofs of the Kochen-Specker theorem  amount to  ``brain teasers'' in graph coloring:
show that no coloring of certain sets of points (representing quantum observables) in Kochen-Specker type
diagrams exists which include only a single red point
per smooth, unbroken curve; all other points should be colored green.
Alternatively, there does not exist a single possibility to consistently and context-independent
list and tabulate the values of all the observables occurring in a  Kochen-Specker type argument~\cite{cabello-96,svozil_2010-pc09}.
Any ``forced'' tabulation would result in a context dependence; i.e.,
the outcome of a measurement of an observable would depend on what other co-measurable observables are measured
alongside of it~\cite{bohr-1949,bell-66,hey-red,redhead,svozil-2008-ql}.
As far as Einstein-Podolsky-Rosen type measurements might reproduce such contextual behaviour,
quantum mechanics predicts noncontextuality~\cite{svozil:040102}.


The violations of conditions of possible classical experience or
the Kochen-Specker theorem do not exclude realism restricted to a single context,
but realistic omniscience beyond it.
It may  not be totally unreasonable to suspect that the assumption of (pre-)determined observables ``outside''
of a single context may be unjustified~\cite{svozil-2003-garda}.
Nevertheless, the current ``mainstream'' interpretation
of the Kochen-Specker theorem is in terms of quantum contextuality; i.e., through a dependence of the outcome
of a single observable on what other observables are actually measured, or could have been in principle measured, alongside of it.


\section{Miracles due to gaps in causal description}

A different issue, discussed by Philipp Frank~\cite{frank},
is the possible occurrence of miracles in the presence of {\em gaps} of physical determinism.
Already Maxwell considered {\em singular points}~\cite[pp.~212-213]{Campbell-1882}, {\em ``where prediction,
except from absolutely perfect data, and guided by the omniscience of contingency, becomes impossible.''}
One might perceive individual events occurring
``outside'' of the validity of classical and quantum physics without any apparent cause as miracles.
For, if there is no cause to an event,
why should such an event occur altogether rather than not occur?

Although such thoughts remain highly speculative, miracles,
if they exist,
could be the basis for an ``operator-directed'' evolution in otherwise deterministic physical systems.
Similar models have  been applied to dualistic models of the mind~\cite{eccles:papal,popper-eccles}.
The objection that this scenario is unnecessarily complicating an otherwise ``monistic'' model
should be carefully re-evaluated in view of computer-generated {\em virtual realities}~\cite{putnam:81,svozil-nat-acad}.
In such ``algorithmic universes,'' there are computable evolution laws, and there are ``inputs'' from ``interfaces.''
From the intrinsic perspective~\cite{svozil-94}, the inputs cannot be causally accounted for;
hence they remain irreducibly ``transcendental'' with respect to the ``algorithmic universe.''





\section{Concluding thoughts}

\subsection{Metaphysical status of (in)determinism}

Hilbert's sixth problem~\cite{hilbert-1900e} is about the axiomatization of physics.
Regardless of whether or not this goal is achievable,
omniscience cannot be gained
via the formalized, syntactic route to infer and predict physical behaviors.
It will remain blocked forever by paradoxical self-reference
which intrinsic observers and operational methods are bound to.

With regards to conjectures about the (in)deterministic evolution of physical events,
the situation is unsettled; and can be expected to remain unsettled forever.
The reason for this situation is the provable impossibility of formally prove (in)determinism:
neither is it possible to assure that physical behaviors are causal and will remain so forever,
nor is it possible to exclude all causal behaviors.
Thus, both from a  formal, as well as operational point of view,
any rational investigation into, or claim of (in)determinism is strictlty metaphysical;
with very limited validity for theformal and the natural sciences.


The postulate of indeterministic behavior in physics or elsewhere is impossible to {\em prove} by
considering a finite operationally obtained encoded phenotype, such as a finite sequence of (supposedly random) bits,
alone.
Furthermore, recursion theory and algorithmic information theory~\cite{chaitin3,calude:02,gruenwald-vitanyi} implies that
an ``unbounded'' system of axioms is required to ``prove'' the ``unbounded''
algorithmic information content of an ``unbounded'' symbolic sequence;
and there exist irreducible complexities in pure mathematics~\cite{chaitin-04,s00032-006-0064-2}.

The opportinistic approach that, as historically many ``ingenious scientists'' failed to come up with a causal description,
indeterminism will prevail, is anectodal at best and  misleading at worst.
The benevolent advices of authoritative researchers to
avoid asking questions related
to ``completing'' a theory,
or to avoid thinking about ``meaning'' and ``rational interpretation,''
or to find causal laws for phenomena which are postulated to occur indeterministically by that same authorities
--- even wisely posted ---
hardly qualify as proofs.

Any kind of ``lawlessness'' can thus be claimed only
{\em with reference to, and relative} certain criteria, laws or quantitative statistical or algorithmic tests.
For instance, randomness could be established {\em with respect to} certain tests,
such as die batteries of tests of randomness, for instance, {\em diehard}, {\it NIST},  {\it TestU01}~\cite{1268777},
or algorithmic~\cite{calude-dinneen05,CDMTCS372} tests.

Note, however, that even the decimal expansion of $\pi$, the ratio between the circumference and the diameter of an ideal circle~\cite{bailey97,bailey05},
behaves `` reasonably random''~\cite{CDMTCS372}.
$\pi$ might even be a ``good source'' of randomness for many Monte Carlo calculations.


\subsection{Harnessing unknowables and indeterminism}

Physical indeterminism need not necessarily perceived negatively as the ``absence'' of causal laws,
but rather as a {\em valuable resource.}

``Programs'' to ``compute'' the {\em halting probability}~\cite{calude-dinneen06,rtx100200236p}
through summation of series without any computable rate of convergence could,
at least in principle and ``in the limit'' of unbounded computational resources,
be interpreted
toward the ``generation'' of provable random sequences.
However, as has already been expressed by John von Neumann~\cite[p.~768]{von-neumann1},
{\em ``Anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin.''}


The production of ``random numbers'' by  physical generators has a long history~\cite{rand-55}.
Besides recursion theoretic undecidability,
there appear to be at least two principal sources of indeterminism and randomness in physics:
(i) one scenario is associated with instabilities of classical physical systems,
and with a strong dependence of future behaviors on the initial value;
(ii) quantum indeterminism, which can be subdivided into three subcategories:  random outcomes of individual events,
 complementarity, and
value indefiniteness.

The similarities and differences between classical and quantum randomness can probably be best conceptualized
in terms of two ``black boxes:'' the first one of them --- called the {\em ``Poincar{\'e} box''} ---
containing a classical, deterministic chaotic, source of randomness;
the second  --- called the {\em ``Born box''} ---
containing a quantum source of randomness.

A {\em ``Poincar{\'e} box''} could be realized by operating a classical dynamical system in the ``shift map'' region.
Major principles for  {\em ``Born boxes''} utilizing beam
splitters~\cite{svozil-qct,rarity-94,zeilinger:qct,stefanov-2000,0256-307X-21-10-027,wang:056107,fiorentino:032334,svozil-2009-howto} should be:
(i) at least three mutually exclusice outcomes to assure value indefiniteness~\cite{PhysRevLett.85.3313},
(ii) the states prepared and measured should be pure and in mutually (possibly interlinked~\cite{svozil:040102}) unbiased bases or contexts,
(iii) events schould be ``independend,''  as to be able to apply proper normalization procedures~\cite{von-neumann1,Samuelson-1968}.


Suppose an agent is being presented with both boxes without any label on, or hint about, them;
i.e., the origin of indeterminism
is unknown to the agent.
In a modified Turing test, an agent's task would be to find out which is the Born and which is
the Poincar{\'e} box by solely observing their output.
As far as is presently known, there should not exist any operational criterion, method or procedure
discriminating amongst these boxes.
Moreover, both types of indeterminism appear to be based on speculative assumptions:
in the classical case it is the existence of continua and the possibility to ``choose''
elements thereof, representing the initial values;
in the quantum case it is the irreducible indeterminism of single events.



Let me end with an amazement: it is mind-bogglig ``how many'' laws and formalized expressions can be found to express physical behavior.
So, there definitely is substance to the pythagorean belief that, at least in a restricted manner,
``nature is numbers.''
One should be careful in the perception of apparent impossibilities to ``explain''
certain phenomena by any causal law.
I personally have the impression that, in their attempts to canonize beliefs in the irreducible randomness in (quantum) mechanics,
many physicists may have prematurely ``thrown the baby out with the bathwater.''
If this feeling is justified only future can tell the generations to come.


\bibliography{svozil}

\end{document}
Consider a universal computer $U$ and an arbitrary algorithm
$B(X)$ whose input is a string of symbols $X$.  Assume that there exists
a ``halting algorithm'' ${\tt HALT}$ which is able to decide whether $B$
terminates on $X$ or not.
The domain of ${\tt HALT}$  is the set of legal programs.
The range of ${\tt HALT}$ are classical bits.

Using ${\tt HALT}(B(X))$ we shall construct another deterministic
computing agent $A$, which has as input any effective program $B$ and
which proceeds as follows:  Upon reading the program $B$ as input, $A$
makes a copy of it.  This can be readily achieved, since the program $B$
is presented to $A$ in some encoded form
$\ulcorner B\urcorner $,
i.e., as a string of
symbols.  In the next step, the agent uses the code
$\ulcorner B\urcorner $
 as input
string for $B$ itself; i.e., $A$ forms  $B(\ulcorner B\urcorner )$,
henceforth denoted by
$B(B)$.  The agent now hands $B(B)$ over to its subroutine ${\tt HALT}$.
Then, $A$ proceeds as follows:  if ${\tt HALT}(B(B))$ decides that
$B(B)$ halts, then the agent $A$ does not halt; this can for instance be
realized by an infinite {\tt DO}-loop; if ${\tt HALT}(B(B))$ decides
that $B(B)$ does {\em not} halt, then $A$ halts.

The agent $A$ will now be confronted with the following paradoxical
task:  take the own code as input and proceed to determine whether or not it halts.
Then, whenever $A(A)$
halts, ${\tt HALT}(A(A))$, by the definition of $A$, would force $A(A)$ not to halt.
Conversely,
whenever $A(A)$ does not halt, then ${\tt HALT}(A(A))$ would steer
$A(A)$ into the halting mode.  In both cases one arrives at a complete
contradiction.  Classically, this contradiction can only be consistently
avoided by assuming the nonexistence of $A$ and, since the only
nontrivial feature of $A$ is the use of the peculiar halting algorithm
${\tt HALT}$, the impossibility of any such halting algorithm.










G U M in color

A small example involves four ball types
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf -}}{\color{green} {\bf -}}$}} \end{picture},
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf -}}{\color{green} {\bf +}}$}} \end{picture},
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf +}}{\color{green} {\bf -}}$}} \end{picture}, and
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf +}}{\color{green} {\bf +}}$}} \end{picture}
Observervation with red eyeglasses renders the ``red~$-$''-observable: ``the ball is either
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf -}}{\color{green} {\bf -}}$}} \end{picture}
or
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf -}}{\color{green} {\bf +}}$}} \end{picture};''
or the  ``red~$+$''-observable: ``the ball is either
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf +}}{\color{green} {\bf -}}$}} \end{picture}, and
or
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf +}}{\color{green} {\bf +}}$}} \end{picture}.''
Observervation with green eyeglasses rendersthe ``green~$-$''-observable: ``the ball is either
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf -}}{\color{green} {\bf -}}$}} \end{picture}
or
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf +}}{\color{green} {\bf -}}$}} \end{picture}, and
or the ``green~$+$''-observable: ``the ball is either
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf -}}{\color{green} {\bf +}}$}} \end{picture};''
or
\unitlength 0.7mm \allinethickness{1pt}\begin{picture}(8,8) \put(4,2){\circle*{8}} \put(4,2){\makebox(0,0)[cc]{${\color{red} {\bf +}}{\color{green} {\bf +}}$}} \end{picture}.''
No ball type is identified uniquely, and knowledge of the ``green'' observable does not imply knowledge of the ``red observable,'' and {\it vice versa.}

